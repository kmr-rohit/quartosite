[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Welcome to my blog! Here I share insights from my learning journey, technical discoveries, and thoughts on software development.\n\n\n\n\n\n\nDate: March 2024\nCategory: System Design\nI’ve been diving deep into system design concepts and wanted to share my structured learning approach. From basic scalability patterns to complex distributed systems, here’s how I’m building my knowledge systematically.\n\n\n\nDate: February 2024\nCategory: DSA\nAfter solving 100+ LeetCode problems, I’ve identified common patterns and techniques that make problem-solving more systematic. This post covers my approach to tackling different types of algorithmic challenges.\n\n\n\nDate: January 2024\nCategory: Technical Blogs\nA deep dive into Netflix’s chaos engineering practices and how they ensure system resilience. I break down the key concepts and show how to apply these principles to your own systems.\n\n\n\n\n\n\n\n\nProblem-solving techniques and strategies\nAlgorithm analysis and optimization\nInterview preparation tips and experiences\nCompetitive programming insights\n\n\n\n\n\nArchitecture patterns and best practices\nScalability and performance optimization\nDistributed systems concepts\nReal-world system design case studies\n\n\n\n\n\nAnalysis of engineering blog posts\nKey insights from industry leaders\nPractical applications of concepts\nLearning resources and recommendations\n\n\n\n\n\nDetailed book summaries and takeaways\nReading progress and recommendations\nImplementation of book concepts\nLearning strategies and tips\n\n\n\n\n\nLanguage-specific tips and tricks\nBest practices and code quality\nDevelopment tools and workflows\nProject experiences and lessons learned\n\n\n\n\n\nContainerization and orchestration\nCloud platforms and services\nCI/CD pipelines and automation\nMonitoring and observability\n\n\n\n\n\n\n\n\nClear explanations of complex concepts\nPractical examples and code snippets\nStep-by-step tutorials and guides\nReal-world applications and case studies\n\n\n\n\n\nMy learning journey and experiences\nChallenges faced and solutions found\nMistakes made and lessons learned\nGrowth and progress over time\n\n\n\n\n\nSharing knowledge with others\nEncouraging discussion and feedback\nBuilding connections with fellow developers\nContributing to the broader tech community\n\n\n\n\n\n\n\n\n“Building a Scalable Web Application: Lessons Learned”\n“My Kubernetes Learning Journey: From Docker to Orchestration”\n“Technical Blog Analysis: Uber’s Real-time Data Platform”\n“Book Review: Designing Data-Intensive Applications”\n“DSA Interview Preparation: My 3-Month Plan”\n\n\n\n\n\n“System Design Deep Dive”: Multi-part series on scalable architecture\n“DSA Problem Patterns”: Common algorithmic patterns and solutions\n“Technical Blog Analysis”: Regular breakdowns of engineering articles\n“Learning Path Guides”: Structured learning recommendations\n\n\n\n\n\n\n\nI welcome guest posts from other developers and learners. If you’d like to contribute:\n\nTopic Ideas: Share your expertise and experiences\nTechnical Tutorials: Step-by-step guides and walkthroughs\nCase Studies: Real-world project experiences\nLearning Journeys: Your own path to mastering concepts\n\n\n\n\n\nJoint Posts: Co-author articles on complex topics\nInterview Series: Q&A with experienced developers\nStudy Groups: Collaborative learning content\nProject Showcases: Highlighting community projects\n\n\n\n\n\n\n\n\nTotal Posts: 15+ articles\nMonthly Views: Growing steadily\nEngagement: Active discussions in comments\nTopics Covered: DSA, System Design, Technical Blogs, Books\n\n\n\n\n\nComments: Thoughtful discussions on technical topics\nSocial Shares: Content shared across developer communities\nFeedback: Valuable insights from readers\nQuestions: Technical questions and clarifications\n\n\n\n\n\n\n\n\nStart with the “Learning Path Guides” series\nFocus on fundamental DSA concepts\nBuild a strong foundation before diving into advanced topics\n\n\n\n\n\nExplore system design patterns and case studies\nPractice with the provided code examples\nEngage in discussions and share your experiences\n\n\n\n\n\nContribute guest posts and share your expertise\nProvide feedback and suggestions for improvement\nMentor others in their learning journey\n\n\n\n\n\n\n\nSubscribe to get notified about new posts and learning updates:\nSubscribe to Newsletter\n\n\n\n\nTwitter: @yourhandle - Quick thoughts and updates\nLinkedIn: Your Profile - Professional insights\nGitHub: Your Profile - Code examples and projects\n\n\n\n\nGet updates via RSS: RSS Feed\n\n\n\n\n\n\n\nPublish Frequency: 2-3 posts per month\nContent Quality: In-depth, well-researched articles\nCommunity Engagement: Active discussions and feedback\nSkill Development: Improve writing and communication\n\n\n\n\n\nThought Leadership: Establish expertise in key areas\nCommunity Building: Create a learning-focused community\nKnowledge Sharing: Help others in their learning journey\nProfessional Growth: Build a strong personal brand\n\n\n\n\n\n\n\nWriting Tips for Developers\n\n\n\n\nStart with an outline: Plan your post structure before writing\nInclude code examples: Show, don’t just tell\nUse clear explanations: Break down complex concepts\nEngage with readers: Encourage comments and discussion\nBe consistent: Regular posting builds audience\n\n\n\n\n\n\n\n\n\nCommon Blogging Mistakes\n\n\n\n\nToo much theory: Balance with practical examples\nPoor formatting: Use headers, lists, and code blocks\nNo engagement: Respond to comments and questions\nInconsistent posting: Maintain regular schedule"
  },
  {
    "objectID": "blog.html#recent-posts",
    "href": "blog.html#recent-posts",
    "title": "Blog",
    "section": "",
    "text": "Date: March 2024\nCategory: System Design\nI’ve been diving deep into system design concepts and wanted to share my structured learning approach. From basic scalability patterns to complex distributed systems, here’s how I’m building my knowledge systematically.\n\n\n\nDate: February 2024\nCategory: DSA\nAfter solving 100+ LeetCode problems, I’ve identified common patterns and techniques that make problem-solving more systematic. This post covers my approach to tackling different types of algorithmic challenges.\n\n\n\nDate: January 2024\nCategory: Technical Blogs\nA deep dive into Netflix’s chaos engineering practices and how they ensure system resilience. I break down the key concepts and show how to apply these principles to your own systems."
  },
  {
    "objectID": "blog.html#blog-categories",
    "href": "blog.html#blog-categories",
    "title": "Blog",
    "section": "",
    "text": "Problem-solving techniques and strategies\nAlgorithm analysis and optimization\nInterview preparation tips and experiences\nCompetitive programming insights\n\n\n\n\n\nArchitecture patterns and best practices\nScalability and performance optimization\nDistributed systems concepts\nReal-world system design case studies\n\n\n\n\n\nAnalysis of engineering blog posts\nKey insights from industry leaders\nPractical applications of concepts\nLearning resources and recommendations\n\n\n\n\n\nDetailed book summaries and takeaways\nReading progress and recommendations\nImplementation of book concepts\nLearning strategies and tips\n\n\n\n\n\nLanguage-specific tips and tricks\nBest practices and code quality\nDevelopment tools and workflows\nProject experiences and lessons learned\n\n\n\n\n\nContainerization and orchestration\nCloud platforms and services\nCI/CD pipelines and automation\nMonitoring and observability"
  },
  {
    "objectID": "blog.html#writing-style",
    "href": "blog.html#writing-style",
    "title": "Blog",
    "section": "",
    "text": "Clear explanations of complex concepts\nPractical examples and code snippets\nStep-by-step tutorials and guides\nReal-world applications and case studies\n\n\n\n\n\nMy learning journey and experiences\nChallenges faced and solutions found\nMistakes made and lessons learned\nGrowth and progress over time\n\n\n\n\n\nSharing knowledge with others\nEncouraging discussion and feedback\nBuilding connections with fellow developers\nContributing to the broader tech community"
  },
  {
    "objectID": "blog.html#upcoming-posts",
    "href": "blog.html#upcoming-posts",
    "title": "Blog",
    "section": "",
    "text": "“Building a Scalable Web Application: Lessons Learned”\n“My Kubernetes Learning Journey: From Docker to Orchestration”\n“Technical Blog Analysis: Uber’s Real-time Data Platform”\n“Book Review: Designing Data-Intensive Applications”\n“DSA Interview Preparation: My 3-Month Plan”\n\n\n\n\n\n“System Design Deep Dive”: Multi-part series on scalable architecture\n“DSA Problem Patterns”: Common algorithmic patterns and solutions\n“Technical Blog Analysis”: Regular breakdowns of engineering articles\n“Learning Path Guides”: Structured learning recommendations"
  },
  {
    "objectID": "blog.html#guest-posts-collaboration",
    "href": "blog.html#guest-posts-collaboration",
    "title": "Blog",
    "section": "",
    "text": "I welcome guest posts from other developers and learners. If you’d like to contribute:\n\nTopic Ideas: Share your expertise and experiences\nTechnical Tutorials: Step-by-step guides and walkthroughs\nCase Studies: Real-world project experiences\nLearning Journeys: Your own path to mastering concepts\n\n\n\n\n\nJoint Posts: Co-author articles on complex topics\nInterview Series: Q&A with experienced developers\nStudy Groups: Collaborative learning content\nProject Showcases: Highlighting community projects"
  },
  {
    "objectID": "blog.html#blog-statistics",
    "href": "blog.html#blog-statistics",
    "title": "Blog",
    "section": "",
    "text": "Total Posts: 15+ articles\nMonthly Views: Growing steadily\nEngagement: Active discussions in comments\nTopics Covered: DSA, System Design, Technical Blogs, Books\n\n\n\n\n\nComments: Thoughtful discussions on technical topics\nSocial Shares: Content shared across developer communities\nFeedback: Valuable insights from readers\nQuestions: Technical questions and clarifications"
  },
  {
    "objectID": "blog.html#reading-recommendations",
    "href": "blog.html#reading-recommendations",
    "title": "Blog",
    "section": "",
    "text": "Start with the “Learning Path Guides” series\nFocus on fundamental DSA concepts\nBuild a strong foundation before diving into advanced topics\n\n\n\n\n\nExplore system design patterns and case studies\nPractice with the provided code examples\nEngage in discussions and share your experiences\n\n\n\n\n\nContribute guest posts and share your expertise\nProvide feedback and suggestions for improvement\nMentor others in their learning journey"
  },
  {
    "objectID": "blog.html#stay-connected",
    "href": "blog.html#stay-connected",
    "title": "Blog",
    "section": "",
    "text": "Subscribe to get notified about new posts and learning updates:\nSubscribe to Newsletter\n\n\n\n\nTwitter: @yourhandle - Quick thoughts and updates\nLinkedIn: Your Profile - Professional insights\nGitHub: Your Profile - Code examples and projects\n\n\n\n\nGet updates via RSS: RSS Feed"
  },
  {
    "objectID": "blog.html#blogging-goals",
    "href": "blog.html#blogging-goals",
    "title": "Blog",
    "section": "",
    "text": "Publish Frequency: 2-3 posts per month\nContent Quality: In-depth, well-researched articles\nCommunity Engagement: Active discussions and feedback\nSkill Development: Improve writing and communication\n\n\n\n\n\nThought Leadership: Establish expertise in key areas\nCommunity Building: Create a learning-focused community\nKnowledge Sharing: Help others in their learning journey\nProfessional Growth: Build a strong personal brand\n\n\n\n\n\n\n\nWriting Tips for Developers\n\n\n\n\nStart with an outline: Plan your post structure before writing\nInclude code examples: Show, don’t just tell\nUse clear explanations: Break down complex concepts\nEngage with readers: Encourage comments and discussion\nBe consistent: Regular posting builds audience\n\n\n\n\n\n\n\n\n\nCommon Blogging Mistakes\n\n\n\n\nToo much theory: Balance with practical examples\nPoor formatting: Use headers, lists, and code blocks\nNo engagement: Respond to comments and questions\nInconsistent posting: Maintain regular schedule"
  },
  {
    "objectID": "system-design/scalability.html",
    "href": "system-design/scalability.html",
    "title": "Scalability",
    "section": "",
    "text": "Strategies and techniques for building systems that can handle growth in users, data, and traffic.\n\n\n\n\n\nDescription: Adding more resources to existing machines\nResources: CPU, RAM, Storage, Network bandwidth\nPros: Simple, no code changes required\nCons: Limited by hardware, expensive, single point of failure\nUse Cases: Small to medium applications, database servers\n\n┌─────────────────────────────────────┐\n│           Single Server             │\n│  ┌─────────┐ ┌─────────┐ ┌─────────┐ │\n│  │  32 CPU │ │ 128GB   │ │ 10TB    │ │\n│  │  Cores  │ │   RAM   │ │ Storage │ │\n│  └─────────┘ └─────────┘ └─────────┘ │\n└─────────────────────────────────────┘\n\n\n\n\nDescription: Adding more machines to distribute load\nPros: No hardware limits, fault tolerance, cost-effective\nCons: Complexity, distributed system challenges\nUse Cases: Web applications, microservices, cloud-native apps\n\n┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐\n│ Server1 │ │ Server2 │ │ Server3 │ │ Server4 │\n│  8 CPU  │ │  8 CPU  │ │  8 CPU  │ │  8 CPU  │\n│ 32GB RAM│ │ 32GB RAM│ │ 32GB RAM│ │ 32GB RAM│\n└─────────┘ └─────────┘ └─────────┘ └─────────┘\n     │           │           │           │\n     └───────────┼───────────┼───────────┘\n                 │           │\n         ┌───────▼───────┐   │\n         │   Load        │   │\n         │  Balancer     │   │\n         └───────────────┘   │\n                 │           │\n         ┌───────▼───────┐   │\n         │   Clients     │   │\n         └───────────────┘\n\n\n\n\n\n\n\n\n\nLayer: Application Layer (Layer 7)\nFeatures: Content-based routing, SSL termination, health checks\nUse Cases: Web applications, microservices\n\n# Health check configuration\nhealth_check = {\n    'path': '/health',\n    'port': 8080,\n    'protocol': 'HTTP',\n    'interval': 30,\n    'timeout': 5,\n    'healthy_threshold': 2,\n    'unhealthy_threshold': 3\n}\n\n\n\n\nLayer: Transport Layer (Layer 4)\nFeatures: TCP/UDP traffic, high performance, static IP\nUse Cases: TCP applications, gaming, IoT\n\n\n\n\n\nLayer: Both Layer 4 and Layer 7\nFeatures: Basic load balancing, health checks\nUse Cases: Legacy applications, simple setups\n\n\n\n\n\n\n\nclass RoundRobinLoadBalancer:\n    def __init__(self, servers):\n        self.servers = servers\n        self.current_index = 0\n    \n    def get_next_server(self):\n        server = self.servers[self.current_index]\n        self.current_index = (self.current_index + 1) % len(self.servers)\n        return server\n\n\n\nclass LeastConnectionsLoadBalancer:\n    def __init__(self, servers):\n        self.servers = {server: 0 for server in servers}\n    \n    def get_next_server(self):\n        return min(self.servers, key=self.servers.get)\n    \n    def increment_connections(self, server):\n        self.servers[server] += 1\n    \n    def decrement_connections(self, server):\n        self.servers[server] = max(0, self.servers[server] - 1)\n\n\n\nclass WeightedRoundRobinLoadBalancer:\n    def __init__(self, server_weights):\n        self.servers = []\n        for server, weight in server_weights.items():\n            self.servers.extend([server] * weight)\n        self.current_index = 0\n    \n    def get_next_server(self):\n        server = self.servers[self.current_index]\n        self.current_index = (self.current_index + 1) % len(self.servers)\n        return server\n\n\n\nimport hashlib\n\nclass IPHashLoadBalancer:\n    def __init__(self, servers):\n        self.servers = servers\n    \n    def get_server_for_ip(self, client_ip):\n        hash_value = int(hashlib.md5(client_ip.encode()).hexdigest(), 16)\n        server_index = hash_value % len(self.servers)\n        return self.servers[server_index]\n\n\n\n\n\n\n\n\n\nimport functools\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity):\n        self.cache = OrderedDict()\n        self.capacity = capacity\n    \n    def get(self, key):\n        if key in self.cache:\n            self.cache.move_to_end(key)\n            return self.cache[key]\n        return None\n    \n    def put(self, key, value):\n        if key in self.cache:\n            self.cache.move_to_end(key)\n        self.cache[key] = value\n        if len(self.cache) &gt; self.capacity:\n            self.cache.popitem(last=False)\n\n# Usage with decorator\ndef cache_result(ttl=300):\n    def decorator(func):\n        cache = {}\n        \n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = str(args) + str(kwargs)\n            if key in cache:\n                result, timestamp = cache[key]\n                if time.time() - timestamp &lt; ttl:\n                    return result\n            \n            result = func(*args, **kwargs)\n            cache[key] = (result, time.time())\n            return result\n        \n        return wrapper\n    return decorator\n\n\n\nimport redis\nimport json\n\nclass RedisCache:\n    def __init__(self, host='localhost', port=6379, db=0):\n        self.redis = redis.Redis(host=host, port=port, db=db)\n    \n    def get(self, key):\n        value = self.redis.get(key)\n        return json.loads(value) if value else None\n    \n    def set(self, key, value, ttl=None):\n        serialized = json.dumps(value)\n        if ttl:\n            self.redis.setex(key, ttl, serialized)\n        else:\n            self.redis.set(key, serialized)\n    \n    def delete(self, key):\n        self.redis.delete(key)\n    \n    def exists(self, key):\n        return self.redis.exists(key)\n\n\n\n# CDN configuration for static assets\ncdn_config = {\n    'domain': 'cdn.example.com',\n    'regions': ['us-east-1', 'us-west-2', 'eu-west-1', 'ap-southeast-1'],\n    'cache_headers': {\n        'Cache-Control': 'public, max-age=31536000',  # 1 year\n        'ETag': 'resource-version-hash'\n    }\n}\n\ndef get_cdn_url(path):\n    return f\"https://{cdn_config['domain']}/{path}\"\n\n\n\n\n\n\ndef get_user_data(user_id):\n    # Try cache first\n    cache_key = f\"user:{user_id}\"\n    user_data = cache.get(cache_key)\n    \n    if user_data:\n        return user_data\n    \n    # Cache miss - fetch from database\n    user_data = database.get_user(user_id)\n    \n    if user_data:\n        # Store in cache for future requests\n        cache.set(cache_key, user_data, ttl=3600)\n    \n    return user_data\n\n\n\ndef update_user_data(user_id, user_data):\n    # Update database first\n    database.update_user(user_id, user_data)\n    \n    # Update cache immediately\n    cache_key = f\"user:{user_id}\"\n    cache.set(cache_key, user_data, ttl=3600)\n\n\n\nclass WriteBackCache:\n    def __init__(self, batch_size=100, flush_interval=60):\n        self.cache = {}\n        self.write_queue = []\n        self.batch_size = batch_size\n        self.flush_interval = flush_interval\n        self.last_flush = time.time()\n    \n    def write(self, key, value):\n        # Write to cache immediately\n        self.cache[key] = value\n        \n        # Add to write queue\n        self.write_queue.append((key, value))\n        \n        # Flush if conditions are met\n        if (len(self.write_queue) &gt;= self.batch_size or \n            time.time() - self.last_flush &gt;= self.flush_interval):\n            self.flush()\n    \n    def flush(self):\n        if not self.write_queue:\n            return\n        \n        # Batch write to database\n        batch_writes = self.write_queue[:self.batch_size]\n        database.batch_update(batch_writes)\n        \n        # Clear processed writes\n        self.write_queue = self.write_queue[self.batch_size:]\n        self.last_flush = time.time()\n\n\n\n\n\n\n\nclass DatabaseManager:\n    def __init__(self):\n        self.master = DatabaseConnection('master-host', 'master-port')\n        self.replicas = [\n            DatabaseConnection('replica1-host', 'replica1-port'),\n            DatabaseConnection('replica2-host', 'replica2-port'),\n            DatabaseConnection('replica3-host', 'replica3-port')\n        ]\n        self.current_replica = 0\n    \n    def read(self, query):\n        # Use round-robin for read replicas\n        replica = self.replicas[self.current_replica]\n        self.current_replica = (self.current_replica + 1) % len(self.replicas)\n        return replica.execute(query)\n    \n    def write(self, query):\n        # Always use master for writes\n        return self.master.execute(query)\n\n\n\nclass ShardedDatabase:\n    def __init__(self, shards):\n        self.shards = shards\n        self.shard_count = len(shards)\n    \n    def get_shard(self, key):\n        # Simple hash-based sharding\n        shard_id = hash(key) % self.shard_count\n        return self.shards[shard_id]\n    \n    def read(self, key, query):\n        shard = self.get_shard(key)\n        return shard.execute(query)\n    \n    def write(self, key, query):\n        shard = self.get_shard(key)\n        return shard.execute(query)\n    \n    def read_across_shards(self, query):\n        # For queries that need data from multiple shards\n        results = []\n        for shard in self.shards:\n            result = shard.execute(query)\n            results.extend(result)\n        return results\n\n\n\n\n\n\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: web-app-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: web-app\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n\n\n\nimport boto3\n\nclass AutoScalingManager:\n    def __init__(self):\n        self.autoscaling = boto3.client('autoscaling')\n    \n    def create_auto_scaling_group(self, name, min_size, max_size, desired_capacity):\n        response = self.autoscaling.create_auto_scaling_group(\n            AutoScalingGroupName=name,\n            MinSize=min_size,\n            MaxSize=max_size,\n            DesiredCapacity=desired_capacity,\n            TargetGroupARNs=['arn:aws:elasticloadbalancing:...'],\n            VPCZoneIdentifier='subnet-12345678,subnet-87654321'\n        )\n        return response\n    \n    def create_scaling_policy(self, asg_name, policy_name, target_cpu):\n        response = self.autoscaling.put_scaling_policy(\n            AutoScalingGroupName=asg_name,\n            PolicyName=policy_name,\n            PolicyType='TargetTrackingScaling',\n            TargetTrackingConfiguration={\n                'PredefinedMetricSpecification': {\n                    'PredefinedMetricType': 'ASGAverageCPUUtilization'\n                },\n                'TargetValue': target_cpu\n            }\n        )\n        return response\n\n\n\n\n\n\nclass PerformanceMonitor:\n    def __init__(self):\n        self.metrics = {}\n    \n    def record_latency(self, operation, duration):\n        if operation not in self.metrics:\n            self.metrics[operation] = []\n        self.metrics[operation].append(duration)\n    \n    def get_average_latency(self, operation):\n        if operation not in self.metrics:\n            return 0\n        return sum(self.metrics[operation]) / len(self.metrics[operation])\n    \n    def get_p95_latency(self, operation):\n        if operation not in self.metrics:\n            return 0\n        sorted_latencies = sorted(self.metrics[operation])\n        index = int(len(sorted_latencies) * 0.95)\n        return sorted_latencies[index]\n    \n    def record_throughput(self, operation, count):\n        # Record requests per second\n        current_time = time.time()\n        if operation not in self.metrics:\n            self.metrics[operation] = {'count': 0, 'start_time': current_time}\n        \n        self.metrics[operation]['count'] += count\n        \n        # Calculate RPS\n        elapsed = current_time - self.metrics[operation]['start_time']\n        rps = self.metrics[operation]['count'] / elapsed\n        return rps\n\n\n\n\n\n\n\n\n\n\nScaling Guidelines\n\n\n\n\nStart Simple: Begin with vertical scaling for small applications\nMonitor First: Understand bottlenecks before scaling\nScale Horizontally: Add more machines rather than bigger machines\nCache Aggressively: Reduce database load with caching\nUse CDN: Distribute static content globally\n\n\n\n\n\n\n\n\n\nCommon Pitfalls\n\n\n\n\nPremature Optimization: Don’t scale before you need to\nIgnoring Bottlenecks: Database is often the limiting factor\nPoor Monitoring: Can’t optimize what you can’t measure\nOver-Engineering: Keep it simple until complexity is justified",
    "crumbs": [
      "System Design",
      "Scalability"
    ]
  },
  {
    "objectID": "system-design/scalability.html#types-of-scaling",
    "href": "system-design/scalability.html#types-of-scaling",
    "title": "Scalability",
    "section": "",
    "text": "Description: Adding more resources to existing machines\nResources: CPU, RAM, Storage, Network bandwidth\nPros: Simple, no code changes required\nCons: Limited by hardware, expensive, single point of failure\nUse Cases: Small to medium applications, database servers\n\n┌─────────────────────────────────────┐\n│           Single Server             │\n│  ┌─────────┐ ┌─────────┐ ┌─────────┐ │\n│  │  32 CPU │ │ 128GB   │ │ 10TB    │ │\n│  │  Cores  │ │   RAM   │ │ Storage │ │\n│  └─────────┘ └─────────┘ └─────────┘ │\n└─────────────────────────────────────┘\n\n\n\n\nDescription: Adding more machines to distribute load\nPros: No hardware limits, fault tolerance, cost-effective\nCons: Complexity, distributed system challenges\nUse Cases: Web applications, microservices, cloud-native apps\n\n┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐\n│ Server1 │ │ Server2 │ │ Server3 │ │ Server4 │\n│  8 CPU  │ │  8 CPU  │ │  8 CPU  │ │  8 CPU  │\n│ 32GB RAM│ │ 32GB RAM│ │ 32GB RAM│ │ 32GB RAM│\n└─────────┘ └─────────┘ └─────────┘ └─────────┘\n     │           │           │           │\n     └───────────┼───────────┼───────────┘\n                 │           │\n         ┌───────▼───────┐   │\n         │   Load        │   │\n         │  Balancer     │   │\n         └───────────────┘   │\n                 │           │\n         ┌───────▼───────┐   │\n         │   Clients     │   │\n         └───────────────┘",
    "crumbs": [
      "System Design",
      "Scalability"
    ]
  },
  {
    "objectID": "system-design/scalability.html#load-balancing",
    "href": "system-design/scalability.html#load-balancing",
    "title": "Scalability",
    "section": "",
    "text": "Layer: Application Layer (Layer 7)\nFeatures: Content-based routing, SSL termination, health checks\nUse Cases: Web applications, microservices\n\n# Health check configuration\nhealth_check = {\n    'path': '/health',\n    'port': 8080,\n    'protocol': 'HTTP',\n    'interval': 30,\n    'timeout': 5,\n    'healthy_threshold': 2,\n    'unhealthy_threshold': 3\n}\n\n\n\n\nLayer: Transport Layer (Layer 4)\nFeatures: TCP/UDP traffic, high performance, static IP\nUse Cases: TCP applications, gaming, IoT\n\n\n\n\n\nLayer: Both Layer 4 and Layer 7\nFeatures: Basic load balancing, health checks\nUse Cases: Legacy applications, simple setups\n\n\n\n\n\n\n\nclass RoundRobinLoadBalancer:\n    def __init__(self, servers):\n        self.servers = servers\n        self.current_index = 0\n    \n    def get_next_server(self):\n        server = self.servers[self.current_index]\n        self.current_index = (self.current_index + 1) % len(self.servers)\n        return server\n\n\n\nclass LeastConnectionsLoadBalancer:\n    def __init__(self, servers):\n        self.servers = {server: 0 for server in servers}\n    \n    def get_next_server(self):\n        return min(self.servers, key=self.servers.get)\n    \n    def increment_connections(self, server):\n        self.servers[server] += 1\n    \n    def decrement_connections(self, server):\n        self.servers[server] = max(0, self.servers[server] - 1)\n\n\n\nclass WeightedRoundRobinLoadBalancer:\n    def __init__(self, server_weights):\n        self.servers = []\n        for server, weight in server_weights.items():\n            self.servers.extend([server] * weight)\n        self.current_index = 0\n    \n    def get_next_server(self):\n        server = self.servers[self.current_index]\n        self.current_index = (self.current_index + 1) % len(self.servers)\n        return server\n\n\n\nimport hashlib\n\nclass IPHashLoadBalancer:\n    def __init__(self, servers):\n        self.servers = servers\n    \n    def get_server_for_ip(self, client_ip):\n        hash_value = int(hashlib.md5(client_ip.encode()).hexdigest(), 16)\n        server_index = hash_value % len(self.servers)\n        return self.servers[server_index]",
    "crumbs": [
      "System Design",
      "Scalability"
    ]
  },
  {
    "objectID": "system-design/scalability.html#caching-strategies",
    "href": "system-design/scalability.html#caching-strategies",
    "title": "Scalability",
    "section": "",
    "text": "import functools\nfrom collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity):\n        self.cache = OrderedDict()\n        self.capacity = capacity\n    \n    def get(self, key):\n        if key in self.cache:\n            self.cache.move_to_end(key)\n            return self.cache[key]\n        return None\n    \n    def put(self, key, value):\n        if key in self.cache:\n            self.cache.move_to_end(key)\n        self.cache[key] = value\n        if len(self.cache) &gt; self.capacity:\n            self.cache.popitem(last=False)\n\n# Usage with decorator\ndef cache_result(ttl=300):\n    def decorator(func):\n        cache = {}\n        \n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = str(args) + str(kwargs)\n            if key in cache:\n                result, timestamp = cache[key]\n                if time.time() - timestamp &lt; ttl:\n                    return result\n            \n            result = func(*args, **kwargs)\n            cache[key] = (result, time.time())\n            return result\n        \n        return wrapper\n    return decorator\n\n\n\nimport redis\nimport json\n\nclass RedisCache:\n    def __init__(self, host='localhost', port=6379, db=0):\n        self.redis = redis.Redis(host=host, port=port, db=db)\n    \n    def get(self, key):\n        value = self.redis.get(key)\n        return json.loads(value) if value else None\n    \n    def set(self, key, value, ttl=None):\n        serialized = json.dumps(value)\n        if ttl:\n            self.redis.setex(key, ttl, serialized)\n        else:\n            self.redis.set(key, serialized)\n    \n    def delete(self, key):\n        self.redis.delete(key)\n    \n    def exists(self, key):\n        return self.redis.exists(key)\n\n\n\n# CDN configuration for static assets\ncdn_config = {\n    'domain': 'cdn.example.com',\n    'regions': ['us-east-1', 'us-west-2', 'eu-west-1', 'ap-southeast-1'],\n    'cache_headers': {\n        'Cache-Control': 'public, max-age=31536000',  # 1 year\n        'ETag': 'resource-version-hash'\n    }\n}\n\ndef get_cdn_url(path):\n    return f\"https://{cdn_config['domain']}/{path}\"\n\n\n\n\n\n\ndef get_user_data(user_id):\n    # Try cache first\n    cache_key = f\"user:{user_id}\"\n    user_data = cache.get(cache_key)\n    \n    if user_data:\n        return user_data\n    \n    # Cache miss - fetch from database\n    user_data = database.get_user(user_id)\n    \n    if user_data:\n        # Store in cache for future requests\n        cache.set(cache_key, user_data, ttl=3600)\n    \n    return user_data\n\n\n\ndef update_user_data(user_id, user_data):\n    # Update database first\n    database.update_user(user_id, user_data)\n    \n    # Update cache immediately\n    cache_key = f\"user:{user_id}\"\n    cache.set(cache_key, user_data, ttl=3600)\n\n\n\nclass WriteBackCache:\n    def __init__(self, batch_size=100, flush_interval=60):\n        self.cache = {}\n        self.write_queue = []\n        self.batch_size = batch_size\n        self.flush_interval = flush_interval\n        self.last_flush = time.time()\n    \n    def write(self, key, value):\n        # Write to cache immediately\n        self.cache[key] = value\n        \n        # Add to write queue\n        self.write_queue.append((key, value))\n        \n        # Flush if conditions are met\n        if (len(self.write_queue) &gt;= self.batch_size or \n            time.time() - self.last_flush &gt;= self.flush_interval):\n            self.flush()\n    \n    def flush(self):\n        if not self.write_queue:\n            return\n        \n        # Batch write to database\n        batch_writes = self.write_queue[:self.batch_size]\n        database.batch_update(batch_writes)\n        \n        # Clear processed writes\n        self.write_queue = self.write_queue[self.batch_size:]\n        self.last_flush = time.time()",
    "crumbs": [
      "System Design",
      "Scalability"
    ]
  },
  {
    "objectID": "system-design/scalability.html#database-scaling",
    "href": "system-design/scalability.html#database-scaling",
    "title": "Scalability",
    "section": "",
    "text": "class DatabaseManager:\n    def __init__(self):\n        self.master = DatabaseConnection('master-host', 'master-port')\n        self.replicas = [\n            DatabaseConnection('replica1-host', 'replica1-port'),\n            DatabaseConnection('replica2-host', 'replica2-port'),\n            DatabaseConnection('replica3-host', 'replica3-port')\n        ]\n        self.current_replica = 0\n    \n    def read(self, query):\n        # Use round-robin for read replicas\n        replica = self.replicas[self.current_replica]\n        self.current_replica = (self.current_replica + 1) % len(self.replicas)\n        return replica.execute(query)\n    \n    def write(self, query):\n        # Always use master for writes\n        return self.master.execute(query)\n\n\n\nclass ShardedDatabase:\n    def __init__(self, shards):\n        self.shards = shards\n        self.shard_count = len(shards)\n    \n    def get_shard(self, key):\n        # Simple hash-based sharding\n        shard_id = hash(key) % self.shard_count\n        return self.shards[shard_id]\n    \n    def read(self, key, query):\n        shard = self.get_shard(key)\n        return shard.execute(query)\n    \n    def write(self, key, query):\n        shard = self.get_shard(key)\n        return shard.execute(query)\n    \n    def read_across_shards(self, query):\n        # For queries that need data from multiple shards\n        results = []\n        for shard in self.shards:\n            result = shard.execute(query)\n            results.extend(result)\n        return results",
    "crumbs": [
      "System Design",
      "Scalability"
    ]
  },
  {
    "objectID": "system-design/scalability.html#auto-scaling",
    "href": "system-design/scalability.html#auto-scaling",
    "title": "Scalability",
    "section": "",
    "text": "apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: web-app-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: web-app\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n\n\n\nimport boto3\n\nclass AutoScalingManager:\n    def __init__(self):\n        self.autoscaling = boto3.client('autoscaling')\n    \n    def create_auto_scaling_group(self, name, min_size, max_size, desired_capacity):\n        response = self.autoscaling.create_auto_scaling_group(\n            AutoScalingGroupName=name,\n            MinSize=min_size,\n            MaxSize=max_size,\n            DesiredCapacity=desired_capacity,\n            TargetGroupARNs=['arn:aws:elasticloadbalancing:...'],\n            VPCZoneIdentifier='subnet-12345678,subnet-87654321'\n        )\n        return response\n    \n    def create_scaling_policy(self, asg_name, policy_name, target_cpu):\n        response = self.autoscaling.put_scaling_policy(\n            AutoScalingGroupName=asg_name,\n            PolicyName=policy_name,\n            PolicyType='TargetTrackingScaling',\n            TargetTrackingConfiguration={\n                'PredefinedMetricSpecification': {\n                    'PredefinedMetricType': 'ASGAverageCPUUtilization'\n                },\n                'TargetValue': target_cpu\n            }\n        )\n        return response",
    "crumbs": [
      "System Design",
      "Scalability"
    ]
  },
  {
    "objectID": "system-design/scalability.html#performance-monitoring",
    "href": "system-design/scalability.html#performance-monitoring",
    "title": "Scalability",
    "section": "",
    "text": "class PerformanceMonitor:\n    def __init__(self):\n        self.metrics = {}\n    \n    def record_latency(self, operation, duration):\n        if operation not in self.metrics:\n            self.metrics[operation] = []\n        self.metrics[operation].append(duration)\n    \n    def get_average_latency(self, operation):\n        if operation not in self.metrics:\n            return 0\n        return sum(self.metrics[operation]) / len(self.metrics[operation])\n    \n    def get_p95_latency(self, operation):\n        if operation not in self.metrics:\n            return 0\n        sorted_latencies = sorted(self.metrics[operation])\n        index = int(len(sorted_latencies) * 0.95)\n        return sorted_latencies[index]\n    \n    def record_throughput(self, operation, count):\n        # Record requests per second\n        current_time = time.time()\n        if operation not in self.metrics:\n            self.metrics[operation] = {'count': 0, 'start_time': current_time}\n        \n        self.metrics[operation]['count'] += count\n        \n        # Calculate RPS\n        elapsed = current_time - self.metrics[operation]['start_time']\n        rps = self.metrics[operation]['count'] / elapsed\n        return rps",
    "crumbs": [
      "System Design",
      "Scalability"
    ]
  },
  {
    "objectID": "system-design/scalability.html#best-practices",
    "href": "system-design/scalability.html#best-practices",
    "title": "Scalability",
    "section": "",
    "text": "Scaling Guidelines\n\n\n\n\nStart Simple: Begin with vertical scaling for small applications\nMonitor First: Understand bottlenecks before scaling\nScale Horizontally: Add more machines rather than bigger machines\nCache Aggressively: Reduce database load with caching\nUse CDN: Distribute static content globally\n\n\n\n\n\n\n\n\n\nCommon Pitfalls\n\n\n\n\nPremature Optimization: Don’t scale before you need to\nIgnoring Bottlenecks: Database is often the limiting factor\nPoor Monitoring: Can’t optimize what you can’t measure\nOver-Engineering: Keep it simple until complexity is justified",
    "crumbs": [
      "System Design",
      "Scalability"
    ]
  },
  {
    "objectID": "system-design/index.html",
    "href": "system-design/index.html",
    "title": "System Design",
    "section": "",
    "text": "Welcome to my System Design learning journey! This section covers scalable architecture patterns, distributed systems, and real-world system design challenges.\n\n\n\nDesign Patterns - Common architectural patterns and their use cases\nCase Studies - Real-world system design examples\nScalability - Horizontal/vertical scaling, load balancing, caching\n\n\n\n\nSystem design is the process of defining the architecture, components, modules, interfaces, and data for a system to satisfy specified requirements. It’s about making trade-offs between different aspects like:\n\nScalability: How well the system handles growth\nReliability: How often the system fails\nAvailability: How much time the system is operational\nPerformance: How fast the system responds\nMaintainability: How easy it is to modify and extend\n\n\n\n\n\n\n\nFunctional Requirements: What the system should do\nNon-Functional Requirements: Performance, scalability, availability\nConstraints: Budget, timeline, technology stack\n\n\n\n\n\nTraffic Estimation: Requests per second, data storage needs\nStorage Calculation: Data size, growth rate\nBandwidth Requirements: Network capacity needed\n\n\n\n\n\nSystem Architecture: Overall structure and components\nDatabase Design: Data models and storage strategies\nAPI Design: Interface definitions and protocols\n\n\n\n\n\nComponent Design: Individual service specifications\nData Flow: How data moves through the system\nError Handling: Failure scenarios and recovery\n\n\n\n\n\n\n\n\nHorizontal Scaling: Adding more machines\nVertical Scaling: Adding more resources to existing machines\nLoad Balancing: Distributing traffic across multiple servers\n\n\n\n\n\nRedundancy: Multiple copies of critical components\nFailover: Automatic switching to backup systems\nData Replication: Keeping data synchronized across locations\n\n\n\n\n\nACID Properties: Atomicity, Consistency, Isolation, Durability\nCAP Theorem: Consistency, Availability, Partition Tolerance\nEventual Consistency: Data becomes consistent over time\n\n\n\n\n\nLatency: Time to respond to a request\nThroughput: Number of requests handled per unit time\nCaching: Storing frequently accessed data\n\n\n\n\n\n\n\n\nClient-Server Architecture\nRESTful APIs\nMicroservices\nAPI Gateway Pattern\n\n\n\n\n\nRelational Databases: MySQL, PostgreSQL\nNoSQL Databases: MongoDB, Cassandra, Redis\nData Warehousing: BigQuery, Snowflake\nCDN: Content Delivery Networks\n\n\n\n\n\nMessage Queues: RabbitMQ, Apache Kafka\nEvent-Driven Architecture\nPub/Sub Pattern\n\n\n\n\n\nLogging: Centralized log management\nMetrics: Performance monitoring\nTracing: Distributed request tracking\nAlerting: Proactive issue detection\n\n\n\n\n\n\n\n\n“Designing Data-Intensive Applications” by Martin Kleppmann\n“System Design Interview” by Alex Xu\n“Building Microservices” by Sam Newman\n\n\n\n\n\nHigh Scalability: Real-world architecture examples\nAWS Architecture Center: Cloud-specific patterns\nGoogle Cloud Architecture Framework\nMartin Fowler’s Blog: Software architecture insights\n\n\n\n\n\nGrokking the System Design Interview\nSystem Design Primer (GitHub)\nInterviewBit System Design\n\n\n\n\n\n\n\n\nDesign a URL Shortener\nDesign a Chat Application\nDesign a Social Media Feed\nDesign a Video Streaming Service\nDesign a Ride-Sharing Service\n\n\n\n\n\n\n\n\n\n\nBefore the Interview\n\n\n\n\nPractice drawing system diagrams\nUnderstand common design patterns\nKnow your numbers (latency, throughput, storage)\nPrepare questions to ask the interviewer\n\n\n\n\n\n\n\n\n\nDuring the Interview\n\n\n\n\nStart with requirements clarification\nBegin with a high-level design\nDiscuss trade-offs explicitly\nConsider failure scenarios\nBe ready to dive deep into any component\n\n\n\n\n\n\n\n\n\n\n\n\n\nActive Topics\n\n\n\n\nDistributed systems and consistency models\nMicroservices architecture patterns\nCloud-native design principles\nEvent-driven architecture\n\n\n\n\n\n\n\n\n\nNext Steps\n\n\n\n\nPractice designing systems from scratch\nStudy real-world architecture case studies\nImplement small-scale distributed systems\nLearn cloud platform-specific patterns",
    "crumbs": [
      "System Design"
    ]
  },
  {
    "objectID": "system-design/index.html#quick-navigation",
    "href": "system-design/index.html#quick-navigation",
    "title": "System Design",
    "section": "",
    "text": "Design Patterns - Common architectural patterns and their use cases\nCase Studies - Real-world system design examples\nScalability - Horizontal/vertical scaling, load balancing, caching",
    "crumbs": [
      "System Design"
    ]
  },
  {
    "objectID": "system-design/index.html#what-is-system-design",
    "href": "system-design/index.html#what-is-system-design",
    "title": "System Design",
    "section": "",
    "text": "System design is the process of defining the architecture, components, modules, interfaces, and data for a system to satisfy specified requirements. It’s about making trade-offs between different aspects like:\n\nScalability: How well the system handles growth\nReliability: How often the system fails\nAvailability: How much time the system is operational\nPerformance: How fast the system responds\nMaintainability: How easy it is to modify and extend",
    "crumbs": [
      "System Design"
    ]
  },
  {
    "objectID": "system-design/index.html#system-design-interview-process",
    "href": "system-design/index.html#system-design-interview-process",
    "title": "System Design",
    "section": "",
    "text": "Functional Requirements: What the system should do\nNon-Functional Requirements: Performance, scalability, availability\nConstraints: Budget, timeline, technology stack\n\n\n\n\n\nTraffic Estimation: Requests per second, data storage needs\nStorage Calculation: Data size, growth rate\nBandwidth Requirements: Network capacity needed\n\n\n\n\n\nSystem Architecture: Overall structure and components\nDatabase Design: Data models and storage strategies\nAPI Design: Interface definitions and protocols\n\n\n\n\n\nComponent Design: Individual service specifications\nData Flow: How data moves through the system\nError Handling: Failure scenarios and recovery",
    "crumbs": [
      "System Design"
    ]
  },
  {
    "objectID": "system-design/index.html#key-concepts",
    "href": "system-design/index.html#key-concepts",
    "title": "System Design",
    "section": "",
    "text": "Horizontal Scaling: Adding more machines\nVertical Scaling: Adding more resources to existing machines\nLoad Balancing: Distributing traffic across multiple servers\n\n\n\n\n\nRedundancy: Multiple copies of critical components\nFailover: Automatic switching to backup systems\nData Replication: Keeping data synchronized across locations\n\n\n\n\n\nACID Properties: Atomicity, Consistency, Isolation, Durability\nCAP Theorem: Consistency, Availability, Partition Tolerance\nEventual Consistency: Data becomes consistent over time\n\n\n\n\n\nLatency: Time to respond to a request\nThroughput: Number of requests handled per unit time\nCaching: Storing frequently accessed data",
    "crumbs": [
      "System Design"
    ]
  },
  {
    "objectID": "system-design/index.html#common-system-design-topics",
    "href": "system-design/index.html#common-system-design-topics",
    "title": "System Design",
    "section": "",
    "text": "Client-Server Architecture\nRESTful APIs\nMicroservices\nAPI Gateway Pattern\n\n\n\n\n\nRelational Databases: MySQL, PostgreSQL\nNoSQL Databases: MongoDB, Cassandra, Redis\nData Warehousing: BigQuery, Snowflake\nCDN: Content Delivery Networks\n\n\n\n\n\nMessage Queues: RabbitMQ, Apache Kafka\nEvent-Driven Architecture\nPub/Sub Pattern\n\n\n\n\n\nLogging: Centralized log management\nMetrics: Performance monitoring\nTracing: Distributed request tracking\nAlerting: Proactive issue detection",
    "crumbs": [
      "System Design"
    ]
  },
  {
    "objectID": "system-design/index.html#learning-resources",
    "href": "system-design/index.html#learning-resources",
    "title": "System Design",
    "section": "",
    "text": "“Designing Data-Intensive Applications” by Martin Kleppmann\n“System Design Interview” by Alex Xu\n“Building Microservices” by Sam Newman\n\n\n\n\n\nHigh Scalability: Real-world architecture examples\nAWS Architecture Center: Cloud-specific patterns\nGoogle Cloud Architecture Framework\nMartin Fowler’s Blog: Software architecture insights\n\n\n\n\n\nGrokking the System Design Interview\nSystem Design Primer (GitHub)\nInterviewBit System Design",
    "crumbs": [
      "System Design"
    ]
  },
  {
    "objectID": "system-design/index.html#interview-preparation",
    "href": "system-design/index.html#interview-preparation",
    "title": "System Design",
    "section": "",
    "text": "Design a URL Shortener\nDesign a Chat Application\nDesign a Social Media Feed\nDesign a Video Streaming Service\nDesign a Ride-Sharing Service\n\n\n\n\n\n\n\n\n\n\nBefore the Interview\n\n\n\n\nPractice drawing system diagrams\nUnderstand common design patterns\nKnow your numbers (latency, throughput, storage)\nPrepare questions to ask the interviewer\n\n\n\n\n\n\n\n\n\nDuring the Interview\n\n\n\n\nStart with requirements clarification\nBegin with a high-level design\nDiscuss trade-offs explicitly\nConsider failure scenarios\nBe ready to dive deep into any component",
    "crumbs": [
      "System Design"
    ]
  },
  {
    "objectID": "system-design/index.html#current-learning-focus",
    "href": "system-design/index.html#current-learning-focus",
    "title": "System Design",
    "section": "",
    "text": "Active Topics\n\n\n\n\nDistributed systems and consistency models\nMicroservices architecture patterns\nCloud-native design principles\nEvent-driven architecture\n\n\n\n\n\n\n\n\n\nNext Steps\n\n\n\n\nPractice designing systems from scratch\nStudy real-world architecture case studies\nImplement small-scale distributed systems\nLearn cloud platform-specific patterns",
    "crumbs": [
      "System Design"
    ]
  },
  {
    "objectID": "blog/system-design-learning-path.html",
    "href": "blog/system-design-learning-path.html",
    "title": "My System Design Learning Path",
    "section": "",
    "text": "After spending several months studying system design, I wanted to share my structured approach to learning this complex topic. System design is one of the most challenging areas in software engineering, but with the right approach, it becomes manageable and even enjoyable.\n\n\nSystem design interviews are a crucial part of the software engineering interview process, especially for senior positions. But beyond interviews, understanding system design principles is essential for:\n\nBuilding Scalable Applications: Understanding how to handle growth\nMaking Architectural Decisions: Choosing the right patterns and technologies\nDebugging Distributed Systems: Identifying bottlenecks and failure points\nCollaborating with Teams: Communicating design decisions effectively\n\n\n\n\n\n\nI started with the basics to build a strong foundation:\n\n\n\nVertical vs Horizontal Scaling: Understanding the difference and trade-offs\nLoad Balancing: Different algorithms and their use cases\nCaching Strategies: When and how to use caching effectively\n\n# Example: Simple load balancer implementation\nclass RoundRobinLoadBalancer:\n    def __init__(self, servers):\n        self.servers = servers\n        self.current_index = 0\n    \n    def get_next_server(self):\n        server = self.servers[self.current_index]\n        self.current_index = (self.current_index + 1) % len(self.servers)\n        return server\n\n\n\n\nACID Properties: Understanding transaction guarantees\nCAP Theorem: Consistency, Availability, Partition Tolerance trade-offs\nDatabase Types: Relational vs NoSQL, when to use each\n\n\n\n\n\nHTTP vs HTTPS: Security and performance implications\nREST vs gRPC: API design patterns\nCDN: Content delivery optimization\n\n\n\n\n\nOnce I had the fundamentals, I moved to architectural patterns:\n\n\n\nService Decomposition: How to break down monolithic applications\nService Communication: Synchronous vs asynchronous patterns\nData Management: Database per service vs shared database\n\n# Example: Circuit breaker pattern for service communication\nclass CircuitBreaker:\n    def __init__(self, failure_threshold=5, timeout=60):\n        self.failure_threshold = failure_threshold\n        self.timeout = timeout\n        self.failure_count = 0\n        self.last_failure_time = None\n        self.state = 'CLOSED'\n    \n    def call(self, func, *args, **kwargs):\n        if self.state == 'OPEN':\n            if time.time() - self.last_failure_time &gt; self.timeout:\n                self.state = 'HALF_OPEN'\n            else:\n                raise Exception(\"Circuit breaker is OPEN\")\n        \n        try:\n            result = func(*args, **kwargs)\n            if self.state == 'HALF_OPEN':\n                self.state = 'CLOSED'\n                self.failure_count = 0\n            return result\n        except Exception as e:\n            self.failure_count += 1\n            self.last_failure_time = time.time()\n            \n            if self.failure_count &gt;= self.failure_threshold:\n                self.state = 'OPEN'\n            \n            raise e\n\n\n\n\nEvent Sourcing: Storing events instead of state\nCQRS: Command Query Responsibility Segregation\nMessage Queues: Apache Kafka, RabbitMQ patterns\n\n\n\n\n\nRead Replicas: Scaling read operations\nSharding: Horizontal data partitioning\nCaching Layers: Application, database, and CDN caching\n\n\n\n\n\nThe final phase focused on complex distributed systems:\n\n\n\nPaxos and Raft: Understanding distributed consensus\nLeader Election: Handling node failures\nReplication: Ensuring data consistency\n\n\n\n\n\nLatency vs Throughput: Understanding performance metrics\nBottleneck Identification: Finding and fixing performance issues\nMonitoring and Observability: Tools and techniques\n\n\n\n\n\nAuthentication and Authorization: Securing distributed systems\nFault Tolerance: Handling failures gracefully\nDisaster Recovery: Backup and recovery strategies\n\n\n\n\n\n\n\n\nI analyzed real-world system designs from companies like: - Netflix: Microservices and chaos engineering - Uber: Real-time data processing - Airbnb: Scalable booking systems - Google: Distributed databases (Spanner)\n\n\n\nBuilding small-scale distributed systems helped me understand the challenges:\n# Example: Simple distributed cache implementation\nclass DistributedCache:\n    def __init__(self, nodes):\n        self.nodes = nodes\n        self.consistent_hash = ConsistentHash(nodes)\n    \n    def get(self, key):\n        node = self.consistent_hash.get_node(key)\n        return node.get(key)\n    \n    def set(self, key, value):\n        node = self.consistent_hash.get_node(key)\n        return node.set(key, value)\n\n\n\nRegular mock interviews helped me: - Structure My Thinking: Following a systematic approach - Communicate Clearly: Explaining complex concepts simply - Handle Edge Cases: Considering failure scenarios - Time Management: Completing designs within time limits\n\n\n\n\n\n\n\n“Designing Data-Intensive Applications” by Martin Kleppmann\n“System Design Interview” by Alex Xu\n“Building Microservices” by Sam Newman\n\n\n\n\n\nHigh Scalability: Real-world architecture examples\nAWS Architecture Center: Cloud-specific patterns\nMartin Fowler’s Blog: Software architecture insights\n\n\n\n\n\nGrokking the System Design Interview\nSystem Design Primer (GitHub)\nInterviewBit System Design\n\n\n\n\n\n\n\n\nStart simple and add complexity as needed\nDon’t solve problems you don’t have\nFocus on the core requirements first\n\n\n\n\n\nAlways consider scalability, availability, and performance\nAsk clarifying questions about requirements\nMake trade-offs explicit\n\n\n\n\n\nDraw diagrams to visualize your design\nExplain your reasoning and trade-offs\nBe ready to iterate based on feedback\n\n\n\n\n\nAfter completing this learning path, I’m now focusing on:\n\n\n\nKubernetes: Container orchestration and microservices\nApache Kafka: Event streaming and real-time processing\nRedis: Advanced caching patterns and data structures\n\n\n\n\n\nBuilding scalable web applications\nImplementing microservices architectures\nWorking with cloud platforms (AWS, GCP)\n\n\n\n\n\nWriting blog posts about system design\nContributing to open source projects\nMentoring others in their learning journey\n\n\n\n\n\n\n\nDon’t rush into complex topics. Build a strong foundation first.\n\n\n\nSystem design is a skill that improves with practice. Do mock interviews and build projects.\n\n\n\nStudy how companies like Netflix, Uber, and Google solve real problems.\n\n\n\nEvery design decision involves trade-offs. Understand and communicate them clearly.\n\n\n\nTechnology evolves quickly. Keep learning about new patterns and tools.\n\n\n\n\nLearning system design is a journey, not a destination. The field is constantly evolving, and there’s always more to learn. The key is to approach it systematically, practice regularly, and learn from both successes and failures.\nMy learning path has been challenging but incredibly rewarding. I’ve gained a deeper understanding of how large-scale systems work, and I’m excited to continue learning and growing in this area.\nIf you’re on a similar journey, I’d love to hear about your experiences and learn from your insights. Feel free to reach out and share your own learning path!\n\nWhat’s your system design learning journey been like? What resources or approaches have been most helpful for you? Share your thoughts in the comments below!"
  },
  {
    "objectID": "blog/system-design-learning-path.html#why-system-design-matters",
    "href": "blog/system-design-learning-path.html#why-system-design-matters",
    "title": "My System Design Learning Path",
    "section": "",
    "text": "System design interviews are a crucial part of the software engineering interview process, especially for senior positions. But beyond interviews, understanding system design principles is essential for:\n\nBuilding Scalable Applications: Understanding how to handle growth\nMaking Architectural Decisions: Choosing the right patterns and technologies\nDebugging Distributed Systems: Identifying bottlenecks and failure points\nCollaborating with Teams: Communicating design decisions effectively"
  },
  {
    "objectID": "blog/system-design-learning-path.html#my-learning-approach",
    "href": "blog/system-design-learning-path.html#my-learning-approach",
    "title": "My System Design Learning Path",
    "section": "",
    "text": "I started with the basics to build a strong foundation:\n\n\n\nVertical vs Horizontal Scaling: Understanding the difference and trade-offs\nLoad Balancing: Different algorithms and their use cases\nCaching Strategies: When and how to use caching effectively\n\n# Example: Simple load balancer implementation\nclass RoundRobinLoadBalancer:\n    def __init__(self, servers):\n        self.servers = servers\n        self.current_index = 0\n    \n    def get_next_server(self):\n        server = self.servers[self.current_index]\n        self.current_index = (self.current_index + 1) % len(self.servers)\n        return server\n\n\n\n\nACID Properties: Understanding transaction guarantees\nCAP Theorem: Consistency, Availability, Partition Tolerance trade-offs\nDatabase Types: Relational vs NoSQL, when to use each\n\n\n\n\n\nHTTP vs HTTPS: Security and performance implications\nREST vs gRPC: API design patterns\nCDN: Content delivery optimization\n\n\n\n\n\nOnce I had the fundamentals, I moved to architectural patterns:\n\n\n\nService Decomposition: How to break down monolithic applications\nService Communication: Synchronous vs asynchronous patterns\nData Management: Database per service vs shared database\n\n# Example: Circuit breaker pattern for service communication\nclass CircuitBreaker:\n    def __init__(self, failure_threshold=5, timeout=60):\n        self.failure_threshold = failure_threshold\n        self.timeout = timeout\n        self.failure_count = 0\n        self.last_failure_time = None\n        self.state = 'CLOSED'\n    \n    def call(self, func, *args, **kwargs):\n        if self.state == 'OPEN':\n            if time.time() - self.last_failure_time &gt; self.timeout:\n                self.state = 'HALF_OPEN'\n            else:\n                raise Exception(\"Circuit breaker is OPEN\")\n        \n        try:\n            result = func(*args, **kwargs)\n            if self.state == 'HALF_OPEN':\n                self.state = 'CLOSED'\n                self.failure_count = 0\n            return result\n        except Exception as e:\n            self.failure_count += 1\n            self.last_failure_time = time.time()\n            \n            if self.failure_count &gt;= self.failure_threshold:\n                self.state = 'OPEN'\n            \n            raise e\n\n\n\n\nEvent Sourcing: Storing events instead of state\nCQRS: Command Query Responsibility Segregation\nMessage Queues: Apache Kafka, RabbitMQ patterns\n\n\n\n\n\nRead Replicas: Scaling read operations\nSharding: Horizontal data partitioning\nCaching Layers: Application, database, and CDN caching\n\n\n\n\n\nThe final phase focused on complex distributed systems:\n\n\n\nPaxos and Raft: Understanding distributed consensus\nLeader Election: Handling node failures\nReplication: Ensuring data consistency\n\n\n\n\n\nLatency vs Throughput: Understanding performance metrics\nBottleneck Identification: Finding and fixing performance issues\nMonitoring and Observability: Tools and techniques\n\n\n\n\n\nAuthentication and Authorization: Securing distributed systems\nFault Tolerance: Handling failures gracefully\nDisaster Recovery: Backup and recovery strategies"
  },
  {
    "objectID": "blog/system-design-learning-path.html#practical-learning-methods",
    "href": "blog/system-design-learning-path.html#practical-learning-methods",
    "title": "My System Design Learning Path",
    "section": "",
    "text": "I analyzed real-world system designs from companies like: - Netflix: Microservices and chaos engineering - Uber: Real-time data processing - Airbnb: Scalable booking systems - Google: Distributed databases (Spanner)\n\n\n\nBuilding small-scale distributed systems helped me understand the challenges:\n# Example: Simple distributed cache implementation\nclass DistributedCache:\n    def __init__(self, nodes):\n        self.nodes = nodes\n        self.consistent_hash = ConsistentHash(nodes)\n    \n    def get(self, key):\n        node = self.consistent_hash.get_node(key)\n        return node.get(key)\n    \n    def set(self, key, value):\n        node = self.consistent_hash.get_node(key)\n        return node.set(key, value)\n\n\n\nRegular mock interviews helped me: - Structure My Thinking: Following a systematic approach - Communicate Clearly: Explaining complex concepts simply - Handle Edge Cases: Considering failure scenarios - Time Management: Completing designs within time limits"
  },
  {
    "objectID": "blog/system-design-learning-path.html#key-resources",
    "href": "blog/system-design-learning-path.html#key-resources",
    "title": "My System Design Learning Path",
    "section": "",
    "text": "“Designing Data-Intensive Applications” by Martin Kleppmann\n“System Design Interview” by Alex Xu\n“Building Microservices” by Sam Newman\n\n\n\n\n\nHigh Scalability: Real-world architecture examples\nAWS Architecture Center: Cloud-specific patterns\nMartin Fowler’s Blog: Software architecture insights\n\n\n\n\n\nGrokking the System Design Interview\nSystem Design Primer (GitHub)\nInterviewBit System Design"
  },
  {
    "objectID": "blog/system-design-learning-path.html#common-mistakes-to-avoid",
    "href": "blog/system-design-learning-path.html#common-mistakes-to-avoid",
    "title": "My System Design Learning Path",
    "section": "",
    "text": "Start simple and add complexity as needed\nDon’t solve problems you don’t have\nFocus on the core requirements first\n\n\n\n\n\nAlways consider scalability, availability, and performance\nAsk clarifying questions about requirements\nMake trade-offs explicit\n\n\n\n\n\nDraw diagrams to visualize your design\nExplain your reasoning and trade-offs\nBe ready to iterate based on feedback"
  },
  {
    "objectID": "blog/system-design-learning-path.html#my-current-focus",
    "href": "blog/system-design-learning-path.html#my-current-focus",
    "title": "My System Design Learning Path",
    "section": "",
    "text": "After completing this learning path, I’m now focusing on:\n\n\n\nKubernetes: Container orchestration and microservices\nApache Kafka: Event streaming and real-time processing\nRedis: Advanced caching patterns and data structures\n\n\n\n\n\nBuilding scalable web applications\nImplementing microservices architectures\nWorking with cloud platforms (AWS, GCP)\n\n\n\n\n\nWriting blog posts about system design\nContributing to open source projects\nMentoring others in their learning journey"
  },
  {
    "objectID": "blog/system-design-learning-path.html#tips-for-success",
    "href": "blog/system-design-learning-path.html#tips-for-success",
    "title": "My System Design Learning Path",
    "section": "",
    "text": "Don’t rush into complex topics. Build a strong foundation first.\n\n\n\nSystem design is a skill that improves with practice. Do mock interviews and build projects.\n\n\n\nStudy how companies like Netflix, Uber, and Google solve real problems.\n\n\n\nEvery design decision involves trade-offs. Understand and communicate them clearly.\n\n\n\nTechnology evolves quickly. Keep learning about new patterns and tools."
  },
  {
    "objectID": "blog/system-design-learning-path.html#conclusion",
    "href": "blog/system-design-learning-path.html#conclusion",
    "title": "My System Design Learning Path",
    "section": "",
    "text": "Learning system design is a journey, not a destination. The field is constantly evolving, and there’s always more to learn. The key is to approach it systematically, practice regularly, and learn from both successes and failures.\nMy learning path has been challenging but incredibly rewarding. I’ve gained a deeper understanding of how large-scale systems work, and I’m excited to continue learning and growing in this area.\nIf you’re on a similar journey, I’d love to hear about your experiences and learn from your insights. Feel free to reach out and share your own learning path!\n\nWhat’s your system design learning journey been like? What resources or approaches have been most helpful for you? Share your thoughts in the comments below!"
  },
  {
    "objectID": "books/reading-list.html",
    "href": "books/reading-list.html",
    "title": "Reading List",
    "section": "",
    "text": "My organized list of technical books, categorized by priority and learning goals.\n\n\n\n\n\n\n\nProgress: 60% (Chapter 5: Replication)\nCategory: System Design\nPriority: High\nTarget Completion: March 2024\nKey Topics: Data models, storage engines, distributed systems\nNotes: Link to detailed notes\n\n\n\n\n\nProgress: 40% (Arrays & Strings section)\nCategory: DSA\nPriority: High\nTarget Completion: April 2024\nKey Topics: Problem-solving techniques, interview strategies\nNotes: Link to detailed notes\n\n\n\n\n\n\n\n\n\n\n\nCategory: System Design\nPriority: High\nPlanned Start: March 2024\nEstimated Duration: 6 weeks\nLearning Goals: Interview preparation, scalable architecture\nPrerequisites: Basic system design concepts\n\n\n\n\n\nCategory: Architecture\nPriority: High\nPlanned Start: April 2024\nEstimated Duration: 4 weeks\nLearning Goals: Microservices patterns, deployment strategies\nPrerequisites: Basic distributed systems knowledge\n\n\n\n\n\nCategory: DevOps\nPriority: High\nPlanned Start: May 2024\nEstimated Duration: 8 weeks\nLearning Goals: Container orchestration, cloud-native applications\nPrerequisites: Docker basics\n\n\n\n\n\n\n\n\nCategory: Programming\nPriority: Medium\nPlanned Start: June 2024\nEstimated Duration: 4 weeks\nLearning Goals: Python best practices, performance optimization\nPrerequisites: Intermediate Python knowledge\n\n\n\n\n\nCategory: Data\nPriority: Medium\nPlanned Start: July 2024\nEstimated Duration: 6 weeks\nLearning Goals: Data modeling, normalization, database design\nPrerequisites: Basic SQL knowledge\n\n\n\n\n\nCategory: DevOps\nPriority: Medium\nPlanned Start: August 2024\nEstimated Duration: 8 weeks\nLearning Goals: SRE practices, monitoring, incident response\nPrerequisites: Basic infrastructure knowledge\n\n\n\n\n\n\n\n\n\n\n\nCategory: DSA\nPriority: Medium\nPlanned Start: September 2024\nEstimated Duration: 12 weeks\nLearning Goals: Algorithm fundamentals, complexity analysis\nPrerequisites: Strong mathematical background\n\n\n\n\n\nCategory: Architecture\nPriority: Medium\nPlanned Start: December 2024\nEstimated Duration: 10 weeks\nLearning Goals: Enterprise patterns, architectural decisions\nPrerequisites: Basic design patterns knowledge\n\n\n\n\n\nCategory: Project Management\nPriority: Low\nPlanned Start: February 2025\nEstimated Duration: 3 weeks\nLearning Goals: Software project management, team dynamics\nPrerequisites: None\n\n\n\n\n\n\n\n\nCategory: Security\nPriority: Medium\nPlanned Start: March 2025\nEstimated Duration: 8 weeks\nLearning Goals: Security principles, threat modeling\nPrerequisites: Basic security concepts\n\n\n\n\n\nCategory: Data Architecture\nPriority: Low\nPlanned Start: May 2025\nEstimated Duration: 6 weeks\nLearning Goals: Modern data architecture, domain-driven design\nPrerequisites: Data engineering basics\n\n\n\n\n\n\n\n\n\n\n\nCategory: Programming\nRating: ⭐⭐⭐⭐⭐\nCompletion Date: January 2024\nKey Takeaways: Meaningful names, small functions, SOLID principles\nImpact: Improved code organization and maintainability\n\n\n\n\n\nCategory: Programming\nRating: ⭐⭐⭐⭐⭐\nCompletion Date: February 2024\nKey Takeaways: DRY principle, automation, continuous learning\nImpact: Enhanced development workflow and tool usage\n\n\n\n\n\n\n\n\nCategory: Architecture\nRating: ⭐⭐⭐⭐\nCompletion Date: November 2023\nKey Takeaways: Design patterns, object-oriented principles\nImpact: Better code structure and reusability\n\n\n\n\n\nCategory: Programming\nRating: ⭐⭐⭐⭐\nCompletion Date: October 2023\nKey Takeaways: Python idioms, advanced techniques\nImpact: More efficient Python code\n\n\n\n\n\n\n\n\n\n\n\nBooks Completed: 2/12 (17%)\nPages Read: 800/3,000 (27%)\nNotes Written: 15/50 (30%)\nProjects Built: 2/5 (40%)\n\n\n\n\n\nAverage Pages/Day: 15-20 pages\nReading Sessions: 30-60 minutes daily\nNote-taking Time: 10-15 minutes per session\nImplementation Time: 2-3 hours per week\n\n\n\n\n\n\n\n\n\n\n\nCurrent Project Needs: Books directly relevant to work\nInterview Preparation: Essential for career advancement\nSkill Gaps: Areas where I need immediate improvement\nIndustry Trends: Emerging technologies and practices\n\n\n\n\n\nCareer Development: Long-term skill building\nTechnology Exploration: New areas of interest\nBest Practices: Improving existing knowledge\nReference Materials: Books to consult as needed\n\n\n\n\n\nPersonal Interest: Topics I’m curious about\nClassic Literature: Timeless books for general knowledge\nSpecialized Topics: Niche areas for future exploration\nRecreational Reading: Less technical, more conceptual\n\n\n\n\n\n\nIdentify Need: Current project or skill gap\nResearch Options: Read reviews, check recommendations\nEvaluate Fit: Match with learning goals and timeline\nPlan Reading: Schedule and estimate duration\nTrack Progress: Monitor completion and understanding\n\n\n\n\n\n\n\n\n\n\nKindle: Primary e-reader for digital books\nO’Reilly Learning: Online platform with technical books\nSafari Books Online: Additional technical book access\nPDF Reader: For books available in PDF format\n\n\n\n\n\nNotion: Primary note-taking and organization\nObsidian: For linked notes and knowledge graphs\nGitHub: Code examples and implementations\nPhysical Notebook: Quick sketches and diagrams\n\n\n\n\n\nVS Code: Code editor for examples\nGitHub: Repository for projects and examples\nDocker: Container environment for testing\nCloud Platforms: AWS/GCP for infrastructure practice\n\n\n\n\n\n\n\n\nMorning: 30-45 minutes before work\nLunch: 15-20 minutes during break\nEvening: 30-60 minutes after work\nWeekend: 2-3 hours for deep reading\n\n\n\n\n\nPages: 100-150 pages per week\nNotes: 5-10 detailed notes\nPractice: 1-2 implementation sessions\nReview: 30 minutes reviewing previous notes\n\n\n\n\n\n\n\n\n\n\n\nBooks Completed: 12 technical books\nPages Read: 3,000+ pages\nNotes Written: 50+ detailed notes\nProjects Built: 5+ implementations\nConcepts Mastered: 25+ key concepts\n\n\n\n\n\nBooks Started: 1-2 new books\nBooks Completed: 1 book per month\nNotes Written: 8-10 notes per month\nPractice Sessions: 4-6 implementation sessions\n\n\n\n\n\n\n\n\nDeep Comprehension: Can explain concepts to others\nPractical Application: Use knowledge in real projects\nCritical Thinking: Evaluate different approaches\nProblem Solving: Apply patterns to new situations\n\n\n\n\n\nSystem Design: Design scalable architectures\nDSA: Solve complex algorithmic problems\nProgramming: Write clean, maintainable code\nDevOps: Deploy and manage applications\n\n\n\n\n\n\n\n\n\nLocal Meetups: Monthly book discussion groups\nOnline Forums: Reddit r/learnprogramming book clubs\nDiscord Groups: Technical book study channels\nMentorship: Teaching others while learning\n\n\n\n\n\nBlog Posts: Monthly book reviews and summaries\nCode Examples: GitHub repositories with implementations\nVideo Content: Explaining concepts to others\nPresentations: Sharing learnings with teams\n\n\n\n\n\n\n\nReading Tips\n\n\n\n\nSet Realistic Goals: Don’t overwhelm yourself with too many books\nTake Regular Breaks: Avoid burnout with consistent but manageable pace\nPractice Implementation: Code examples and build projects\nReview Regularly: Revisit notes to reinforce learning\nShare Knowledge: Discuss concepts with others\n\n\n\n\n\n\n\n\n\nCommon Pitfalls\n\n\n\n\nOverwhelming: Trying to read too many books simultaneously\nPassive Reading: Not engaging actively with the material\nNo Practice: Reading without implementation\nIsolation: Learning without community discussion\nPerfectionism: Getting stuck on one book for too long",
    "crumbs": [
      "Books",
      "Reading List"
    ]
  },
  {
    "objectID": "books/reading-list.html#currently-reading",
    "href": "books/reading-list.html#currently-reading",
    "title": "Reading List",
    "section": "",
    "text": "Progress: 60% (Chapter 5: Replication)\nCategory: System Design\nPriority: High\nTarget Completion: March 2024\nKey Topics: Data models, storage engines, distributed systems\nNotes: Link to detailed notes\n\n\n\n\n\nProgress: 40% (Arrays & Strings section)\nCategory: DSA\nPriority: High\nTarget Completion: April 2024\nKey Topics: Problem-solving techniques, interview strategies\nNotes: Link to detailed notes",
    "crumbs": [
      "Books",
      "Reading List"
    ]
  },
  {
    "objectID": "books/reading-list.html#upcoming-books-next-3-months",
    "href": "books/reading-list.html#upcoming-books-next-3-months",
    "title": "Reading List",
    "section": "",
    "text": "Category: System Design\nPriority: High\nPlanned Start: March 2024\nEstimated Duration: 6 weeks\nLearning Goals: Interview preparation, scalable architecture\nPrerequisites: Basic system design concepts\n\n\n\n\n\nCategory: Architecture\nPriority: High\nPlanned Start: April 2024\nEstimated Duration: 4 weeks\nLearning Goals: Microservices patterns, deployment strategies\nPrerequisites: Basic distributed systems knowledge\n\n\n\n\n\nCategory: DevOps\nPriority: High\nPlanned Start: May 2024\nEstimated Duration: 8 weeks\nLearning Goals: Container orchestration, cloud-native applications\nPrerequisites: Docker basics\n\n\n\n\n\n\n\n\nCategory: Programming\nPriority: Medium\nPlanned Start: June 2024\nEstimated Duration: 4 weeks\nLearning Goals: Python best practices, performance optimization\nPrerequisites: Intermediate Python knowledge\n\n\n\n\n\nCategory: Data\nPriority: Medium\nPlanned Start: July 2024\nEstimated Duration: 6 weeks\nLearning Goals: Data modeling, normalization, database design\nPrerequisites: Basic SQL knowledge\n\n\n\n\n\nCategory: DevOps\nPriority: Medium\nPlanned Start: August 2024\nEstimated Duration: 8 weeks\nLearning Goals: SRE practices, monitoring, incident response\nPrerequisites: Basic infrastructure knowledge",
    "crumbs": [
      "Books",
      "Reading List"
    ]
  },
  {
    "objectID": "books/reading-list.html#long-term-reading-plan-6-12-months",
    "href": "books/reading-list.html#long-term-reading-plan-6-12-months",
    "title": "Reading List",
    "section": "",
    "text": "Category: DSA\nPriority: Medium\nPlanned Start: September 2024\nEstimated Duration: 12 weeks\nLearning Goals: Algorithm fundamentals, complexity analysis\nPrerequisites: Strong mathematical background\n\n\n\n\n\nCategory: Architecture\nPriority: Medium\nPlanned Start: December 2024\nEstimated Duration: 10 weeks\nLearning Goals: Enterprise patterns, architectural decisions\nPrerequisites: Basic design patterns knowledge\n\n\n\n\n\nCategory: Project Management\nPriority: Low\nPlanned Start: February 2025\nEstimated Duration: 3 weeks\nLearning Goals: Software project management, team dynamics\nPrerequisites: None\n\n\n\n\n\n\n\n\nCategory: Security\nPriority: Medium\nPlanned Start: March 2025\nEstimated Duration: 8 weeks\nLearning Goals: Security principles, threat modeling\nPrerequisites: Basic security concepts\n\n\n\n\n\nCategory: Data Architecture\nPriority: Low\nPlanned Start: May 2025\nEstimated Duration: 6 weeks\nLearning Goals: Modern data architecture, domain-driven design\nPrerequisites: Data engineering basics",
    "crumbs": [
      "Books",
      "Reading List"
    ]
  },
  {
    "objectID": "books/reading-list.html#completed-books",
    "href": "books/reading-list.html#completed-books",
    "title": "Reading List",
    "section": "",
    "text": "Category: Programming\nRating: ⭐⭐⭐⭐⭐\nCompletion Date: January 2024\nKey Takeaways: Meaningful names, small functions, SOLID principles\nImpact: Improved code organization and maintainability\n\n\n\n\n\nCategory: Programming\nRating: ⭐⭐⭐⭐⭐\nCompletion Date: February 2024\nKey Takeaways: DRY principle, automation, continuous learning\nImpact: Enhanced development workflow and tool usage\n\n\n\n\n\n\n\n\nCategory: Architecture\nRating: ⭐⭐⭐⭐\nCompletion Date: November 2023\nKey Takeaways: Design patterns, object-oriented principles\nImpact: Better code structure and reusability\n\n\n\n\n\nCategory: Programming\nRating: ⭐⭐⭐⭐\nCompletion Date: October 2023\nKey Takeaways: Python idioms, advanced techniques\nImpact: More efficient Python code",
    "crumbs": [
      "Books",
      "Reading List"
    ]
  },
  {
    "objectID": "books/reading-list.html#reading-statistics",
    "href": "books/reading-list.html#reading-statistics",
    "title": "Reading List",
    "section": "",
    "text": "Books Completed: 2/12 (17%)\nPages Read: 800/3,000 (27%)\nNotes Written: 15/50 (30%)\nProjects Built: 2/5 (40%)\n\n\n\n\n\nAverage Pages/Day: 15-20 pages\nReading Sessions: 30-60 minutes daily\nNote-taking Time: 10-15 minutes per session\nImplementation Time: 2-3 hours per week",
    "crumbs": [
      "Books",
      "Reading List"
    ]
  },
  {
    "objectID": "books/reading-list.html#book-selection-criteria",
    "href": "books/reading-list.html#book-selection-criteria",
    "title": "Reading List",
    "section": "",
    "text": "Current Project Needs: Books directly relevant to work\nInterview Preparation: Essential for career advancement\nSkill Gaps: Areas where I need immediate improvement\nIndustry Trends: Emerging technologies and practices\n\n\n\n\n\nCareer Development: Long-term skill building\nTechnology Exploration: New areas of interest\nBest Practices: Improving existing knowledge\nReference Materials: Books to consult as needed\n\n\n\n\n\nPersonal Interest: Topics I’m curious about\nClassic Literature: Timeless books for general knowledge\nSpecialized Topics: Niche areas for future exploration\nRecreational Reading: Less technical, more conceptual\n\n\n\n\n\n\nIdentify Need: Current project or skill gap\nResearch Options: Read reviews, check recommendations\nEvaluate Fit: Match with learning goals and timeline\nPlan Reading: Schedule and estimate duration\nTrack Progress: Monitor completion and understanding",
    "crumbs": [
      "Books",
      "Reading List"
    ]
  },
  {
    "objectID": "books/reading-list.html#reading-environment-setup",
    "href": "books/reading-list.html#reading-environment-setup",
    "title": "Reading List",
    "section": "",
    "text": "Kindle: Primary e-reader for digital books\nO’Reilly Learning: Online platform with technical books\nSafari Books Online: Additional technical book access\nPDF Reader: For books available in PDF format\n\n\n\n\n\nNotion: Primary note-taking and organization\nObsidian: For linked notes and knowledge graphs\nGitHub: Code examples and implementations\nPhysical Notebook: Quick sketches and diagrams\n\n\n\n\n\nVS Code: Code editor for examples\nGitHub: Repository for projects and examples\nDocker: Container environment for testing\nCloud Platforms: AWS/GCP for infrastructure practice\n\n\n\n\n\n\n\n\nMorning: 30-45 minutes before work\nLunch: 15-20 minutes during break\nEvening: 30-60 minutes after work\nWeekend: 2-3 hours for deep reading\n\n\n\n\n\nPages: 100-150 pages per week\nNotes: 5-10 detailed notes\nPractice: 1-2 implementation sessions\nReview: 30 minutes reviewing previous notes",
    "crumbs": [
      "Books",
      "Reading List"
    ]
  },
  {
    "objectID": "books/reading-list.html#success-metrics",
    "href": "books/reading-list.html#success-metrics",
    "title": "Reading List",
    "section": "",
    "text": "Books Completed: 12 technical books\nPages Read: 3,000+ pages\nNotes Written: 50+ detailed notes\nProjects Built: 5+ implementations\nConcepts Mastered: 25+ key concepts\n\n\n\n\n\nBooks Started: 1-2 new books\nBooks Completed: 1 book per month\nNotes Written: 8-10 notes per month\nPractice Sessions: 4-6 implementation sessions\n\n\n\n\n\n\n\n\nDeep Comprehension: Can explain concepts to others\nPractical Application: Use knowledge in real projects\nCritical Thinking: Evaluate different approaches\nProblem Solving: Apply patterns to new situations\n\n\n\n\n\nSystem Design: Design scalable architectures\nDSA: Solve complex algorithmic problems\nProgramming: Write clean, maintainable code\nDevOps: Deploy and manage applications",
    "crumbs": [
      "Books",
      "Reading List"
    ]
  },
  {
    "objectID": "books/reading-list.html#community-accountability",
    "href": "books/reading-list.html#community-accountability",
    "title": "Reading List",
    "section": "",
    "text": "Local Meetups: Monthly book discussion groups\nOnline Forums: Reddit r/learnprogramming book clubs\nDiscord Groups: Technical book study channels\nMentorship: Teaching others while learning\n\n\n\n\n\nBlog Posts: Monthly book reviews and summaries\nCode Examples: GitHub repositories with implementations\nVideo Content: Explaining concepts to others\nPresentations: Sharing learnings with teams\n\n\n\n\n\n\n\nReading Tips\n\n\n\n\nSet Realistic Goals: Don’t overwhelm yourself with too many books\nTake Regular Breaks: Avoid burnout with consistent but manageable pace\nPractice Implementation: Code examples and build projects\nReview Regularly: Revisit notes to reinforce learning\nShare Knowledge: Discuss concepts with others\n\n\n\n\n\n\n\n\n\nCommon Pitfalls\n\n\n\n\nOverwhelming: Trying to read too many books simultaneously\nPassive Reading: Not engaging actively with the material\nNo Practice: Reading without implementation\nIsolation: Learning without community discussion\nPerfectionism: Getting stuck on one book for too long",
    "crumbs": [
      "Books",
      "Reading List"
    ]
  },
  {
    "objectID": "books/notes.html",
    "href": "books/notes.html",
    "title": "Book Notes",
    "section": "",
    "text": "Detailed notes and summaries from my technical book readings.\n\n\n\n\nProgress: 60% (Chapter 5: Replication)\nCategory: System Design\nRating: ⭐⭐⭐⭐⭐ (so far)\n\n\nKey Concepts: - Reliability: System continues working correctly despite faults - Scalability: System can handle increased load gracefully - Maintainability: System can be modified and operated easily\nImportant Points: - Faults vs Failures: Faults are component failures, failures are system-wide - Scalability Metrics: Throughput (requests/second) and response time - Maintainability Factors: Operability, simplicity, evolvability\nCode Example:\n# Example: Fault-tolerant service\nclass FaultTolerantService:\n    def __init__(self, primary_service, backup_service):\n        self.primary = primary_service\n        self.backup = backup_service\n        self.current = self.primary\n    \n    def handle_request(self, request):\n        try:\n            return self.current.process(request)\n        except ServiceUnavailableError:\n            # Failover to backup\n            self.current = self.backup\n            return self.current.process(request)\n\n\n\nKey Concepts: - Relational Model: Tables with relationships, SQL queries - Document Model: Self-contained documents, hierarchical data - Graph Model: Entities and relationships, complex queries\nTrade-offs: - Relational: ACID transactions, complex queries, schema flexibility - Document: Schema flexibility, locality, complex queries harder - Graph: Complex relationships, query complexity, scaling challenges\nPractical Application:\n-- Relational: User with multiple addresses\nCREATE TABLE users (\n    id INT PRIMARY KEY,\n    name VARCHAR(100),\n    email VARCHAR(100)\n);\n\nCREATE TABLE addresses (\n    id INT PRIMARY KEY,\n    user_id INT,\n    street VARCHAR(200),\n    city VARCHAR(100),\n    FOREIGN KEY (user_id) REFERENCES users(id)\n);\n\n-- Document: User with embedded addresses\n{\n    \"id\": 123,\n    \"name\": \"John Doe\",\n    \"email\": \"john@example.com\",\n    \"addresses\": [\n        {\"street\": \"123 Main St\", \"city\": \"New York\"},\n        {\"street\": \"456 Oak Ave\", \"city\": \"Los Angeles\"}\n    ]\n}\n\n\n\nKey Concepts: - B-tree: Balanced tree structure, good for range queries - LSM-tree: Log-structured merge tree, high write throughput - Hash Indexes: Key-value lookups, no range queries\nPerformance Characteristics: - B-tree: O(log n) reads and writes, good for mixed workloads - LSM-tree: O(log n) reads, O(1) writes, write-optimized - Hash Index: O(1) reads and writes, no range queries\nImplementation Example:\n# Simple B-tree implementation concept\nclass BTreeNode:\n    def __init__(self, leaf=True):\n        self.leaf = leaf\n        self.keys = []\n        self.children = []\n        self.values = []\n\nclass BTree:\n    def __init__(self, t=3):\n        self.root = BTreeNode()\n        self.t = t  # minimum degree\n    \n    def search(self, key, node=None):\n        if node is None:\n            node = self.root\n        \n        i = 0\n        while i &lt; len(node.keys) and key &gt; node.keys[i]:\n            i += 1\n        \n        if i &lt; len(node.keys) and node.keys[i] == key:\n            return node.values[i]\n        \n        if node.leaf:\n            return None\n        \n        return self.search(key, node.children[i])\n\n\n\nKey Concepts: - Schema Evolution: Handling data format changes over time - Backward Compatibility: New code can read old data - Forward Compatibility: Old code can read new data\nEncoding Formats: - JSON: Human-readable, schema-less, verbose - Protocol Buffers: Binary, schema-based, efficient - Avro: Schema evolution, binary format\nSchema Evolution Example:\n// Protocol Buffer schema evolution\nmessage User {\n    string id = 1;\n    string name = 2;\n    string email = 3;\n    // New field added - optional for backward compatibility\n    optional string phone = 4;\n}\n\n// Migration strategy\ndef migrate_user_data(old_user, new_schema):\n    new_user = {\n        'id': old_user.get('id'),\n        'name': old_user.get('name'),\n        'email': old_user.get('email'),\n        'phone': old_user.get('phone', '')  # Default value\n    }\n    return new_user\n\n\n\nKey Concepts: - Leader-Follower Replication: Single leader, multiple followers - Multi-Leader Replication: Multiple leaders, conflict resolution - Leaderless Replication: No single leader, quorum-based\nConsistency Models: - Synchronous: Wait for all replicas to confirm - Asynchronous: Don’t wait for replica confirmation - Semi-synchronous: Wait for some replicas\n\n\n\n\n\nProgress: 40% (Arrays & Strings section)\nCategory: DSA\nRating: ⭐⭐⭐⭐⭐\n\n\nKey Techniques: - Two Pointers: Efficient array traversal and manipulation - Sliding Window: Contiguous subarray problems - Hash Tables: O(1) lookups for frequency counting\nCommon Patterns:\n# Two Pointers - Two Sum in sorted array\ndef two_sum_sorted(arr, target):\n    left, right = 0, len(arr) - 1\n    while left &lt; right:\n        current_sum = arr[left] + arr[right]\n        if current_sum == target:\n            return [left, right]\n        elif current_sum &lt; target:\n            left += 1\n        else:\n            right -= 1\n    return []\n\n# Sliding Window - Longest substring without repeating characters\ndef longest_substring(s):\n    char_map = {}\n    left = 0\n    max_length = 0\n    \n    for right, char in enumerate(s):\n        if char in char_map and char_map[char] &gt;= left:\n            left = char_map[char] + 1\n        char_map[char] = right\n        max_length = max(max_length, right - left + 1)\n    \n    return max_length\n\n# Hash Table - Character frequency\ndef is_anagram(s, t):\n    if len(s) != len(t):\n        return False\n    \n    char_count = {}\n    for char in s:\n        char_count[char] = char_count.get(char, 0) + 1\n    \n    for char in t:\n        if char not in char_count or char_count[char] == 0:\n            return False\n        char_count[char] -= 1\n    \n    return True\n\n\n\nKey Techniques: - Fast/Slow Pointers: Detect cycles, find middle - Reversing: Iterative and recursive approaches - Merging: Combine sorted lists efficiently\nCommon Patterns:\nclass ListNode:\n    def __init__(self, val=0, next=None):\n        self.val = val\n        self.next = next\n\n# Fast/Slow Pointers - Detect cycle\ndef has_cycle(head):\n    if not head or not head.next:\n        return False\n    \n    slow = fast = head\n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n        if slow == fast:\n            return True\n    \n    return False\n\n# Reverse Linked List\ndef reverse_list(head):\n    prev = None\n    curr = head\n    \n    while curr:\n        next_temp = curr.next\n        curr.next = prev\n        prev = curr\n        curr = next_temp\n    \n    return prev\n\n# Merge Two Sorted Lists\ndef merge_two_lists(l1, l2):\n    dummy = ListNode(0)\n    current = dummy\n    \n    while l1 and l2:\n        if l1.val &lt;= l2.val:\n            current.next = l1\n            l1 = l1.next\n        else:\n            current.next = l2\n            l2 = l2.next\n        current = current.next\n    \n    current.next = l1 if l1 else l2\n    return dummy.next\n\n\n\n\n\n\n\nCategory: Programming\nRating: ⭐⭐⭐⭐⭐\nCompletion Date: January 2024\n\n\nMeaningful Names: - Use intention-revealing names - Avoid disinformation and abbreviations - Make names pronounceable and searchable - Use consistent naming conventions\nFunctions: - Keep functions small (ideally &lt; 20 lines) - Do one thing well - Use descriptive names - Minimize arguments (0-3 is ideal)\nCode Example:\n# Bad: Unclear names and long function\ndef process_data(data):\n    result = []\n    for item in data:\n        if item['status'] == 'active' and item['age'] &gt; 18:\n            result.append({\n                'name': item['name'],\n                'score': item['score'] * 1.1\n            })\n    return result\n\n# Good: Clear names and small functions\ndef get_eligible_users(users):\n    return [user for user in users if is_eligible(user)]\n\ndef is_eligible(user):\n    return user['status'] == 'active' and user['age'] &gt; 18\n\ndef calculate_bonus_score(user):\n    return {\n        'name': user['name'],\n        'score': user['score'] * BONUS_MULTIPLIER\n    }\n\n\n\nSingle Responsibility Principle (SRP): - A class should have only one reason to change - Each class should have a single, well-defined purpose\nOpen/Closed Principle (OCP): - Open for extension, closed for modification - Use inheritance and polymorphism\nLiskov Substitution Principle (LSP): - Subtypes must be substitutable for their base types - Don’t violate the contract of the base class\nInterface Segregation Principle (ISP): - Clients shouldn’t depend on interfaces they don’t use - Keep interfaces small and focused\nDependency Inversion Principle (DIP): - Depend on abstractions, not concretions - High-level modules shouldn’t depend on low-level modules\n\n\n\n\nCategory: Programming\nRating: ⭐⭐⭐⭐⭐\nCompletion Date: February 2024\n\n\nDRY (Don’t Repeat Yourself): - Every piece of knowledge should have a single representation - Eliminate duplication in code, documentation, and processes\nAutomation: - Automate repetitive tasks - Use scripts for build, test, and deployment - Invest in tools that save time\nCode Example:\n# Automation example: Build script\n#!/usr/bin/env python3\nimport subprocess\nimport sys\n\ndef run_tests():\n    \"\"\"Run all tests and return success status\"\"\"\n    result = subprocess.run(['python', '-m', 'pytest'], capture_output=True)\n    return result.returncode == 0\n\ndef build_project():\n    \"\"\"Build the project\"\"\"\n    subprocess.run(['python', 'setup.py', 'build'])\n\ndef main():\n    print(\"Running tests...\")\n    if not run_tests():\n        print(\"Tests failed!\")\n        sys.exit(1)\n    \n    print(\"Building project...\")\n    build_project()\n    print(\"Build complete!\")\n\nif __name__ == \"__main__\":\n    main()\n\n\n\nOrthogonality: - Keep components independent - Changes in one component shouldn’t affect others - Use loose coupling and high cohesion\nPrototyping: - Build prototypes to explore ideas - Use prototypes to validate assumptions - Throw away prototypes, don’t evolve them into production\nTesting: - Test early, test often, test automatically - Write tests for your code - Use test-driven development (TDD)\n\n\n\n\n\n\n\n## Book: [Title]\n**Author**: [Author Name]  \n**Category**: [DSA/System Design/Programming/etc.]  \n**Status**: [Reading/Completed/Planned]  \n**Rating**: [1-5 stars]\n\n### Summary\n[2-3 sentence overview of the book]\n\n### Key Concepts\n- [Concept 1 with explanation]\n- [Concept 2 with explanation]\n- [Concept 3 with explanation]\n\n### Code Examples\n[Important code snippets and implementations]\n\n### Practical Applications\n[How to apply concepts in real projects]\n\n### Questions & Follow-up\n[Topics to explore further]\n\n### Chapter-by-Chapter Notes\n\n#### Chapter 1: [Title]\n**Key Points**:\n- [Point 1]\n- [Point 2]\n- [Point 3]\n\n**Code Examples**:\n```python\n# Example code here\nQuestions: - [Question 1] - [Question 2] ```\n\n\n\n\n\n\n\n\n\nEffective Note-Taking\n\n\n\n\nBe Selective: Focus on key concepts and insights\nUse Your Own Words: Don’t just copy, understand and rephrase\nInclude Examples: Code snippets and practical applications\nAsk Questions: Note areas that need further exploration\nConnect Ideas: Link concepts to other books and experiences\n\n\n\n\n\n\n\n\n\nCommon Mistakes\n\n\n\n\nPassive Copying: Just copying text without understanding\nToo Much Detail: Getting lost in minutiae\nNo Review: Writing notes but never revisiting them\nNo Application: Not connecting theory to practice",
    "crumbs": [
      "Books",
      "Book Notes"
    ]
  },
  {
    "objectID": "books/notes.html#currently-reading",
    "href": "books/notes.html#currently-reading",
    "title": "Book Notes",
    "section": "",
    "text": "Progress: 60% (Chapter 5: Replication)\nCategory: System Design\nRating: ⭐⭐⭐⭐⭐ (so far)\n\n\nKey Concepts: - Reliability: System continues working correctly despite faults - Scalability: System can handle increased load gracefully - Maintainability: System can be modified and operated easily\nImportant Points: - Faults vs Failures: Faults are component failures, failures are system-wide - Scalability Metrics: Throughput (requests/second) and response time - Maintainability Factors: Operability, simplicity, evolvability\nCode Example:\n# Example: Fault-tolerant service\nclass FaultTolerantService:\n    def __init__(self, primary_service, backup_service):\n        self.primary = primary_service\n        self.backup = backup_service\n        self.current = self.primary\n    \n    def handle_request(self, request):\n        try:\n            return self.current.process(request)\n        except ServiceUnavailableError:\n            # Failover to backup\n            self.current = self.backup\n            return self.current.process(request)\n\n\n\nKey Concepts: - Relational Model: Tables with relationships, SQL queries - Document Model: Self-contained documents, hierarchical data - Graph Model: Entities and relationships, complex queries\nTrade-offs: - Relational: ACID transactions, complex queries, schema flexibility - Document: Schema flexibility, locality, complex queries harder - Graph: Complex relationships, query complexity, scaling challenges\nPractical Application:\n-- Relational: User with multiple addresses\nCREATE TABLE users (\n    id INT PRIMARY KEY,\n    name VARCHAR(100),\n    email VARCHAR(100)\n);\n\nCREATE TABLE addresses (\n    id INT PRIMARY KEY,\n    user_id INT,\n    street VARCHAR(200),\n    city VARCHAR(100),\n    FOREIGN KEY (user_id) REFERENCES users(id)\n);\n\n-- Document: User with embedded addresses\n{\n    \"id\": 123,\n    \"name\": \"John Doe\",\n    \"email\": \"john@example.com\",\n    \"addresses\": [\n        {\"street\": \"123 Main St\", \"city\": \"New York\"},\n        {\"street\": \"456 Oak Ave\", \"city\": \"Los Angeles\"}\n    ]\n}\n\n\n\nKey Concepts: - B-tree: Balanced tree structure, good for range queries - LSM-tree: Log-structured merge tree, high write throughput - Hash Indexes: Key-value lookups, no range queries\nPerformance Characteristics: - B-tree: O(log n) reads and writes, good for mixed workloads - LSM-tree: O(log n) reads, O(1) writes, write-optimized - Hash Index: O(1) reads and writes, no range queries\nImplementation Example:\n# Simple B-tree implementation concept\nclass BTreeNode:\n    def __init__(self, leaf=True):\n        self.leaf = leaf\n        self.keys = []\n        self.children = []\n        self.values = []\n\nclass BTree:\n    def __init__(self, t=3):\n        self.root = BTreeNode()\n        self.t = t  # minimum degree\n    \n    def search(self, key, node=None):\n        if node is None:\n            node = self.root\n        \n        i = 0\n        while i &lt; len(node.keys) and key &gt; node.keys[i]:\n            i += 1\n        \n        if i &lt; len(node.keys) and node.keys[i] == key:\n            return node.values[i]\n        \n        if node.leaf:\n            return None\n        \n        return self.search(key, node.children[i])\n\n\n\nKey Concepts: - Schema Evolution: Handling data format changes over time - Backward Compatibility: New code can read old data - Forward Compatibility: Old code can read new data\nEncoding Formats: - JSON: Human-readable, schema-less, verbose - Protocol Buffers: Binary, schema-based, efficient - Avro: Schema evolution, binary format\nSchema Evolution Example:\n// Protocol Buffer schema evolution\nmessage User {\n    string id = 1;\n    string name = 2;\n    string email = 3;\n    // New field added - optional for backward compatibility\n    optional string phone = 4;\n}\n\n// Migration strategy\ndef migrate_user_data(old_user, new_schema):\n    new_user = {\n        'id': old_user.get('id'),\n        'name': old_user.get('name'),\n        'email': old_user.get('email'),\n        'phone': old_user.get('phone', '')  # Default value\n    }\n    return new_user\n\n\n\nKey Concepts: - Leader-Follower Replication: Single leader, multiple followers - Multi-Leader Replication: Multiple leaders, conflict resolution - Leaderless Replication: No single leader, quorum-based\nConsistency Models: - Synchronous: Wait for all replicas to confirm - Asynchronous: Don’t wait for replica confirmation - Semi-synchronous: Wait for some replicas\n\n\n\n\n\nProgress: 40% (Arrays & Strings section)\nCategory: DSA\nRating: ⭐⭐⭐⭐⭐\n\n\nKey Techniques: - Two Pointers: Efficient array traversal and manipulation - Sliding Window: Contiguous subarray problems - Hash Tables: O(1) lookups for frequency counting\nCommon Patterns:\n# Two Pointers - Two Sum in sorted array\ndef two_sum_sorted(arr, target):\n    left, right = 0, len(arr) - 1\n    while left &lt; right:\n        current_sum = arr[left] + arr[right]\n        if current_sum == target:\n            return [left, right]\n        elif current_sum &lt; target:\n            left += 1\n        else:\n            right -= 1\n    return []\n\n# Sliding Window - Longest substring without repeating characters\ndef longest_substring(s):\n    char_map = {}\n    left = 0\n    max_length = 0\n    \n    for right, char in enumerate(s):\n        if char in char_map and char_map[char] &gt;= left:\n            left = char_map[char] + 1\n        char_map[char] = right\n        max_length = max(max_length, right - left + 1)\n    \n    return max_length\n\n# Hash Table - Character frequency\ndef is_anagram(s, t):\n    if len(s) != len(t):\n        return False\n    \n    char_count = {}\n    for char in s:\n        char_count[char] = char_count.get(char, 0) + 1\n    \n    for char in t:\n        if char not in char_count or char_count[char] == 0:\n            return False\n        char_count[char] -= 1\n    \n    return True\n\n\n\nKey Techniques: - Fast/Slow Pointers: Detect cycles, find middle - Reversing: Iterative and recursive approaches - Merging: Combine sorted lists efficiently\nCommon Patterns:\nclass ListNode:\n    def __init__(self, val=0, next=None):\n        self.val = val\n        self.next = next\n\n# Fast/Slow Pointers - Detect cycle\ndef has_cycle(head):\n    if not head or not head.next:\n        return False\n    \n    slow = fast = head\n    while fast and fast.next:\n        slow = slow.next\n        fast = fast.next.next\n        if slow == fast:\n            return True\n    \n    return False\n\n# Reverse Linked List\ndef reverse_list(head):\n    prev = None\n    curr = head\n    \n    while curr:\n        next_temp = curr.next\n        curr.next = prev\n        prev = curr\n        curr = next_temp\n    \n    return prev\n\n# Merge Two Sorted Lists\ndef merge_two_lists(l1, l2):\n    dummy = ListNode(0)\n    current = dummy\n    \n    while l1 and l2:\n        if l1.val &lt;= l2.val:\n            current.next = l1\n            l1 = l1.next\n        else:\n            current.next = l2\n            l2 = l2.next\n        current = current.next\n    \n    current.next = l1 if l1 else l2\n    return dummy.next",
    "crumbs": [
      "Books",
      "Book Notes"
    ]
  },
  {
    "objectID": "books/notes.html#completed-books",
    "href": "books/notes.html#completed-books",
    "title": "Book Notes",
    "section": "",
    "text": "Category: Programming\nRating: ⭐⭐⭐⭐⭐\nCompletion Date: January 2024\n\n\nMeaningful Names: - Use intention-revealing names - Avoid disinformation and abbreviations - Make names pronounceable and searchable - Use consistent naming conventions\nFunctions: - Keep functions small (ideally &lt; 20 lines) - Do one thing well - Use descriptive names - Minimize arguments (0-3 is ideal)\nCode Example:\n# Bad: Unclear names and long function\ndef process_data(data):\n    result = []\n    for item in data:\n        if item['status'] == 'active' and item['age'] &gt; 18:\n            result.append({\n                'name': item['name'],\n                'score': item['score'] * 1.1\n            })\n    return result\n\n# Good: Clear names and small functions\ndef get_eligible_users(users):\n    return [user for user in users if is_eligible(user)]\n\ndef is_eligible(user):\n    return user['status'] == 'active' and user['age'] &gt; 18\n\ndef calculate_bonus_score(user):\n    return {\n        'name': user['name'],\n        'score': user['score'] * BONUS_MULTIPLIER\n    }\n\n\n\nSingle Responsibility Principle (SRP): - A class should have only one reason to change - Each class should have a single, well-defined purpose\nOpen/Closed Principle (OCP): - Open for extension, closed for modification - Use inheritance and polymorphism\nLiskov Substitution Principle (LSP): - Subtypes must be substitutable for their base types - Don’t violate the contract of the base class\nInterface Segregation Principle (ISP): - Clients shouldn’t depend on interfaces they don’t use - Keep interfaces small and focused\nDependency Inversion Principle (DIP): - Depend on abstractions, not concretions - High-level modules shouldn’t depend on low-level modules\n\n\n\n\nCategory: Programming\nRating: ⭐⭐⭐⭐⭐\nCompletion Date: February 2024\n\n\nDRY (Don’t Repeat Yourself): - Every piece of knowledge should have a single representation - Eliminate duplication in code, documentation, and processes\nAutomation: - Automate repetitive tasks - Use scripts for build, test, and deployment - Invest in tools that save time\nCode Example:\n# Automation example: Build script\n#!/usr/bin/env python3\nimport subprocess\nimport sys\n\ndef run_tests():\n    \"\"\"Run all tests and return success status\"\"\"\n    result = subprocess.run(['python', '-m', 'pytest'], capture_output=True)\n    return result.returncode == 0\n\ndef build_project():\n    \"\"\"Build the project\"\"\"\n    subprocess.run(['python', 'setup.py', 'build'])\n\ndef main():\n    print(\"Running tests...\")\n    if not run_tests():\n        print(\"Tests failed!\")\n        sys.exit(1)\n    \n    print(\"Building project...\")\n    build_project()\n    print(\"Build complete!\")\n\nif __name__ == \"__main__\":\n    main()\n\n\n\nOrthogonality: - Keep components independent - Changes in one component shouldn’t affect others - Use loose coupling and high cohesion\nPrototyping: - Build prototypes to explore ideas - Use prototypes to validate assumptions - Throw away prototypes, don’t evolve them into production\nTesting: - Test early, test often, test automatically - Write tests for your code - Use test-driven development (TDD)",
    "crumbs": [
      "Books",
      "Book Notes"
    ]
  },
  {
    "objectID": "books/notes.html#reading-notes-template",
    "href": "books/notes.html#reading-notes-template",
    "title": "Book Notes",
    "section": "",
    "text": "## Book: [Title]\n**Author**: [Author Name]  \n**Category**: [DSA/System Design/Programming/etc.]  \n**Status**: [Reading/Completed/Planned]  \n**Rating**: [1-5 stars]\n\n### Summary\n[2-3 sentence overview of the book]\n\n### Key Concepts\n- [Concept 1 with explanation]\n- [Concept 2 with explanation]\n- [Concept 3 with explanation]\n\n### Code Examples\n[Important code snippets and implementations]\n\n### Practical Applications\n[How to apply concepts in real projects]\n\n### Questions & Follow-up\n[Topics to explore further]\n\n### Chapter-by-Chapter Notes\n\n#### Chapter 1: [Title]\n**Key Points**:\n- [Point 1]\n- [Point 2]\n- [Point 3]\n\n**Code Examples**:\n```python\n# Example code here\nQuestions: - [Question 1] - [Question 2] ```\n\n\n\n\n\n\n\n\n\nEffective Note-Taking\n\n\n\n\nBe Selective: Focus on key concepts and insights\nUse Your Own Words: Don’t just copy, understand and rephrase\nInclude Examples: Code snippets and practical applications\nAsk Questions: Note areas that need further exploration\nConnect Ideas: Link concepts to other books and experiences\n\n\n\n\n\n\n\n\n\nCommon Mistakes\n\n\n\n\nPassive Copying: Just copying text without understanding\nToo Much Detail: Getting lost in minutiae\nNo Review: Writing notes but never revisiting them\nNo Application: Not connecting theory to practice",
    "crumbs": [
      "Books",
      "Book Notes"
    ]
  },
  {
    "objectID": "dsa/algorithms.html",
    "href": "dsa/algorithms.html",
    "title": "Algorithms",
    "section": "",
    "text": "A comprehensive guide to fundamental algorithms and problem-solving techniques.\n\n\n\n\n\nDescription: Try all possible solutions\nUse Cases: Small problem sizes, when optimal solution is needed\nExample: Generate all permutations, try all combinations\n\n# Generate all permutations\ndef permutations(nums):\n    if len(nums) &lt;= 1:\n        return [nums]\n    \n    result = []\n    for i in range(len(nums)):\n        for perm in permutations(nums[:i] + nums[i+1:]):\n            result.append([nums[i]] + perm)\n    return result\n\n\n\n\nDescription: Break problem into smaller subproblems, solve recursively, combine results\nTime Complexity: Often O(n log n)\nUse Cases: Sorting, searching, matrix multiplication\n\n# Merge Sort\ndef merge_sort(arr):\n    if len(arr) &lt;= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = merge_sort(arr[:mid])\n    right = merge_sort(arr[mid:])\n    \n    return merge(left, right)\n\ndef merge(left, right):\n    result = []\n    i = j = 0\n    \n    while i &lt; len(left) and j &lt; len(right):\n        if left[i] &lt;= right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    return result\n\n\n\n\nDescription: Solve complex problems by breaking into simpler subproblems, store results\nUse Cases: Optimization problems, counting problems, path finding\n\n# Fibonacci with memoization\ndef fibonacci(n, memo={}):\n    if n in memo:\n        return memo[n]\n    if n &lt;= 1:\n        return n\n    \n    memo[n] = fibonacci(n-1, memo) + fibonacci(n-2, memo)\n    return memo[n]\n\n# Longest Common Subsequence\ndef lcs(text1, text2):\n    m, n = len(text1), len(text2)\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\n    \n    for i in range(1, m + 1):\n        for j in range(1, n + 1):\n            if text1[i-1] == text2[j-1]:\n                dp[i][j] = dp[i-1][j-1] + 1\n            else:\n                dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n    \n    return dp[m][n]\n\n\n\n\nDescription: Make locally optimal choice at each step\nUse Cases: Scheduling, Huffman coding, minimum spanning trees\nNote: May not always give optimal solution\n\n# Activity Selection Problem\ndef activity_selection(start, finish):\n    n = len(start)\n    selected = [0]  # First activity is always selected\n    \n    j = 0\n    for i in range(1, n):\n        if start[i] &gt;= finish[j]:\n            selected.append(i)\n            j = i\n    \n    return selected\n\n\n\n\n\n\n\n\n\nTime Complexity: O(n log n) average, O(n²) worst\nSpace Complexity: O(log n)\nStability: Not stable\n\ndef quick_sort(arr):\n    if len(arr) &lt;= 1:\n        return arr\n    \n    pivot = arr[len(arr) // 2]\n    left = [x for x in arr if x &lt; pivot]\n    middle = [x for x in arr if x == pivot]\n    right = [x for x in arr if x &gt; pivot]\n    \n    return quick_sort(left) + middle + quick_sort(right)\n\n\n\n\nTime Complexity: O(n log n)\nSpace Complexity: O(n)\nStability: Stable\n\n\n\n\n\nTime Complexity: O(n log n)\nSpace Complexity: O(1)\nStability: Not stable\n\n\n\n\n\n\n\n\nTime Complexity: O(n + k) where k is range of input\nUse Cases: When range of input is not much larger than number of objects\n\ndef counting_sort(arr):\n    max_val = max(arr)\n    count = [0] * (max_val + 1)\n    \n    for num in arr:\n        count[num] += 1\n    \n    result = []\n    for i in range(len(count)):\n        result.extend([i] * count[i])\n    \n    return result\n\n\n\n\n\n\n\n\nTime Complexity: O(log n)\nPrerequisite: Array must be sorted\n\ndef binary_search(arr, target):\n    left, right = 0, len(arr) - 1\n    \n    while left &lt;= right:\n        mid = (left + right) // 2\n        if arr[mid] == target:\n            return mid\n        elif arr[mid] &lt; target:\n            left = mid + 1\n        else:\n            right = mid - 1\n    \n    return -1\n\n\n\n\n\n\n\nTime Complexity: O(V + E)\nUse Cases: Shortest path in unweighted graphs, level-order traversal\n\nfrom collections import deque\n\ndef bfs(graph, start):\n    visited = set()\n    queue = deque([start])\n    visited.add(start)\n    \n    while queue:\n        vertex = queue.popleft()\n        print(vertex, end=' ')\n        \n        for neighbor in graph[vertex]:\n            if neighbor not in visited:\n                visited.add(neighbor)\n                queue.append(neighbor)\n\n\n\n\nTime Complexity: O(V + E)\nUse Cases: Topological sorting, cycle detection, maze solving\n\ndef dfs(graph, start, visited=None):\n    if visited is None:\n        visited = set()\n    \n    visited.add(start)\n    print(start, end=' ')\n    \n    for neighbor in graph[start]:\n        if neighbor not in visited:\n            dfs(graph, neighbor, visited)\n\n\n\n\n\n\n\n\n\nTime Complexity: O(n + m) where n is text length, m is pattern length\nUse Cases: Text search, DNA sequence matching\n\ndef kmp_search(text, pattern):\n    def compute_lps(pattern):\n        lps = [0] * len(pattern)\n        length = 0\n        i = 1\n        \n        while i &lt; len(pattern):\n            if pattern[i] == pattern[length]:\n                length += 1\n                lps[i] = length\n                i += 1\n            else:\n                if length != 0:\n                    length = lps[length - 1]\n                else:\n                    lps[i] = 0\n                    i += 1\n        return lps\n    \n    lps = compute_lps(pattern)\n    i = j = 0\n    \n    while i &lt; len(text):\n        if pattern[j] == text[i]:\n            i += 1\n            j += 1\n        \n        if j == len(pattern):\n            return i - j\n        elif i &lt; len(text) and pattern[j] != text[i]:\n            if j != 0:\n                j = lps[j - 1]\n            else:\n                i += 1\n    \n    return -1\n\n\n\n\n\n\n\n\nBig O Notation: Upper bound on growth rate\nCommon Complexities: O(1), O(log n), O(n), O(n log n), O(n²), O(2ⁿ)\n\n\n\n\n\nAuxiliary Space: Extra space used by algorithm\nIn-place Algorithms: Use O(1) extra space\n\n\n\n\n\n\n\n\n\n\n\nBefore Coding\n\n\n\n\nUnderstand the problem completely\nIdentify input/output constraints\nConsider edge cases\nChoose appropriate data structure\nPlan your algorithm\n\n\n\n\n\n\n\n\n\nCommon Mistakes\n\n\n\n\nNot handling edge cases\nIncorrect time/space complexity analysis\nOver-optimizing prematurely\nNot testing with different inputs",
    "crumbs": [
      "Data Structures & Algorithms",
      "Algorithms"
    ]
  },
  {
    "objectID": "dsa/algorithms.html#algorithmic-paradigms",
    "href": "dsa/algorithms.html#algorithmic-paradigms",
    "title": "Algorithms",
    "section": "",
    "text": "Description: Try all possible solutions\nUse Cases: Small problem sizes, when optimal solution is needed\nExample: Generate all permutations, try all combinations\n\n# Generate all permutations\ndef permutations(nums):\n    if len(nums) &lt;= 1:\n        return [nums]\n    \n    result = []\n    for i in range(len(nums)):\n        for perm in permutations(nums[:i] + nums[i+1:]):\n            result.append([nums[i]] + perm)\n    return result\n\n\n\n\nDescription: Break problem into smaller subproblems, solve recursively, combine results\nTime Complexity: Often O(n log n)\nUse Cases: Sorting, searching, matrix multiplication\n\n# Merge Sort\ndef merge_sort(arr):\n    if len(arr) &lt;= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = merge_sort(arr[:mid])\n    right = merge_sort(arr[mid:])\n    \n    return merge(left, right)\n\ndef merge(left, right):\n    result = []\n    i = j = 0\n    \n    while i &lt; len(left) and j &lt; len(right):\n        if left[i] &lt;= right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    return result\n\n\n\n\nDescription: Solve complex problems by breaking into simpler subproblems, store results\nUse Cases: Optimization problems, counting problems, path finding\n\n# Fibonacci with memoization\ndef fibonacci(n, memo={}):\n    if n in memo:\n        return memo[n]\n    if n &lt;= 1:\n        return n\n    \n    memo[n] = fibonacci(n-1, memo) + fibonacci(n-2, memo)\n    return memo[n]\n\n# Longest Common Subsequence\ndef lcs(text1, text2):\n    m, n = len(text1), len(text2)\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\n    \n    for i in range(1, m + 1):\n        for j in range(1, n + 1):\n            if text1[i-1] == text2[j-1]:\n                dp[i][j] = dp[i-1][j-1] + 1\n            else:\n                dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n    \n    return dp[m][n]\n\n\n\n\nDescription: Make locally optimal choice at each step\nUse Cases: Scheduling, Huffman coding, minimum spanning trees\nNote: May not always give optimal solution\n\n# Activity Selection Problem\ndef activity_selection(start, finish):\n    n = len(start)\n    selected = [0]  # First activity is always selected\n    \n    j = 0\n    for i in range(1, n):\n        if start[i] &gt;= finish[j]:\n            selected.append(i)\n            j = i\n    \n    return selected",
    "crumbs": [
      "Data Structures & Algorithms",
      "Algorithms"
    ]
  },
  {
    "objectID": "dsa/algorithms.html#sorting-algorithms",
    "href": "dsa/algorithms.html#sorting-algorithms",
    "title": "Algorithms",
    "section": "",
    "text": "Time Complexity: O(n log n) average, O(n²) worst\nSpace Complexity: O(log n)\nStability: Not stable\n\ndef quick_sort(arr):\n    if len(arr) &lt;= 1:\n        return arr\n    \n    pivot = arr[len(arr) // 2]\n    left = [x for x in arr if x &lt; pivot]\n    middle = [x for x in arr if x == pivot]\n    right = [x for x in arr if x &gt; pivot]\n    \n    return quick_sort(left) + middle + quick_sort(right)\n\n\n\n\nTime Complexity: O(n log n)\nSpace Complexity: O(n)\nStability: Stable\n\n\n\n\n\nTime Complexity: O(n log n)\nSpace Complexity: O(1)\nStability: Not stable\n\n\n\n\n\n\n\n\nTime Complexity: O(n + k) where k is range of input\nUse Cases: When range of input is not much larger than number of objects\n\ndef counting_sort(arr):\n    max_val = max(arr)\n    count = [0] * (max_val + 1)\n    \n    for num in arr:\n        count[num] += 1\n    \n    result = []\n    for i in range(len(count)):\n        result.extend([i] * count[i])\n    \n    return result",
    "crumbs": [
      "Data Structures & Algorithms",
      "Algorithms"
    ]
  },
  {
    "objectID": "dsa/algorithms.html#searching-algorithms",
    "href": "dsa/algorithms.html#searching-algorithms",
    "title": "Algorithms",
    "section": "",
    "text": "Time Complexity: O(log n)\nPrerequisite: Array must be sorted\n\ndef binary_search(arr, target):\n    left, right = 0, len(arr) - 1\n    \n    while left &lt;= right:\n        mid = (left + right) // 2\n        if arr[mid] == target:\n            return mid\n        elif arr[mid] &lt; target:\n            left = mid + 1\n        else:\n            right = mid - 1\n    \n    return -1",
    "crumbs": [
      "Data Structures & Algorithms",
      "Algorithms"
    ]
  },
  {
    "objectID": "dsa/algorithms.html#graph-algorithms",
    "href": "dsa/algorithms.html#graph-algorithms",
    "title": "Algorithms",
    "section": "",
    "text": "Time Complexity: O(V + E)\nUse Cases: Shortest path in unweighted graphs, level-order traversal\n\nfrom collections import deque\n\ndef bfs(graph, start):\n    visited = set()\n    queue = deque([start])\n    visited.add(start)\n    \n    while queue:\n        vertex = queue.popleft()\n        print(vertex, end=' ')\n        \n        for neighbor in graph[vertex]:\n            if neighbor not in visited:\n                visited.add(neighbor)\n                queue.append(neighbor)\n\n\n\n\nTime Complexity: O(V + E)\nUse Cases: Topological sorting, cycle detection, maze solving\n\ndef dfs(graph, start, visited=None):\n    if visited is None:\n        visited = set()\n    \n    visited.add(start)\n    print(start, end=' ')\n    \n    for neighbor in graph[start]:\n        if neighbor not in visited:\n            dfs(graph, neighbor, visited)",
    "crumbs": [
      "Data Structures & Algorithms",
      "Algorithms"
    ]
  },
  {
    "objectID": "dsa/algorithms.html#string-algorithms",
    "href": "dsa/algorithms.html#string-algorithms",
    "title": "Algorithms",
    "section": "",
    "text": "Time Complexity: O(n + m) where n is text length, m is pattern length\nUse Cases: Text search, DNA sequence matching\n\ndef kmp_search(text, pattern):\n    def compute_lps(pattern):\n        lps = [0] * len(pattern)\n        length = 0\n        i = 1\n        \n        while i &lt; len(pattern):\n            if pattern[i] == pattern[length]:\n                length += 1\n                lps[i] = length\n                i += 1\n            else:\n                if length != 0:\n                    length = lps[length - 1]\n                else:\n                    lps[i] = 0\n                    i += 1\n        return lps\n    \n    lps = compute_lps(pattern)\n    i = j = 0\n    \n    while i &lt; len(text):\n        if pattern[j] == text[i]:\n            i += 1\n            j += 1\n        \n        if j == len(pattern):\n            return i - j\n        elif i &lt; len(text) and pattern[j] != text[i]:\n            if j != 0:\n                j = lps[j - 1]\n            else:\n                i += 1\n    \n    return -1",
    "crumbs": [
      "Data Structures & Algorithms",
      "Algorithms"
    ]
  },
  {
    "objectID": "dsa/algorithms.html#algorithm-analysis",
    "href": "dsa/algorithms.html#algorithm-analysis",
    "title": "Algorithms",
    "section": "",
    "text": "Big O Notation: Upper bound on growth rate\nCommon Complexities: O(1), O(log n), O(n), O(n log n), O(n²), O(2ⁿ)\n\n\n\n\n\nAuxiliary Space: Extra space used by algorithm\nIn-place Algorithms: Use O(1) extra space",
    "crumbs": [
      "Data Structures & Algorithms",
      "Algorithms"
    ]
  },
  {
    "objectID": "dsa/algorithms.html#problem-solving-strategies",
    "href": "dsa/algorithms.html#problem-solving-strategies",
    "title": "Algorithms",
    "section": "",
    "text": "Before Coding\n\n\n\n\nUnderstand the problem completely\nIdentify input/output constraints\nConsider edge cases\nChoose appropriate data structure\nPlan your algorithm\n\n\n\n\n\n\n\n\n\nCommon Mistakes\n\n\n\n\nNot handling edge cases\nIncorrect time/space complexity analysis\nOver-optimizing prematurely\nNot testing with different inputs",
    "crumbs": [
      "Data Structures & Algorithms",
      "Algorithms"
    ]
  },
  {
    "objectID": "dsa/data-structures.html",
    "href": "dsa/data-structures.html",
    "title": "Data Structures",
    "section": "",
    "text": "A comprehensive guide to fundamental data structures with implementations and use cases.\n\n\n\n\n\nDescription: Contiguous memory allocation for elements\nTime Complexity: Access O(1), Search O(n), Insert/Delete O(n)\nUse Cases: When you need random access, fixed size collections\n\n# Basic array operations\narr = [1, 2, 3, 4, 5]\narr.append(6)      # O(1) amortized\narr.insert(0, 0)   # O(n)\narr.pop()          # O(1)\narr[2]             # O(1) access\n\n\n\n\nDescription: Nodes connected by pointers\nTime Complexity: Access O(n), Search O(n), Insert/Delete O(1) at head/tail\nUse Cases: Dynamic size, frequent insertions/deletions\n\nclass ListNode:\n    def __init__(self, val=0, next=None):\n        self.val = val\n        self.next = next\n\n# Common operations\ndef reverse_list(head):\n    prev = None\n    curr = head\n    while curr:\n        next_temp = curr.next\n        curr.next = prev\n        prev = curr\n        curr = next_temp\n    return prev\n\n\n\n\nDescription: LIFO (Last In, First Out) structure\nTime Complexity: Push/Pop O(1), Search O(n)\nUse Cases: Function call stack, undo operations, parentheses matching\n\n# Stack implementation\nstack = []\nstack.append(1)    # Push\nstack.append(2)\nstack.append(3)\ntop = stack.pop()  # Pop - returns 3\n\n\n\n\nDescription: FIFO (First In, First Out) structure\nTime Complexity: Enqueue/Dequeue O(1), Search O(n)\nUse Cases: BFS, task scheduling, print queues\n\nfrom collections import deque\n\nqueue = deque()\nqueue.append(1)    # Enqueue\nqueue.append(2)\nqueue.append(3)\nfirst = queue.popleft()  # Dequeue - returns 1\n\n\n\n\n\n\n\nDescription: Each node has at most two children\nUse Cases: Expression trees, file systems, decision trees\n\nclass TreeNode:\n    def __init__(self, val=0, left=None, right=None):\n        self.val = val\n        self.left = left\n        self.right = right\n\n# Tree traversal\ndef inorder_traversal(root):\n    if not root:\n        return []\n    return inorder_traversal(root.left) + [root.val] + inorder_traversal(root.right)\n\n\n\n\nDescription: Ordered binary tree where left &lt; root &lt; right\nTime Complexity: Search/Insert/Delete O(log n) average, O(n) worst\nUse Cases: Symbol tables, ordered data storage\n\n\n\n\n\nDescription: Complete binary tree with heap property\nTime Complexity: Insert/Delete O(log n), Get min/max O(1)\nUse Cases: Priority queues, heap sort, top-k elements\n\nimport heapq\n\n# Min heap\nheap = []\nheapq.heappush(heap, 3)\nheapq.heappush(heap, 1)\nheapq.heappush(heap, 2)\nmin_val = heapq.heappop(heap)  # Returns 1\n\n\n\n\n\n\n\nDescription: Key-value pairs with O(1) average access\nTime Complexity: Insert/Delete/Search O(1) average, O(n) worst\nUse Cases: Caching, symbol tables, duplicate detection\n\n# Dictionary in Python\nhash_table = {}\nhash_table['key'] = 'value'    # Insert\nvalue = hash_table['key']      # Access\nhash_table.pop('key')          # Delete\n\n\n\n\n\n\n\nDescription: List of lists representing graph edges\nSpace Complexity: O(V + E)\nUse Cases: Sparse graphs, most graph algorithms\n\n# Adjacency list representation\ngraph = {\n    0: [1, 2],\n    1: [0, 2],\n    2: [0, 1, 3],\n    3: [2]\n}\n\n\n\n\nDescription: 2D matrix representing graph edges\nSpace Complexity: O(V²)\nUse Cases: Dense graphs, quick edge existence check\n\n\n\n\n\n\n\n\nDescription: Tree for storing strings with common prefixes\nUse Cases: Autocomplete, spell checkers, IP routing\n\n\n\n\n\nDescription: Tree for range queries and updates\nTime Complexity: Query/Update O(log n)\nUse Cases: Range sum/min/max queries\n\n\n\n\n\n\n\n\n\n\n\nMemory Management\n\n\n\n\nConsider space complexity alongside time complexity\nBe aware of language-specific optimizations\nUse appropriate data structures for your use case\n\n\n\n\n\n\n\n\n\nCommon Pitfalls\n\n\n\n\nNot considering edge cases (empty structures, single elements)\nForgetting to handle memory leaks in manual implementations\nChoosing wrong data structure for the problem",
    "crumbs": [
      "Data Structures & Algorithms",
      "Data Structures"
    ]
  },
  {
    "objectID": "dsa/data-structures.html#linear-data-structures",
    "href": "dsa/data-structures.html#linear-data-structures",
    "title": "Data Structures",
    "section": "",
    "text": "Description: Contiguous memory allocation for elements\nTime Complexity: Access O(1), Search O(n), Insert/Delete O(n)\nUse Cases: When you need random access, fixed size collections\n\n# Basic array operations\narr = [1, 2, 3, 4, 5]\narr.append(6)      # O(1) amortized\narr.insert(0, 0)   # O(n)\narr.pop()          # O(1)\narr[2]             # O(1) access\n\n\n\n\nDescription: Nodes connected by pointers\nTime Complexity: Access O(n), Search O(n), Insert/Delete O(1) at head/tail\nUse Cases: Dynamic size, frequent insertions/deletions\n\nclass ListNode:\n    def __init__(self, val=0, next=None):\n        self.val = val\n        self.next = next\n\n# Common operations\ndef reverse_list(head):\n    prev = None\n    curr = head\n    while curr:\n        next_temp = curr.next\n        curr.next = prev\n        prev = curr\n        curr = next_temp\n    return prev\n\n\n\n\nDescription: LIFO (Last In, First Out) structure\nTime Complexity: Push/Pop O(1), Search O(n)\nUse Cases: Function call stack, undo operations, parentheses matching\n\n# Stack implementation\nstack = []\nstack.append(1)    # Push\nstack.append(2)\nstack.append(3)\ntop = stack.pop()  # Pop - returns 3\n\n\n\n\nDescription: FIFO (First In, First Out) structure\nTime Complexity: Enqueue/Dequeue O(1), Search O(n)\nUse Cases: BFS, task scheduling, print queues\n\nfrom collections import deque\n\nqueue = deque()\nqueue.append(1)    # Enqueue\nqueue.append(2)\nqueue.append(3)\nfirst = queue.popleft()  # Dequeue - returns 1",
    "crumbs": [
      "Data Structures & Algorithms",
      "Data Structures"
    ]
  },
  {
    "objectID": "dsa/data-structures.html#tree-based-data-structures",
    "href": "dsa/data-structures.html#tree-based-data-structures",
    "title": "Data Structures",
    "section": "",
    "text": "Description: Each node has at most two children\nUse Cases: Expression trees, file systems, decision trees\n\nclass TreeNode:\n    def __init__(self, val=0, left=None, right=None):\n        self.val = val\n        self.left = left\n        self.right = right\n\n# Tree traversal\ndef inorder_traversal(root):\n    if not root:\n        return []\n    return inorder_traversal(root.left) + [root.val] + inorder_traversal(root.right)\n\n\n\n\nDescription: Ordered binary tree where left &lt; root &lt; right\nTime Complexity: Search/Insert/Delete O(log n) average, O(n) worst\nUse Cases: Symbol tables, ordered data storage\n\n\n\n\n\nDescription: Complete binary tree with heap property\nTime Complexity: Insert/Delete O(log n), Get min/max O(1)\nUse Cases: Priority queues, heap sort, top-k elements\n\nimport heapq\n\n# Min heap\nheap = []\nheapq.heappush(heap, 3)\nheapq.heappush(heap, 1)\nheapq.heappush(heap, 2)\nmin_val = heapq.heappop(heap)  # Returns 1",
    "crumbs": [
      "Data Structures & Algorithms",
      "Data Structures"
    ]
  },
  {
    "objectID": "dsa/data-structures.html#hash-based-data-structures",
    "href": "dsa/data-structures.html#hash-based-data-structures",
    "title": "Data Structures",
    "section": "",
    "text": "Description: Key-value pairs with O(1) average access\nTime Complexity: Insert/Delete/Search O(1) average, O(n) worst\nUse Cases: Caching, symbol tables, duplicate detection\n\n# Dictionary in Python\nhash_table = {}\nhash_table['key'] = 'value'    # Insert\nvalue = hash_table['key']      # Access\nhash_table.pop('key')          # Delete",
    "crumbs": [
      "Data Structures & Algorithms",
      "Data Structures"
    ]
  },
  {
    "objectID": "dsa/data-structures.html#graph-data-structures",
    "href": "dsa/data-structures.html#graph-data-structures",
    "title": "Data Structures",
    "section": "",
    "text": "Description: List of lists representing graph edges\nSpace Complexity: O(V + E)\nUse Cases: Sparse graphs, most graph algorithms\n\n# Adjacency list representation\ngraph = {\n    0: [1, 2],\n    1: [0, 2],\n    2: [0, 1, 3],\n    3: [2]\n}\n\n\n\n\nDescription: 2D matrix representing graph edges\nSpace Complexity: O(V²)\nUse Cases: Dense graphs, quick edge existence check",
    "crumbs": [
      "Data Structures & Algorithms",
      "Data Structures"
    ]
  },
  {
    "objectID": "dsa/data-structures.html#advanced-data-structures",
    "href": "dsa/data-structures.html#advanced-data-structures",
    "title": "Data Structures",
    "section": "",
    "text": "Description: Tree for storing strings with common prefixes\nUse Cases: Autocomplete, spell checkers, IP routing\n\n\n\n\n\nDescription: Tree for range queries and updates\nTime Complexity: Query/Update O(log n)\nUse Cases: Range sum/min/max queries",
    "crumbs": [
      "Data Structures & Algorithms",
      "Data Structures"
    ]
  },
  {
    "objectID": "dsa/data-structures.html#implementation-tips",
    "href": "dsa/data-structures.html#implementation-tips",
    "title": "Data Structures",
    "section": "",
    "text": "Memory Management\n\n\n\n\nConsider space complexity alongside time complexity\nBe aware of language-specific optimizations\nUse appropriate data structures for your use case\n\n\n\n\n\n\n\n\n\nCommon Pitfalls\n\n\n\n\nNot considering edge cases (empty structures, single elements)\nForgetting to handle memory leaks in manual implementations\nChoosing wrong data structure for the problem",
    "crumbs": [
      "Data Structures & Algorithms",
      "Data Structures"
    ]
  },
  {
    "objectID": "technical-blogs/index.html",
    "href": "technical-blogs/index.html",
    "title": "Technical Blogs",
    "section": "",
    "text": "Welcome to my Technical Blog Breakdown section! Here I analyze and break down interesting technical articles, engineering blogs, and industry insights to extract key learnings and practical knowledge.\n\n\n\nBlog Breakdowns - Detailed analysis of technical articles\nNotes - Quick summaries and key takeaways\n\n\n\n\n\n\n\nSoftware Architecture: System design patterns, best practices\nPerformance Optimization: Code optimization, database tuning\nDevOps & Infrastructure: CI/CD, cloud platforms, monitoring\nSecurity: Best practices, vulnerabilities, secure coding\n\n\n\n\n\nProgramming Languages: Language features, frameworks, libraries\nDatabases: Query optimization, data modeling, new technologies\nDistributed Systems: Scalability, consistency, fault tolerance\nMachine Learning: Algorithms, frameworks, practical applications\n\n\n\n\n\nCompany Engineering Blogs: Netflix, Uber, Airbnb, Google, etc.\nOpen Source Projects: Architecture decisions, implementation details\nTechnical Conferences: Keynotes, presentations, workshops\nResearch Papers: Academic insights applied to practical problems\n\n\n\n\n\n\n\n\nUnderstanding the problem being solved\nHistorical context and motivation\nIndustry relevance and impact\n\n\n\n\n\nCore concepts and technologies used\nArchitecture decisions and trade-offs\nImplementation details and code examples\n\n\n\n\n\nMain takeaways and insights\nApplicable patterns and practices\nPotential applications to other problems\n\n\n\n\n\nStrengths and weaknesses of the approach\nAlternative solutions and considerations\nLessons learned and best practices\n\n\n\n\n\n\n\n\nNetflix Tech Blog: Microservices, chaos engineering, data processing\nUber Engineering: Real-time systems, machine learning, infrastructure\nAirbnb Engineering: Data science, mobile development, platform engineering\nGoogle Cloud Blog: Cloud architecture, Kubernetes, serverless\nAWS Architecture Blog: Cloud patterns, best practices, case studies\n\n\n\n\n\nHigh Scalability: Real-world architecture examples\nMartin Fowler’s Blog: Software architecture and design\nJepsen: Distributed systems testing and analysis\nACM Queue: Computer science and engineering insights\nIEEE Software: Academic and industry research\n\n\n\n\n\nJoel on Software: Software development insights\nCoding Horror: Programming practices and tools\nPaul Graham’s Essays: Startups and programming philosophy\nRands in Repose: Engineering management and culture\n\n\n\n\n\n\n\n\nSkim First: Get overview, identify key sections\nDeep Read: Focus on technical details and code\nTake Notes: Document key concepts and insights\nApply Learning: Think about practical applications\nShare Knowledge: Discuss with others, write summaries\n\n\n\n\n## Article: [Title]\n**Author**: [Author Name]  \n**Source**: [Blog/Publication]  \n**Date**: [Publication Date]  \n**Category**: [Architecture/Performance/Security/etc.]\n\n### Summary\n[2-3 sentence overview]\n\n### Key Points\n- [Point 1]\n- [Point 2]\n- [Point 3]\n\n### Technical Details\n[Code examples, diagrams, implementation notes]\n\n### Takeaways\n- [Learning 1]\n- [Learning 2]\n- [Learning 3]\n\n### Questions/Follow-up\n- [Questions for further research]\n- [Related topics to explore]\n\n\n\n\n\n\n\n\n\n\nActive Topics\n\n\n\n\nDistributed Systems: Consistency models, consensus algorithms\nPerformance Engineering: Profiling, optimization techniques\nCloud-Native Architecture: Kubernetes, serverless, microservices\nData Engineering: ETL pipelines, data lakes, real-time processing\n\n\n\n\n\n\n\n\n\nUpcoming Analysis\n\n\n\n\nNetflix’s Chaos Engineering: How they test system resilience\nUber’s Real-time Data Platform: Architecture for massive scale\nGoogle’s Spanner: Distributed database design\nAirbnb’s Data Science Platform: ML infrastructure and practices\n\n\n\n\n\n\n\n\n\nAnalyze 20+ technical articles\nFocus on distributed systems and scalability\nBuild practical examples from blog concepts\nShare insights through my own blog posts\n\n\n\n\n\nDeep dive into specific technologies (Kubernetes, Kafka, etc.)\nCompare different architectural approaches\nBuild proof-of-concept implementations\nContribute to open source projects\n\n\n\n\n\nDevelop expertise in system design\nBuild a comprehensive knowledge base\nShare knowledge through teaching and writing\nApply learnings to real-world projects\n\n\n\n\n\n\n\n\nPocket: Save articles for later reading\nNotion: Organize notes and insights\nDraw.io: Create diagrams and visualizations\nGitHub: Store code examples and implementations\n\n\n\n\n\nGoogle Scholar: Academic papers and research\narXiv: Preprints and technical papers\nStack Overflow: Community discussions and solutions\nReddit: r/programming, r/sysadmin, r/devops\n\n\n\n\n\nLeetCode: Algorithm problems and solutions\nHackerRank: Programming challenges\nAWS/GCP/Azure: Cloud platform experimentation\nDocker/Kubernetes: Container and orchestration practice\n\n\n\n\n\n\n\n\nWeekly Summaries: Key insights from recent readings\nDeep Dives: Detailed analysis of specific topics\nTutorials: Step-by-step implementations\nCase Studies: Real-world applications\n\n\n\n\n\nLocal Meetups: In-person technical discussions\nOnline Forums: Reddit, Stack Overflow, Discord\nStudy Groups: Collaborative learning sessions\nMentorship: Teaching others while learning\n\n\n\n\n\n\n\n\nArticles Read: Target 50+ technical articles per year\nTopics Covered: 10+ major technical areas\nCode Examples: 20+ practical implementations\nNotes Quality: Comprehensive, well-organized summaries\n\n\n\n\n\nSystem Design: Ability to design scalable systems\nProblem Solving: Apply patterns to new challenges\nCommunication: Explain complex concepts clearly\nImplementation: Build working prototypes\n\n\n\n\n\nBlog Posts: 24+ articles per year\nKnowledge Sharing: Help others learn and grow\nOpen Source: Contribute to relevant projects\nNetworking: Connect with other developers\n\n\n\n\n\n\n\nGetting Started\n\n\n\n\nChoose a Topic: Pick an area that interests you\nFind Quality Sources: Look for reputable engineering blogs\nRead Actively: Take notes and ask questions\nPractice: Implement concepts in your own projects\nShare: Write about what you learn",
    "crumbs": [
      "Technical Blogs"
    ]
  },
  {
    "objectID": "technical-blogs/index.html#quick-navigation",
    "href": "technical-blogs/index.html#quick-navigation",
    "title": "Technical Blogs",
    "section": "",
    "text": "Blog Breakdowns - Detailed analysis of technical articles\nNotes - Quick summaries and key takeaways",
    "crumbs": [
      "Technical Blogs"
    ]
  },
  {
    "objectID": "technical-blogs/index.html#what-i-cover",
    "href": "technical-blogs/index.html#what-i-cover",
    "title": "Technical Blogs",
    "section": "",
    "text": "Software Architecture: System design patterns, best practices\nPerformance Optimization: Code optimization, database tuning\nDevOps & Infrastructure: CI/CD, cloud platforms, monitoring\nSecurity: Best practices, vulnerabilities, secure coding\n\n\n\n\n\nProgramming Languages: Language features, frameworks, libraries\nDatabases: Query optimization, data modeling, new technologies\nDistributed Systems: Scalability, consistency, fault tolerance\nMachine Learning: Algorithms, frameworks, practical applications\n\n\n\n\n\nCompany Engineering Blogs: Netflix, Uber, Airbnb, Google, etc.\nOpen Source Projects: Architecture decisions, implementation details\nTechnical Conferences: Keynotes, presentations, workshops\nResearch Papers: Academic insights applied to practical problems",
    "crumbs": [
      "Technical Blogs"
    ]
  },
  {
    "objectID": "technical-blogs/index.html#my-analysis-approach",
    "href": "technical-blogs/index.html#my-analysis-approach",
    "title": "Technical Blogs",
    "section": "",
    "text": "Understanding the problem being solved\nHistorical context and motivation\nIndustry relevance and impact\n\n\n\n\n\nCore concepts and technologies used\nArchitecture decisions and trade-offs\nImplementation details and code examples\n\n\n\n\n\nMain takeaways and insights\nApplicable patterns and practices\nPotential applications to other problems\n\n\n\n\n\nStrengths and weaknesses of the approach\nAlternative solutions and considerations\nLessons learned and best practices",
    "crumbs": [
      "Technical Blogs"
    ]
  },
  {
    "objectID": "technical-blogs/index.html#featured-sources",
    "href": "technical-blogs/index.html#featured-sources",
    "title": "Technical Blogs",
    "section": "",
    "text": "Netflix Tech Blog: Microservices, chaos engineering, data processing\nUber Engineering: Real-time systems, machine learning, infrastructure\nAirbnb Engineering: Data science, mobile development, platform engineering\nGoogle Cloud Blog: Cloud architecture, Kubernetes, serverless\nAWS Architecture Blog: Cloud patterns, best practices, case studies\n\n\n\n\n\nHigh Scalability: Real-world architecture examples\nMartin Fowler’s Blog: Software architecture and design\nJepsen: Distributed systems testing and analysis\nACM Queue: Computer science and engineering insights\nIEEE Software: Academic and industry research\n\n\n\n\n\nJoel on Software: Software development insights\nCoding Horror: Programming practices and tools\nPaul Graham’s Essays: Startups and programming philosophy\nRands in Repose: Engineering management and culture",
    "crumbs": [
      "Technical Blogs"
    ]
  },
  {
    "objectID": "technical-blogs/index.html#reading-strategy",
    "href": "technical-blogs/index.html#reading-strategy",
    "title": "Technical Blogs",
    "section": "",
    "text": "Skim First: Get overview, identify key sections\nDeep Read: Focus on technical details and code\nTake Notes: Document key concepts and insights\nApply Learning: Think about practical applications\nShare Knowledge: Discuss with others, write summaries\n\n\n\n\n## Article: [Title]\n**Author**: [Author Name]  \n**Source**: [Blog/Publication]  \n**Date**: [Publication Date]  \n**Category**: [Architecture/Performance/Security/etc.]\n\n### Summary\n[2-3 sentence overview]\n\n### Key Points\n- [Point 1]\n- [Point 2]\n- [Point 3]\n\n### Technical Details\n[Code examples, diagrams, implementation notes]\n\n### Takeaways\n- [Learning 1]\n- [Learning 2]\n- [Learning 3]\n\n### Questions/Follow-up\n- [Questions for further research]\n- [Related topics to explore]",
    "crumbs": [
      "Technical Blogs"
    ]
  },
  {
    "objectID": "technical-blogs/index.html#current-reading-focus",
    "href": "technical-blogs/index.html#current-reading-focus",
    "title": "Technical Blogs",
    "section": "",
    "text": "Active Topics\n\n\n\n\nDistributed Systems: Consistency models, consensus algorithms\nPerformance Engineering: Profiling, optimization techniques\nCloud-Native Architecture: Kubernetes, serverless, microservices\nData Engineering: ETL pipelines, data lakes, real-time processing\n\n\n\n\n\n\n\n\n\nUpcoming Analysis\n\n\n\n\nNetflix’s Chaos Engineering: How they test system resilience\nUber’s Real-time Data Platform: Architecture for massive scale\nGoogle’s Spanner: Distributed database design\nAirbnb’s Data Science Platform: ML infrastructure and practices",
    "crumbs": [
      "Technical Blogs"
    ]
  },
  {
    "objectID": "technical-blogs/index.html#learning-goals",
    "href": "technical-blogs/index.html#learning-goals",
    "title": "Technical Blogs",
    "section": "",
    "text": "Analyze 20+ technical articles\nFocus on distributed systems and scalability\nBuild practical examples from blog concepts\nShare insights through my own blog posts\n\n\n\n\n\nDeep dive into specific technologies (Kubernetes, Kafka, etc.)\nCompare different architectural approaches\nBuild proof-of-concept implementations\nContribute to open source projects\n\n\n\n\n\nDevelop expertise in system design\nBuild a comprehensive knowledge base\nShare knowledge through teaching and writing\nApply learnings to real-world projects",
    "crumbs": [
      "Technical Blogs"
    ]
  },
  {
    "objectID": "technical-blogs/index.html#tools-resources",
    "href": "technical-blogs/index.html#tools-resources",
    "title": "Technical Blogs",
    "section": "",
    "text": "Pocket: Save articles for later reading\nNotion: Organize notes and insights\nDraw.io: Create diagrams and visualizations\nGitHub: Store code examples and implementations\n\n\n\n\n\nGoogle Scholar: Academic papers and research\narXiv: Preprints and technical papers\nStack Overflow: Community discussions and solutions\nReddit: r/programming, r/sysadmin, r/devops\n\n\n\n\n\nLeetCode: Algorithm problems and solutions\nHackerRank: Programming challenges\nAWS/GCP/Azure: Cloud platform experimentation\nDocker/Kubernetes: Container and orchestration practice",
    "crumbs": [
      "Technical Blogs"
    ]
  },
  {
    "objectID": "technical-blogs/index.html#sharing-collaboration",
    "href": "technical-blogs/index.html#sharing-collaboration",
    "title": "Technical Blogs",
    "section": "",
    "text": "Weekly Summaries: Key insights from recent readings\nDeep Dives: Detailed analysis of specific topics\nTutorials: Step-by-step implementations\nCase Studies: Real-world applications\n\n\n\n\n\nLocal Meetups: In-person technical discussions\nOnline Forums: Reddit, Stack Overflow, Discord\nStudy Groups: Collaborative learning sessions\nMentorship: Teaching others while learning",
    "crumbs": [
      "Technical Blogs"
    ]
  },
  {
    "objectID": "technical-blogs/index.html#success-metrics",
    "href": "technical-blogs/index.html#success-metrics",
    "title": "Technical Blogs",
    "section": "",
    "text": "Articles Read: Target 50+ technical articles per year\nTopics Covered: 10+ major technical areas\nCode Examples: 20+ practical implementations\nNotes Quality: Comprehensive, well-organized summaries\n\n\n\n\n\nSystem Design: Ability to design scalable systems\nProblem Solving: Apply patterns to new challenges\nCommunication: Explain complex concepts clearly\nImplementation: Build working prototypes\n\n\n\n\n\nBlog Posts: 24+ articles per year\nKnowledge Sharing: Help others learn and grow\nOpen Source: Contribute to relevant projects\nNetworking: Connect with other developers\n\n\n\n\n\n\n\nGetting Started\n\n\n\n\nChoose a Topic: Pick an area that interests you\nFind Quality Sources: Look for reputable engineering blogs\nRead Actively: Take notes and ask questions\nPractice: Implement concepts in your own projects\nShare: Write about what you learn",
    "crumbs": [
      "Technical Blogs"
    ]
  },
  {
    "objectID": "technical-blogs/notes.html",
    "href": "technical-blogs/notes.html",
    "title": "Quick Notes",
    "section": "",
    "text": "Quick summaries and key takeaways from technical articles and engineering blogs.\n\n\n\n\n\n\nSource: Architecture of Open Source Applications\nDate: 2023\nCategory: System Architecture\nSummary: Analysis of Asterisk’s modular architecture for telephony applications.\nKey Takeaways: - Module Design: Plug-in architecture enables extensibility - Event-Driven: Asynchronous event handling for scalability - Configuration Management: Dynamic configuration without restarts - Error Handling: Graceful degradation and recovery\nCode Insight:\n// Module registration pattern\nstatic struct ast_module *load_module(const char *name) {\n    struct ast_module *mod = ast_load_resource(name);\n    if (mod) {\n        ast_module_register(mod);\n    }\n    return mod;\n}\n\n\n\n\nSource: Martin Kleppmann’s Book\nDate: 2023\nCategory: Data Systems\nSummary: How to handle data format evolution in distributed systems.\nKey Takeaways: - Schema Evolution: Backward/forward compatibility strategies - Encoding Formats: JSON, Protocol Buffers, Avro comparison - Versioning: API versioning vs data versioning - Migration Strategies: Rolling upgrades and data transformation\nPractical Application:\n# Protocol Buffer with optional fields for evolution\nmessage User {\n    string id = 1;\n    string name = 2;\n    string email = 3;\n    // New field added - optional for backward compatibility\n    optional string phone = 4;\n}\n\n\n\n\n\n\n\nSource: MySQL Performance Blog\nDate: 2023\nCategory: Database Performance\nSummary: Techniques for optimizing MySQL query performance.\nKey Takeaways: - Index Strategy: Composite indexes and covering indexes - Query Analysis: EXPLAIN plan interpretation - Partitioning: Table partitioning for large datasets - Caching: Application-level and query result caching\nOptimization Example:\n-- Before: Full table scan\nSELECT * FROM orders WHERE user_id = 123 AND status = 'pending';\n\n-- After: Proper indexing\nCREATE INDEX idx_user_status ON orders(user_id, status);\nSELECT user_id, order_id, amount FROM orders \nWHERE user_id = 123 AND status = 'pending';\n\n\n\n\nSource: Redis Blog\nDate: 2023\nCategory: Caching\nSummary: Memory optimization techniques for Redis deployments.\nKey Takeaways: - Memory Policies: LRU, LFU, TTL-based eviction - Data Structures: Choosing appropriate Redis data types - Compression: Using compression for large values - Monitoring: Memory usage tracking and alerting\nMemory Optimization:\n# Using Redis hashes instead of separate keys\n# Before: Multiple keys\nredis.set(f\"user:{user_id}:name\", name)\nredis.set(f\"user:{user_id}:email\", email)\n\n# After: Hash structure\nredis.hset(f\"user:{user_id}\", mapping={\n    \"name\": name,\n    \"email\": email\n})\n\n\n\n\n\n\n\nSource: Distributed Systems Course\nDate: 2023\nCategory: Distributed Systems\nSummary: Understanding the Raft consensus algorithm for distributed systems.\nKey Takeaways: - Leader Election: Randomized timeout-based election - Log Replication: Append-only log with consistency checks - Safety Properties: Leader completeness and log matching - Fault Tolerance: Handling network partitions and failures\nRaft Implementation Concept:\nclass RaftNode:\n    def __init__(self, node_id, nodes):\n        self.node_id = node_id\n        self.nodes = nodes\n        self.current_term = 0\n        self.voted_for = None\n        self.log = []\n        self.commit_index = 0\n        self.state = 'follower'\n    \n    def start_election(self):\n        self.current_term += 1\n        self.state = 'candidate'\n        self.voted_for = self.node_id\n        \n        # Request votes from other nodes\n        votes_received = 1  # Vote for self\n        for node in self.nodes:\n            if node != self.node_id:\n                if self.request_vote(node):\n                    votes_received += 1\n        \n        if votes_received &gt; len(self.nodes) // 2:\n            self.become_leader()\n\n\n\n\nSource: Microservices.io\nDate: 2023\nCategory: Microservices\nSummary: Different communication patterns for microservices architecture.\nKey Takeaways: - Synchronous: REST, gRPC for request-response - Asynchronous: Message queues, event-driven - Circuit Breaker: Fault tolerance pattern - API Gateway: Centralized routing and cross-cutting concerns\nCircuit Breaker Pattern:\nclass CircuitBreaker:\n    def __init__(self, failure_threshold=5, timeout=60):\n        self.failure_threshold = failure_threshold\n        self.timeout = timeout\n        self.failure_count = 0\n        self.last_failure_time = None\n        self.state = 'CLOSED'\n    \n    def call(self, func, *args, **kwargs):\n        if self.state == 'OPEN':\n            if time.time() - self.last_failure_time &gt; self.timeout:\n                self.state = 'HALF_OPEN'\n            else:\n                raise Exception(\"Circuit breaker is OPEN\")\n        \n        try:\n            result = func(*args, **kwargs)\n            if self.state == 'HALF_OPEN':\n                self.state = 'CLOSED'\n                self.failure_count = 0\n            return result\n        except Exception as e:\n            self.failure_count += 1\n            self.last_failure_time = time.time()\n            \n            if self.failure_count &gt;= self.failure_threshold:\n                self.state = 'OPEN'\n            \n            raise e\n\n\n\n\n\n\n\nSource: Kubernetes Blog\nDate: 2023\nCategory: Container Orchestration\nSummary: Best practices for resource management in Kubernetes.\nKey Takeaways: - Resource Limits: CPU and memory limits for pods - Resource Requests: Guaranteed resources for pods - Horizontal Pod Autoscaler: Automatic scaling based on metrics - Resource Quotas: Namespace-level resource constraints\nResource Configuration:\napiVersion: v1\nkind: Pod\nmetadata:\n  name: web-app\nspec:\n  containers:\n  - name: web\n    image: nginx\n    resources:\n      requests:\n        memory: \"64Mi\"\n        cpu: \"250m\"\n      limits:\n        memory: \"128Mi\"\n        cpu: \"500m\"\n\n\n\n\nSource: AWS Blog\nDate: 2023\nCategory: Serverless\nSummary: Techniques for optimizing AWS Lambda function performance.\nKey Takeaways: - Cold Start Optimization: Keep functions warm, use provisioned concurrency - Memory Allocation: More memory = more CPU - Dependency Management: Minimize deployment package size - Connection Reuse: Reuse database connections across invocations\nOptimization Example:\n# Connection reuse pattern\nimport boto3\nimport pymysql\n\n# Global variables for connection reuse\ndb_connection = None\n\ndef lambda_handler(event, context):\n    global db_connection\n    \n    # Reuse connection if available\n    if db_connection is None:\n        db_connection = pymysql.connect(\n            host=os.environ['DB_HOST'],\n            user=os.environ['DB_USER'],\n            password=os.environ['DB_PASSWORD'],\n            database=os.environ['DB_NAME']\n        )\n    \n    # Use connection for database operations\n    with db_connection.cursor() as cursor:\n        cursor.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))\n        result = cursor.fetchone()\n    \n    return result\n\n\n\n\n\n\n\nSource: OWASP\nDate: 2023\nCategory: Security\nSummary: Updated OWASP Top 10 security vulnerabilities and mitigations.\nKey Takeaways: - Broken Access Control: Implement proper authorization - Cryptographic Failures: Use strong encryption and secure protocols - Injection: Parameterized queries and input validation - Security Misconfiguration: Secure defaults and regular updates\nSecurity Best Practices:\n# SQL Injection Prevention\nimport sqlite3\n\n# Bad: String concatenation\ndef bad_query(user_input):\n    query = f\"SELECT * FROM users WHERE name = '{user_input}'\"\n    return cursor.execute(query)\n\n# Good: Parameterized query\ndef good_query(user_input):\n    query = \"SELECT * FROM users WHERE name = ?\"\n    return cursor.execute(query, (user_input,))\n\n\n\n\nSource: Security Blog\nDate: 2023\nCategory: Security Architecture\nSummary: Implementing zero trust security principles in modern applications.\nKey Takeaways: - Never Trust, Always Verify: Authenticate and authorize every request - Least Privilege: Grant minimum necessary permissions - Micro-segmentation: Network segmentation at service level - Continuous Monitoring: Real-time security monitoring and response\nZero Trust Implementation:\n# Service-to-service authentication\nimport jwt\nimport requests\n\nclass ZeroTrustClient:\n    def __init__(self, service_name, private_key):\n        self.service_name = service_name\n        self.private_key = private_key\n    \n    def make_authenticated_request(self, target_service, endpoint, data):\n        # Create JWT token for service authentication\n        token = jwt.encode({\n            'service': self.service_name,\n            'aud': target_service,\n            'exp': datetime.utcnow() + timedelta(minutes=5)\n        }, self.private_key, algorithm='RS256')\n        \n        # Make request with authentication\n        headers = {'Authorization': f'Bearer {token}'}\n        response = requests.post(\n            f\"https://{target_service}/{endpoint}\",\n            json=data,\n            headers=headers\n        )\n        \n        return response.json()\n\n\n\n\n\n\n\n\n\nLatency: Response time (P50, P95, P99)\nThroughput: Requests per second (RPS)\nError Rate: Percentage of failed requests\nResource Utilization: CPU, memory, disk, network\n\n\n\n\n\nRetry Pattern: Exponential backoff for transient failures\nBulkhead Pattern: Isolate failures between services\nCache-Aside: Application-managed caching\nEvent Sourcing: Store events instead of state\n\n\n\n\n\nGolden Signals: Latency, traffic, errors, saturation\nSLI/SLO: Service level indicators and objectives\nAlerting: Meaningful alerts with actionable information\nDashboards: Real-time visibility into system health\n\n\n\n\n\n\n\nNote-Taking Tips\n\n\n\n\nBe Concise: Focus on key insights and actionable items\nInclude Code: Practical examples help with implementation\nCategorize: Organize notes by topic and difficulty level\nReview Regularly: Revisit notes to reinforce learning",
    "crumbs": [
      "Technical Blogs",
      "Quick Notes"
    ]
  },
  {
    "objectID": "technical-blogs/notes.html#recent-notes",
    "href": "technical-blogs/notes.html#recent-notes",
    "title": "Quick Notes",
    "section": "",
    "text": "Source: Architecture of Open Source Applications\nDate: 2023\nCategory: System Architecture\nSummary: Analysis of Asterisk’s modular architecture for telephony applications.\nKey Takeaways: - Module Design: Plug-in architecture enables extensibility - Event-Driven: Asynchronous event handling for scalability - Configuration Management: Dynamic configuration without restarts - Error Handling: Graceful degradation and recovery\nCode Insight:\n// Module registration pattern\nstatic struct ast_module *load_module(const char *name) {\n    struct ast_module *mod = ast_load_resource(name);\n    if (mod) {\n        ast_module_register(mod);\n    }\n    return mod;\n}\n\n\n\n\nSource: Martin Kleppmann’s Book\nDate: 2023\nCategory: Data Systems\nSummary: How to handle data format evolution in distributed systems.\nKey Takeaways: - Schema Evolution: Backward/forward compatibility strategies - Encoding Formats: JSON, Protocol Buffers, Avro comparison - Versioning: API versioning vs data versioning - Migration Strategies: Rolling upgrades and data transformation\nPractical Application:\n# Protocol Buffer with optional fields for evolution\nmessage User {\n    string id = 1;\n    string name = 2;\n    string email = 3;\n    // New field added - optional for backward compatibility\n    optional string phone = 4;\n}\n\n\n\n\n\n\n\nSource: MySQL Performance Blog\nDate: 2023\nCategory: Database Performance\nSummary: Techniques for optimizing MySQL query performance.\nKey Takeaways: - Index Strategy: Composite indexes and covering indexes - Query Analysis: EXPLAIN plan interpretation - Partitioning: Table partitioning for large datasets - Caching: Application-level and query result caching\nOptimization Example:\n-- Before: Full table scan\nSELECT * FROM orders WHERE user_id = 123 AND status = 'pending';\n\n-- After: Proper indexing\nCREATE INDEX idx_user_status ON orders(user_id, status);\nSELECT user_id, order_id, amount FROM orders \nWHERE user_id = 123 AND status = 'pending';\n\n\n\n\nSource: Redis Blog\nDate: 2023\nCategory: Caching\nSummary: Memory optimization techniques for Redis deployments.\nKey Takeaways: - Memory Policies: LRU, LFU, TTL-based eviction - Data Structures: Choosing appropriate Redis data types - Compression: Using compression for large values - Monitoring: Memory usage tracking and alerting\nMemory Optimization:\n# Using Redis hashes instead of separate keys\n# Before: Multiple keys\nredis.set(f\"user:{user_id}:name\", name)\nredis.set(f\"user:{user_id}:email\", email)\n\n# After: Hash structure\nredis.hset(f\"user:{user_id}\", mapping={\n    \"name\": name,\n    \"email\": email\n})\n\n\n\n\n\n\n\nSource: Distributed Systems Course\nDate: 2023\nCategory: Distributed Systems\nSummary: Understanding the Raft consensus algorithm for distributed systems.\nKey Takeaways: - Leader Election: Randomized timeout-based election - Log Replication: Append-only log with consistency checks - Safety Properties: Leader completeness and log matching - Fault Tolerance: Handling network partitions and failures\nRaft Implementation Concept:\nclass RaftNode:\n    def __init__(self, node_id, nodes):\n        self.node_id = node_id\n        self.nodes = nodes\n        self.current_term = 0\n        self.voted_for = None\n        self.log = []\n        self.commit_index = 0\n        self.state = 'follower'\n    \n    def start_election(self):\n        self.current_term += 1\n        self.state = 'candidate'\n        self.voted_for = self.node_id\n        \n        # Request votes from other nodes\n        votes_received = 1  # Vote for self\n        for node in self.nodes:\n            if node != self.node_id:\n                if self.request_vote(node):\n                    votes_received += 1\n        \n        if votes_received &gt; len(self.nodes) // 2:\n            self.become_leader()\n\n\n\n\nSource: Microservices.io\nDate: 2023\nCategory: Microservices\nSummary: Different communication patterns for microservices architecture.\nKey Takeaways: - Synchronous: REST, gRPC for request-response - Asynchronous: Message queues, event-driven - Circuit Breaker: Fault tolerance pattern - API Gateway: Centralized routing and cross-cutting concerns\nCircuit Breaker Pattern:\nclass CircuitBreaker:\n    def __init__(self, failure_threshold=5, timeout=60):\n        self.failure_threshold = failure_threshold\n        self.timeout = timeout\n        self.failure_count = 0\n        self.last_failure_time = None\n        self.state = 'CLOSED'\n    \n    def call(self, func, *args, **kwargs):\n        if self.state == 'OPEN':\n            if time.time() - self.last_failure_time &gt; self.timeout:\n                self.state = 'HALF_OPEN'\n            else:\n                raise Exception(\"Circuit breaker is OPEN\")\n        \n        try:\n            result = func(*args, **kwargs)\n            if self.state == 'HALF_OPEN':\n                self.state = 'CLOSED'\n                self.failure_count = 0\n            return result\n        except Exception as e:\n            self.failure_count += 1\n            self.last_failure_time = time.time()\n            \n            if self.failure_count &gt;= self.failure_threshold:\n                self.state = 'OPEN'\n            \n            raise e\n\n\n\n\n\n\n\nSource: Kubernetes Blog\nDate: 2023\nCategory: Container Orchestration\nSummary: Best practices for resource management in Kubernetes.\nKey Takeaways: - Resource Limits: CPU and memory limits for pods - Resource Requests: Guaranteed resources for pods - Horizontal Pod Autoscaler: Automatic scaling based on metrics - Resource Quotas: Namespace-level resource constraints\nResource Configuration:\napiVersion: v1\nkind: Pod\nmetadata:\n  name: web-app\nspec:\n  containers:\n  - name: web\n    image: nginx\n    resources:\n      requests:\n        memory: \"64Mi\"\n        cpu: \"250m\"\n      limits:\n        memory: \"128Mi\"\n        cpu: \"500m\"\n\n\n\n\nSource: AWS Blog\nDate: 2023\nCategory: Serverless\nSummary: Techniques for optimizing AWS Lambda function performance.\nKey Takeaways: - Cold Start Optimization: Keep functions warm, use provisioned concurrency - Memory Allocation: More memory = more CPU - Dependency Management: Minimize deployment package size - Connection Reuse: Reuse database connections across invocations\nOptimization Example:\n# Connection reuse pattern\nimport boto3\nimport pymysql\n\n# Global variables for connection reuse\ndb_connection = None\n\ndef lambda_handler(event, context):\n    global db_connection\n    \n    # Reuse connection if available\n    if db_connection is None:\n        db_connection = pymysql.connect(\n            host=os.environ['DB_HOST'],\n            user=os.environ['DB_USER'],\n            password=os.environ['DB_PASSWORD'],\n            database=os.environ['DB_NAME']\n        )\n    \n    # Use connection for database operations\n    with db_connection.cursor() as cursor:\n        cursor.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))\n        result = cursor.fetchone()\n    \n    return result\n\n\n\n\n\n\n\nSource: OWASP\nDate: 2023\nCategory: Security\nSummary: Updated OWASP Top 10 security vulnerabilities and mitigations.\nKey Takeaways: - Broken Access Control: Implement proper authorization - Cryptographic Failures: Use strong encryption and secure protocols - Injection: Parameterized queries and input validation - Security Misconfiguration: Secure defaults and regular updates\nSecurity Best Practices:\n# SQL Injection Prevention\nimport sqlite3\n\n# Bad: String concatenation\ndef bad_query(user_input):\n    query = f\"SELECT * FROM users WHERE name = '{user_input}'\"\n    return cursor.execute(query)\n\n# Good: Parameterized query\ndef good_query(user_input):\n    query = \"SELECT * FROM users WHERE name = ?\"\n    return cursor.execute(query, (user_input,))\n\n\n\n\nSource: Security Blog\nDate: 2023\nCategory: Security Architecture\nSummary: Implementing zero trust security principles in modern applications.\nKey Takeaways: - Never Trust, Always Verify: Authenticate and authorize every request - Least Privilege: Grant minimum necessary permissions - Micro-segmentation: Network segmentation at service level - Continuous Monitoring: Real-time security monitoring and response\nZero Trust Implementation:\n# Service-to-service authentication\nimport jwt\nimport requests\n\nclass ZeroTrustClient:\n    def __init__(self, service_name, private_key):\n        self.service_name = service_name\n        self.private_key = private_key\n    \n    def make_authenticated_request(self, target_service, endpoint, data):\n        # Create JWT token for service authentication\n        token = jwt.encode({\n            'service': self.service_name,\n            'aud': target_service,\n            'exp': datetime.utcnow() + timedelta(minutes=5)\n        }, self.private_key, algorithm='RS256')\n        \n        # Make request with authentication\n        headers = {'Authorization': f'Bearer {token}'}\n        response = requests.post(\n            f\"https://{target_service}/{endpoint}\",\n            json=data,\n            headers=headers\n        )\n        \n        return response.json()",
    "crumbs": [
      "Technical Blogs",
      "Quick Notes"
    ]
  },
  {
    "objectID": "technical-blogs/notes.html#quick-reference",
    "href": "technical-blogs/notes.html#quick-reference",
    "title": "Quick Notes",
    "section": "",
    "text": "Latency: Response time (P50, P95, P99)\nThroughput: Requests per second (RPS)\nError Rate: Percentage of failed requests\nResource Utilization: CPU, memory, disk, network\n\n\n\n\n\nRetry Pattern: Exponential backoff for transient failures\nBulkhead Pattern: Isolate failures between services\nCache-Aside: Application-managed caching\nEvent Sourcing: Store events instead of state\n\n\n\n\n\nGolden Signals: Latency, traffic, errors, saturation\nSLI/SLO: Service level indicators and objectives\nAlerting: Meaningful alerts with actionable information\nDashboards: Real-time visibility into system health\n\n\n\n\n\n\n\nNote-Taking Tips\n\n\n\n\nBe Concise: Focus on key insights and actionable items\nInclude Code: Practical examples help with implementation\nCategorize: Organize notes by topic and difficulty level\nReview Regularly: Revisit notes to reinforce learning",
    "crumbs": [
      "Technical Blogs",
      "Quick Notes"
    ]
  },
  {
    "objectID": "technical-blogs/breakdowns.html",
    "href": "technical-blogs/breakdowns.html",
    "title": "Blog Breakdowns",
    "section": "",
    "text": "Detailed analysis of technical articles, engineering blogs, and industry insights.\n\n\n\n\nSource: Netflix Tech Blog\nAuthor: Netflix Engineering Team\nDate: 2023\nCategory: Distributed Systems, Reliability Engineering\n\n\nNetflix’s approach to ensuring system resilience through controlled chaos engineering experiments that test how their distributed systems handle failures.\n\n\n\n\nChaos Monkey: Randomly terminates instances to test fault tolerance\nChaos Kong: Simulates entire AWS region failures\nFailure Injection Testing: Proactive approach to finding weaknesses\nAutomated Recovery: Systems must self-heal without human intervention\n\n\n\n\n\n\n# Example: Chaos Monkey implementation concept\nclass ChaosMonkey:\n    def __init__(self, target_services, failure_rate=0.01):\n        self.target_services = target_services\n        self.failure_rate = failure_rate\n    \n    def run_experiment(self):\n        for service in self.target_services:\n            if random.random() &lt; self.failure_rate:\n                self.terminate_instance(service)\n    \n    def terminate_instance(self, service):\n        # Simulate instance termination\n        print(f\"Terminating instance in {service}\")\n        # Actual implementation would use AWS API\n\n\n\n\nInstance Failures: Random EC2 instance termination\nNetwork Partitions: Simulate network connectivity issues\nDatabase Failures: Primary database unavailability\nRegion Failures: Entire AWS region going down\nDependency Failures: Third-party service outages\n\n\n\n\n\n\nProactive Testing: Better to find failures in controlled environment\nAutomated Recovery: Systems should heal themselves\nGradual Rollout: Start with small experiments, scale up\nMonitoring: Comprehensive observability is crucial\nTeam Culture: Engineering teams must embrace failure as learning\n\n\n\n\n\nImplement chaos engineering in your own systems\nStart with simple failure injection tests\nBuild automated recovery mechanisms\nCreate comprehensive monitoring and alerting\n\n\n\n\n\n\nSource: Uber Engineering Blog\nAuthor: Uber Data Team\nDate: 2023\nCategory: Data Engineering, Real-time Systems\n\n\nUber’s architecture for processing and serving real-time data at massive scale, handling millions of events per second across their global platform.\n\n\n\n\nApache Kafka: Primary message streaming platform\nApache Flink: Real-time stream processing engine\nApache Pinot: Real-time analytics database\nMicroservices Architecture: Decoupled data processing services\n\n\n\n\n\n\n┌─────────┐    ┌─────────┐    ┌─────────┐    ┌─────────┐\n│  Event  │───▶│  Kafka  │───▶│  Flink  │───▶│  Pinot  │\n│Sources  │    │ Streams │    │Process  │    │Analytics│\n└─────────┘    └─────────┘    └─────────┘    └─────────┘\n     │              │              │              │\n     ▼              ▼              ▼              ▼\n┌─────────┐    ┌─────────┐    ┌─────────┐    ┌─────────┐\n│  Mobile │    │  Batch  │    │  Real-  │    │  Query  │\n│   App   │    │Storage  │    │  time   │    │  API    │\n└─────────┘    └─────────┘    └─────────┘    └─────────┘\n\n\n\n# Example: Flink job for ride analytics\nfrom pyflink.datastream import StreamExecutionEnvironment\nfrom pyflink.table import StreamTableEnvironment\n\ndef process_ride_events():\n    env = StreamExecutionEnvironment.get_execution_environment()\n    t_env = StreamTableEnvironment.create(env)\n    \n    # Create table from Kafka topic\n    t_env.execute_sql(\"\"\"\n        CREATE TABLE ride_events (\n            ride_id STRING,\n            driver_id STRING,\n            rider_id STRING,\n            pickup_location STRING,\n            dropoff_location STRING,\n            event_time TIMESTAMP(3),\n            WATERMARK FOR event_time AS event_time - INTERVAL '5' SECOND\n        ) WITH (\n            'connector' = 'kafka',\n            'topic' = 'ride-events',\n            'properties.bootstrap.servers' = 'localhost:9092',\n            'format' = 'json'\n        )\n    \"\"\")\n    \n    # Process events in real-time\n    result = t_env.sql_query(\"\"\"\n        SELECT \n            driver_id,\n            COUNT(*) as rides_count,\n            AVG(ride_duration) as avg_duration\n        FROM ride_events\n        GROUP BY driver_id, TUMBLE(event_time, INTERVAL '1' HOUR)\n    \"\"\")\n    \n    return result\n\n\n\n\n\nEvent-Driven Architecture: Decouple data producers from consumers\nStream Processing: Real-time analytics enable better decision making\nScalability: Horizontal scaling through partitioning\nFault Tolerance: Exactly-once processing semantics\nData Governance: Schema evolution and data quality\n\n\n\n\n\nData Volume: Partitioning and parallel processing\nLatency: Optimized data pipelines and caching\nConsistency: Event sourcing and CQRS patterns\nMonitoring: Real-time metrics and alerting\n\n\n\n\n\n\nSource: Google Research Paper\nAuthor: Google Spanner Team\nDate: 2012 (Updated 2023)\nCategory: Distributed Systems, Databases\n\n\nGoogle Spanner is a globally distributed database that provides external consistency and high availability across data centers worldwide.\n\n\n\n\nGlobal Distribution: Data replicated across multiple continents\nExternal Consistency: Strong consistency across all replicas\nTrueTime API: Hardware clocks synchronized with GPS/atomic clocks\nPaxos Consensus: Distributed consensus for data replication\n\n\n\n\n\n\n# Conceptual TrueTime API implementation\nclass TrueTimeAPI:\n    def __init__(self):\n        self.uncertainty = 1  # milliseconds\n    \n    def now(self):\n        # Returns time with uncertainty bounds\n        current_time = get_gps_time()\n        return {\n            'earliest': current_time - self.uncertainty,\n            'latest': current_time + self.uncertainty\n        }\n    \n    def after(self, time):\n        # Returns true if current time is definitely after given time\n        return self.now()['earliest'] &gt; time\n    \n    def before(self, time):\n        # Returns true if current time is definitely before given time\n        return self.now()['latest'] &lt; time\n\n\n\nclass SpannerTransaction:\n    def __init__(self, participants):\n        self.participants = participants\n        self.truetime = TrueTimeAPI()\n    \n    def commit(self):\n        # Phase 1: Prepare\n        prepare_results = []\n        for participant in self.participants:\n            result = participant.prepare()\n            prepare_results.append(result)\n        \n        if all(prepare_results):\n            # Phase 2: Commit\n            commit_time = self.truetime.now()['latest']\n            \n            # Wait until commit_time has definitely passed\n            while not self.truetime.after(commit_time):\n                time.sleep(0.001)  # 1ms\n            \n            for participant in self.participants:\n                participant.commit(commit_time)\n            \n            return True\n        else:\n            # Abort\n            for participant in self.participants:\n                participant.abort()\n            return False\n\n\n\n\n\nGlobal Consistency: Possible with precise time synchronization\nHardware Dependencies: GPS and atomic clocks for time accuracy\nPerformance Trade-offs: Consistency vs latency considerations\nOperational Complexity: Managing distributed systems at scale\n\n\n\n\n\nMulti-Region Deployments: Consistent data across continents\nFinancial Transactions: ACID properties for critical operations\nReal-time Analytics: Consistent reads for business intelligence\nCompliance: Data sovereignty and regulatory requirements\n\n\n\n\n\n\nSource: Airbnb Engineering Blog\nAuthor: Airbnb Data Science Team\nDate: 2023\nCategory: Machine Learning, Data Infrastructure\n\n\nAirbnb’s platform for building, deploying, and monitoring machine learning models at scale, supporting hundreds of ML models in production.\n\n\n\n\nBighead: Airbnb’s ML platform built on Kubernetes\nFeature Store: Centralized feature management and serving\nModel Serving: Real-time prediction serving infrastructure\nA/B Testing: Framework for model experimentation\n\n\n\n\n\n\n# Example: Feature store implementation\nclass FeatureStore:\n    def __init__(self):\n        self.feature_registry = {}\n        self.feature_serving = {}\n    \n    def register_feature(self, name, feature_definition):\n        \"\"\"Register a new feature definition\"\"\"\n        self.feature_registry[name] = {\n            'definition': feature_definition,\n            'data_type': feature_definition.data_type,\n            'freshness': feature_definition.freshness,\n            'serving_type': feature_definition.serving_type\n        }\n    \n    def get_feature(self, feature_name, entity_id, timestamp=None):\n        \"\"\"Get feature value for an entity\"\"\"\n        if feature_name not in self.feature_serving:\n            raise ValueError(f\"Feature {feature_name} not found\")\n        \n        return self.feature_serving[feature_name].get_value(\n            entity_id, timestamp\n        )\n    \n    def get_features(self, feature_names, entity_id, timestamp=None):\n        \"\"\"Get multiple features for an entity\"\"\"\n        features = {}\n        for name in feature_names:\n            features[name] = self.get_feature(name, entity_id, timestamp)\n        return features\n\n\n\nclass ModelServing:\n    def __init__(self, model_registry):\n        self.model_registry = model_registry\n        self.active_models = {}\n    \n    def deploy_model(self, model_name, model_version):\n        \"\"\"Deploy a model version to production\"\"\"\n        model = self.model_registry.get_model(model_name, model_version)\n        \n        # Create Kubernetes deployment\n        deployment = self.create_deployment(model)\n        \n        # Update load balancer\n        self.update_routing(model_name, deployment)\n        \n        self.active_models[model_name] = {\n            'version': model_version,\n            'deployment': deployment\n        }\n    \n    def predict(self, model_name, features):\n        \"\"\"Make prediction using deployed model\"\"\"\n        if model_name not in self.active_models:\n            raise ValueError(f\"Model {model_name} not deployed\")\n        \n        # Route to appropriate model instance\n        model_endpoint = self.get_model_endpoint(model_name)\n        \n        # Make prediction\n        response = requests.post(\n            f\"{model_endpoint}/predict\",\n            json={'features': features}\n        )\n        \n        return response.json()['prediction']\n\n\n\n\n\nFeature Engineering: Centralized feature management is crucial\nModel Lifecycle: Automated deployment and monitoring\nA/B Testing: Rigorous experimentation framework\nScalability: Kubernetes-based infrastructure for ML workloads\nMonitoring: Comprehensive ML model observability\n\n\n\n\n\nFeature Versioning: Track feature changes over time\nModel Monitoring: Monitor drift, performance, and business metrics\nAutomated Pipelines: CI/CD for ML models\nExperimentation: Systematic A/B testing framework\n\n\n\n\n\n\n\n\n\n\nBeginner: Basic concepts, high-level architecture\nIntermediate: Implementation details, trade-offs\nAdvanced: Deep technical insights, performance characteristics\n\n\n\n\n\nImmediate: Can be applied to current projects\nShort-term: Requires some infrastructure changes\nLong-term: Strategic architectural decisions\n\n\n\n\n\nHigh: Novel concepts, industry best practices\nMedium: Good implementation examples\nLow: Basic concepts, limited new insights\n\n\n\n\n\n\n\nReading Recommendations\n\n\n\n\nStart with: Company engineering blogs for practical insights\nDeep dive: Research papers for theoretical foundations\nStay current: Follow industry leaders and conferences\nPractice: Implement concepts in your own projects",
    "crumbs": [
      "Technical Blogs",
      "Blog Breakdowns"
    ]
  },
  {
    "objectID": "technical-blogs/breakdowns.html#recent-breakdowns",
    "href": "technical-blogs/breakdowns.html#recent-breakdowns",
    "title": "Blog Breakdowns",
    "section": "",
    "text": "Source: Netflix Tech Blog\nAuthor: Netflix Engineering Team\nDate: 2023\nCategory: Distributed Systems, Reliability Engineering\n\n\nNetflix’s approach to ensuring system resilience through controlled chaos engineering experiments that test how their distributed systems handle failures.\n\n\n\n\nChaos Monkey: Randomly terminates instances to test fault tolerance\nChaos Kong: Simulates entire AWS region failures\nFailure Injection Testing: Proactive approach to finding weaknesses\nAutomated Recovery: Systems must self-heal without human intervention\n\n\n\n\n\n\n# Example: Chaos Monkey implementation concept\nclass ChaosMonkey:\n    def __init__(self, target_services, failure_rate=0.01):\n        self.target_services = target_services\n        self.failure_rate = failure_rate\n    \n    def run_experiment(self):\n        for service in self.target_services:\n            if random.random() &lt; self.failure_rate:\n                self.terminate_instance(service)\n    \n    def terminate_instance(self, service):\n        # Simulate instance termination\n        print(f\"Terminating instance in {service}\")\n        # Actual implementation would use AWS API\n\n\n\n\nInstance Failures: Random EC2 instance termination\nNetwork Partitions: Simulate network connectivity issues\nDatabase Failures: Primary database unavailability\nRegion Failures: Entire AWS region going down\nDependency Failures: Third-party service outages\n\n\n\n\n\n\nProactive Testing: Better to find failures in controlled environment\nAutomated Recovery: Systems should heal themselves\nGradual Rollout: Start with small experiments, scale up\nMonitoring: Comprehensive observability is crucial\nTeam Culture: Engineering teams must embrace failure as learning\n\n\n\n\n\nImplement chaos engineering in your own systems\nStart with simple failure injection tests\nBuild automated recovery mechanisms\nCreate comprehensive monitoring and alerting\n\n\n\n\n\n\nSource: Uber Engineering Blog\nAuthor: Uber Data Team\nDate: 2023\nCategory: Data Engineering, Real-time Systems\n\n\nUber’s architecture for processing and serving real-time data at massive scale, handling millions of events per second across their global platform.\n\n\n\n\nApache Kafka: Primary message streaming platform\nApache Flink: Real-time stream processing engine\nApache Pinot: Real-time analytics database\nMicroservices Architecture: Decoupled data processing services\n\n\n\n\n\n\n┌─────────┐    ┌─────────┐    ┌─────────┐    ┌─────────┐\n│  Event  │───▶│  Kafka  │───▶│  Flink  │───▶│  Pinot  │\n│Sources  │    │ Streams │    │Process  │    │Analytics│\n└─────────┘    └─────────┘    └─────────┘    └─────────┘\n     │              │              │              │\n     ▼              ▼              ▼              ▼\n┌─────────┐    ┌─────────┐    ┌─────────┐    ┌─────────┐\n│  Mobile │    │  Batch  │    │  Real-  │    │  Query  │\n│   App   │    │Storage  │    │  time   │    │  API    │\n└─────────┘    └─────────┘    └─────────┘    └─────────┘\n\n\n\n# Example: Flink job for ride analytics\nfrom pyflink.datastream import StreamExecutionEnvironment\nfrom pyflink.table import StreamTableEnvironment\n\ndef process_ride_events():\n    env = StreamExecutionEnvironment.get_execution_environment()\n    t_env = StreamTableEnvironment.create(env)\n    \n    # Create table from Kafka topic\n    t_env.execute_sql(\"\"\"\n        CREATE TABLE ride_events (\n            ride_id STRING,\n            driver_id STRING,\n            rider_id STRING,\n            pickup_location STRING,\n            dropoff_location STRING,\n            event_time TIMESTAMP(3),\n            WATERMARK FOR event_time AS event_time - INTERVAL '5' SECOND\n        ) WITH (\n            'connector' = 'kafka',\n            'topic' = 'ride-events',\n            'properties.bootstrap.servers' = 'localhost:9092',\n            'format' = 'json'\n        )\n    \"\"\")\n    \n    # Process events in real-time\n    result = t_env.sql_query(\"\"\"\n        SELECT \n            driver_id,\n            COUNT(*) as rides_count,\n            AVG(ride_duration) as avg_duration\n        FROM ride_events\n        GROUP BY driver_id, TUMBLE(event_time, INTERVAL '1' HOUR)\n    \"\"\")\n    \n    return result\n\n\n\n\n\nEvent-Driven Architecture: Decouple data producers from consumers\nStream Processing: Real-time analytics enable better decision making\nScalability: Horizontal scaling through partitioning\nFault Tolerance: Exactly-once processing semantics\nData Governance: Schema evolution and data quality\n\n\n\n\n\nData Volume: Partitioning and parallel processing\nLatency: Optimized data pipelines and caching\nConsistency: Event sourcing and CQRS patterns\nMonitoring: Real-time metrics and alerting\n\n\n\n\n\n\nSource: Google Research Paper\nAuthor: Google Spanner Team\nDate: 2012 (Updated 2023)\nCategory: Distributed Systems, Databases\n\n\nGoogle Spanner is a globally distributed database that provides external consistency and high availability across data centers worldwide.\n\n\n\n\nGlobal Distribution: Data replicated across multiple continents\nExternal Consistency: Strong consistency across all replicas\nTrueTime API: Hardware clocks synchronized with GPS/atomic clocks\nPaxos Consensus: Distributed consensus for data replication\n\n\n\n\n\n\n# Conceptual TrueTime API implementation\nclass TrueTimeAPI:\n    def __init__(self):\n        self.uncertainty = 1  # milliseconds\n    \n    def now(self):\n        # Returns time with uncertainty bounds\n        current_time = get_gps_time()\n        return {\n            'earliest': current_time - self.uncertainty,\n            'latest': current_time + self.uncertainty\n        }\n    \n    def after(self, time):\n        # Returns true if current time is definitely after given time\n        return self.now()['earliest'] &gt; time\n    \n    def before(self, time):\n        # Returns true if current time is definitely before given time\n        return self.now()['latest'] &lt; time\n\n\n\nclass SpannerTransaction:\n    def __init__(self, participants):\n        self.participants = participants\n        self.truetime = TrueTimeAPI()\n    \n    def commit(self):\n        # Phase 1: Prepare\n        prepare_results = []\n        for participant in self.participants:\n            result = participant.prepare()\n            prepare_results.append(result)\n        \n        if all(prepare_results):\n            # Phase 2: Commit\n            commit_time = self.truetime.now()['latest']\n            \n            # Wait until commit_time has definitely passed\n            while not self.truetime.after(commit_time):\n                time.sleep(0.001)  # 1ms\n            \n            for participant in self.participants:\n                participant.commit(commit_time)\n            \n            return True\n        else:\n            # Abort\n            for participant in self.participants:\n                participant.abort()\n            return False\n\n\n\n\n\nGlobal Consistency: Possible with precise time synchronization\nHardware Dependencies: GPS and atomic clocks for time accuracy\nPerformance Trade-offs: Consistency vs latency considerations\nOperational Complexity: Managing distributed systems at scale\n\n\n\n\n\nMulti-Region Deployments: Consistent data across continents\nFinancial Transactions: ACID properties for critical operations\nReal-time Analytics: Consistent reads for business intelligence\nCompliance: Data sovereignty and regulatory requirements\n\n\n\n\n\n\nSource: Airbnb Engineering Blog\nAuthor: Airbnb Data Science Team\nDate: 2023\nCategory: Machine Learning, Data Infrastructure\n\n\nAirbnb’s platform for building, deploying, and monitoring machine learning models at scale, supporting hundreds of ML models in production.\n\n\n\n\nBighead: Airbnb’s ML platform built on Kubernetes\nFeature Store: Centralized feature management and serving\nModel Serving: Real-time prediction serving infrastructure\nA/B Testing: Framework for model experimentation\n\n\n\n\n\n\n# Example: Feature store implementation\nclass FeatureStore:\n    def __init__(self):\n        self.feature_registry = {}\n        self.feature_serving = {}\n    \n    def register_feature(self, name, feature_definition):\n        \"\"\"Register a new feature definition\"\"\"\n        self.feature_registry[name] = {\n            'definition': feature_definition,\n            'data_type': feature_definition.data_type,\n            'freshness': feature_definition.freshness,\n            'serving_type': feature_definition.serving_type\n        }\n    \n    def get_feature(self, feature_name, entity_id, timestamp=None):\n        \"\"\"Get feature value for an entity\"\"\"\n        if feature_name not in self.feature_serving:\n            raise ValueError(f\"Feature {feature_name} not found\")\n        \n        return self.feature_serving[feature_name].get_value(\n            entity_id, timestamp\n        )\n    \n    def get_features(self, feature_names, entity_id, timestamp=None):\n        \"\"\"Get multiple features for an entity\"\"\"\n        features = {}\n        for name in feature_names:\n            features[name] = self.get_feature(name, entity_id, timestamp)\n        return features\n\n\n\nclass ModelServing:\n    def __init__(self, model_registry):\n        self.model_registry = model_registry\n        self.active_models = {}\n    \n    def deploy_model(self, model_name, model_version):\n        \"\"\"Deploy a model version to production\"\"\"\n        model = self.model_registry.get_model(model_name, model_version)\n        \n        # Create Kubernetes deployment\n        deployment = self.create_deployment(model)\n        \n        # Update load balancer\n        self.update_routing(model_name, deployment)\n        \n        self.active_models[model_name] = {\n            'version': model_version,\n            'deployment': deployment\n        }\n    \n    def predict(self, model_name, features):\n        \"\"\"Make prediction using deployed model\"\"\"\n        if model_name not in self.active_models:\n            raise ValueError(f\"Model {model_name} not deployed\")\n        \n        # Route to appropriate model instance\n        model_endpoint = self.get_model_endpoint(model_name)\n        \n        # Make prediction\n        response = requests.post(\n            f\"{model_endpoint}/predict\",\n            json={'features': features}\n        )\n        \n        return response.json()['prediction']\n\n\n\n\n\nFeature Engineering: Centralized feature management is crucial\nModel Lifecycle: Automated deployment and monitoring\nA/B Testing: Rigorous experimentation framework\nScalability: Kubernetes-based infrastructure for ML workloads\nMonitoring: Comprehensive ML model observability\n\n\n\n\n\nFeature Versioning: Track feature changes over time\nModel Monitoring: Monitor drift, performance, and business metrics\nAutomated Pipelines: CI/CD for ML models\nExperimentation: Systematic A/B testing framework",
    "crumbs": [
      "Technical Blogs",
      "Blog Breakdowns"
    ]
  },
  {
    "objectID": "technical-blogs/breakdowns.html#analysis-framework",
    "href": "technical-blogs/breakdowns.html#analysis-framework",
    "title": "Blog Breakdowns",
    "section": "",
    "text": "Beginner: Basic concepts, high-level architecture\nIntermediate: Implementation details, trade-offs\nAdvanced: Deep technical insights, performance characteristics\n\n\n\n\n\nImmediate: Can be applied to current projects\nShort-term: Requires some infrastructure changes\nLong-term: Strategic architectural decisions\n\n\n\n\n\nHigh: Novel concepts, industry best practices\nMedium: Good implementation examples\nLow: Basic concepts, limited new insights\n\n\n\n\n\n\n\nReading Recommendations\n\n\n\n\nStart with: Company engineering blogs for practical insights\nDeep dive: Research papers for theoretical foundations\nStay current: Follow industry leaders and conferences\nPractice: Implement concepts in your own projects",
    "crumbs": [
      "Technical Blogs",
      "Blog Breakdowns"
    ]
  },
  {
    "objectID": "dsa/index.html",
    "href": "dsa/index.html",
    "title": "Data Structures & Algorithms",
    "section": "",
    "text": "Welcome to my DSA learning journey! This section covers fundamental computer science concepts, problem-solving techniques, and algorithmic thinking.\n\n\n\nData Structures - Arrays, Linked Lists, Trees, Graphs, Hash Tables, etc.\nAlgorithms - Sorting, Searching, Dynamic Programming, Greedy, etc.\nProblems - Practice problems and solutions\n\n\n\n\n\n\n\n“Introduction to Algorithms” (CLRS)\n“Cracking the Coding Interview”\n“Algorithms” by Robert Sedgewick\n\n\n\n\n\nLeetCode\nHackerRank\nCodeforces\nAtCoder\n\n\n\n\n\n\n\nLinear: Arrays, Linked Lists, Stacks, Queues\nTree-based: Binary Trees, BST, AVL, Red-Black Trees\nGraph-based: Adjacency Matrix/List, BFS/DFS\nHash-based: Hash Tables, Hash Sets\nAdvanced: Heaps, Tries, Segment Trees\n\n\n\n\n\nBrute Force: Complete search, backtracking\nDivide & Conquer: Merge sort, quick sort, binary search\nDynamic Programming: Memoization, tabulation\nGreedy: Local optimal choices\nTwo Pointers: Sliding window, fast/slow pointers\n\n\n\n\n\nBig O notation\nSpace complexity\nBest/worst/average case analysis\n\n\n\n\n\n\n\n\n\n\n\n\nCurrent Focus\n\n\n\nWorking on dynamic programming problems and advanced tree algorithms.\n\n\n\n\n\n\n\n\nPro Tip\n\n\n\nPractice implementing data structures from scratch to truly understand their internals.",
    "crumbs": [
      "Data Structures & Algorithms"
    ]
  },
  {
    "objectID": "dsa/index.html#quick-navigation",
    "href": "dsa/index.html#quick-navigation",
    "title": "Data Structures & Algorithms",
    "section": "",
    "text": "Data Structures - Arrays, Linked Lists, Trees, Graphs, Hash Tables, etc.\nAlgorithms - Sorting, Searching, Dynamic Programming, Greedy, etc.\nProblems - Practice problems and solutions",
    "crumbs": [
      "Data Structures & Algorithms"
    ]
  },
  {
    "objectID": "dsa/index.html#learning-resources",
    "href": "dsa/index.html#learning-resources",
    "title": "Data Structures & Algorithms",
    "section": "",
    "text": "“Introduction to Algorithms” (CLRS)\n“Cracking the Coding Interview”\n“Algorithms” by Robert Sedgewick\n\n\n\n\n\nLeetCode\nHackerRank\nCodeforces\nAtCoder\n\n\n\n\n\n\n\nLinear: Arrays, Linked Lists, Stacks, Queues\nTree-based: Binary Trees, BST, AVL, Red-Black Trees\nGraph-based: Adjacency Matrix/List, BFS/DFS\nHash-based: Hash Tables, Hash Sets\nAdvanced: Heaps, Tries, Segment Trees\n\n\n\n\n\nBrute Force: Complete search, backtracking\nDivide & Conquer: Merge sort, quick sort, binary search\nDynamic Programming: Memoization, tabulation\nGreedy: Local optimal choices\nTwo Pointers: Sliding window, fast/slow pointers\n\n\n\n\n\nBig O notation\nSpace complexity\nBest/worst/average case analysis",
    "crumbs": [
      "Data Structures & Algorithms"
    ]
  },
  {
    "objectID": "dsa/index.html#recent-learning-notes",
    "href": "dsa/index.html#recent-learning-notes",
    "title": "Data Structures & Algorithms",
    "section": "",
    "text": "Current Focus\n\n\n\nWorking on dynamic programming problems and advanced tree algorithms.\n\n\n\n\n\n\n\n\nPro Tip\n\n\n\nPractice implementing data structures from scratch to truly understand their internals.",
    "crumbs": [
      "Data Structures & Algorithms"
    ]
  },
  {
    "objectID": "dsa/problems.html",
    "href": "dsa/problems.html",
    "title": "Practice Problems",
    "section": "",
    "text": "A collection of DSA problems with solutions and explanations.\n\n\n\n\nProblem: Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target.\ndef two_sum(nums, target):\n    seen = {}\n    for i, num in enumerate(nums):\n        complement = target - num\n        if complement in seen:\n            return [seen[complement], i]\n        seen[num] = i\n    return []\n\n# Example\nnums = [2, 7, 11, 15]\ntarget = 9\nprint(two_sum(nums, target))  # [0, 1]\nTime Complexity: O(n)\nSpace Complexity: O(n)\n\n\n\nProblem: Given a string s containing just the characters '(', ')', '{', '}', '[' and ']', determine if the input string is valid.\ndef is_valid(s):\n    stack = []\n    brackets = {')': '(', '}': '{', ']': '['}\n    \n    for char in s:\n        if char in '({[':\n            stack.append(char)\n        elif char in ')}]':\n            if not stack or stack.pop() != brackets[char]:\n                return False\n    \n    return len(stack) == 0\n\n# Example\nprint(is_valid(\"()[]{}\"))  # True\nprint(is_valid(\"([)]\"))    # False\nTime Complexity: O(n)\nSpace Complexity: O(n)\n\n\n\n\n\n\nProblem: Given a string s, find the length of the longest substring without repeating characters.\ndef length_of_longest_substring(s):\n    char_map = {}\n    left = 0\n    max_length = 0\n    \n    for right, char in enumerate(s):\n        if char in char_map and char_map[char] &gt;= left:\n            left = char_map[char] + 1\n        char_map[char] = right\n        max_length = max(max_length, right - left + 1)\n    \n    return max_length\n\n# Example\nprint(length_of_longest_substring(\"abcabcbb\"))  # 3\nTime Complexity: O(n)\nSpace Complexity: O(min(m, n)) where m is charset size\n\n\n\nProblem: Merge two sorted linked lists and return it as a sorted list.\nclass ListNode:\n    def __init__(self, val=0, next=None):\n        self.val = val\n        self.next = next\n\ndef merge_two_lists(l1, l2):\n    dummy = ListNode(0)\n    current = dummy\n    \n    while l1 and l2:\n        if l1.val &lt;= l2.val:\n            current.next = l1\n            l1 = l1.next\n        else:\n            current.next = l2\n            l2 = l2.next\n        current = current.next\n    \n    current.next = l1 if l1 else l2\n    return dummy.next\nTime Complexity: O(n + m)\nSpace Complexity: O(1)\n\n\n\n\n\n\nProblem: Find the median of two sorted arrays nums1 and nums2.\ndef find_median_sorted_arrays(nums1, nums2):\n    # Ensure nums1 is the smaller array\n    if len(nums1) &gt; len(nums2):\n        nums1, nums2 = nums2, nums1\n    \n    x, y = len(nums1), len(nums2)\n    low, high = 0, x\n    \n    while low &lt;= high:\n        partitionX = (low + high) // 2\n        partitionY = (x + y + 1) // 2 - partitionX\n        \n        # Find the elements around the partition\n        maxLeftX = float('-inf') if partitionX == 0 else nums1[partitionX - 1]\n        minRightX = float('inf') if partitionX == x else nums1[partitionX]\n        \n        maxLeftY = float('-inf') if partitionY == 0 else nums2[partitionY - 1]\n        minRightY = float('inf') if partitionY == y else nums2[partitionY]\n        \n        # Check if we found the correct partition\n        if maxLeftX &lt;= minRightY and maxLeftY &lt;= minRightX:\n            # Found the correct partition\n            if (x + y) % 2 == 0:\n                return (max(maxLeftX, maxLeftY) + min(minRightX, minRightY)) / 2\n            else:\n                return max(maxLeftX, maxLeftY)\n        elif maxLeftX &gt; minRightY:\n            high = partitionX - 1\n        else:\n            low = partitionX + 1\n    \n    raise ValueError(\"Input arrays are not sorted\")\nTime Complexity: O(log(min(m, n)))\nSpace Complexity: O(1)\n\n\n\n\n\n\nProblem: You are climbing a staircase. It takes n steps to reach the top. Each time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top?\ndef climb_stairs(n):\n    if n &lt;= 2:\n        return n\n    \n    dp = [0] * (n + 1)\n    dp[1] = 1\n    dp[2] = 2\n    \n    for i in range(3, n + 1):\n        dp[i] = dp[i-1] + dp[i-2]\n    \n    return dp[n]\n\n# Space optimized version\ndef climb_stairs_optimized(n):\n    if n &lt;= 2:\n        return n\n    \n    prev, curr = 1, 2\n    for i in range(3, n + 1):\n        prev, curr = curr, prev + curr\n    \n    return curr\nTime Complexity: O(n)\nSpace Complexity: O(1) for optimized version\n\n\n\nProblem: Given an integer array nums, return the length of the longest strictly increasing subsequence.\ndef length_of_lis(nums):\n    if not nums:\n        return 0\n    \n    dp = [1] * len(nums)\n    \n    for i in range(1, len(nums)):\n        for j in range(i):\n            if nums[i] &gt; nums[j]:\n                dp[i] = max(dp[i], dp[j] + 1)\n    \n    return max(dp)\n\n# Binary search approach (more efficient)\ndef length_of_lis_binary(nums):\n    sub = []\n    \n    for num in nums:\n        i = bisect_left(sub, num)\n        if i == len(sub):\n            sub.append(num)\n        else:\n            sub[i] = num\n    \n    return len(sub)\nTime Complexity: O(n²) for DP, O(n log n) for binary search\nSpace Complexity: O(n)\n\n\n\n\n\n\nProblem: Given an m x n 2D binary grid grid which represents a map of '1's (land) and '0's (water), return the number of islands.\ndef num_islands(grid):\n    if not grid:\n        return 0\n    \n    def dfs(i, j):\n        if (i &lt; 0 or i &gt;= len(grid) or \n            j &lt; 0 or j &gt;= len(grid[0]) or \n            grid[i][j] == '0'):\n            return\n        \n        grid[i][j] = '0'  # Mark as visited\n        dfs(i+1, j)\n        dfs(i-1, j)\n        dfs(i, j+1)\n        dfs(i, j-1)\n    \n    count = 0\n    for i in range(len(grid)):\n        for j in range(len(grid[0])):\n            if grid[i][j] == '1':\n                dfs(i, j)\n                count += 1\n    \n    return count\nTime Complexity: O(m × n)\nSpace Complexity: O(m × n) in worst case\n\n\n\n\n\n\n\n\n\n\nBefore Starting\n\n\n\n\nUnderstand the problem: Read carefully, identify inputs/outputs\nConsider examples: Work through small examples manually\nIdentify patterns: Look for common algorithmic patterns\nPlan your approach: Choose appropriate data structures\nConsider edge cases: Empty inputs, single elements, etc.\n\n\n\n\n\n\n\n\n\nCommon Mistakes\n\n\n\n\nNot handling edge cases\nIncorrect time/space complexity analysis\nNot optimizing for the specific constraints\nOvercomplicating simple problems\n\n\n\n\n\n\n\n\n\nLeetCode: 2000+ problems with varying difficulty\nHackerRank: Good for beginners, company-specific problems\nCodeforces: Competitive programming, regular contests\nAtCoder: Japanese platform, good for learning\n\n\n\n\n\nArrays & Strings: Two pointers, sliding window, prefix sums\nLinked Lists: Fast/slow pointers, reversing, merging\nTrees: DFS/BFS, recursion, tree construction\nGraphs: DFS/BFS, shortest paths, topological sort\nDynamic Programming: Memoization, tabulation, state transitions\nBinary Search: Finding boundaries, optimization problems",
    "crumbs": [
      "Data Structures & Algorithms",
      "Practice Problems"
    ]
  },
  {
    "objectID": "dsa/problems.html#easy-problems",
    "href": "dsa/problems.html#easy-problems",
    "title": "Practice Problems",
    "section": "",
    "text": "Problem: Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target.\ndef two_sum(nums, target):\n    seen = {}\n    for i, num in enumerate(nums):\n        complement = target - num\n        if complement in seen:\n            return [seen[complement], i]\n        seen[num] = i\n    return []\n\n# Example\nnums = [2, 7, 11, 15]\ntarget = 9\nprint(two_sum(nums, target))  # [0, 1]\nTime Complexity: O(n)\nSpace Complexity: O(n)\n\n\n\nProblem: Given a string s containing just the characters '(', ')', '{', '}', '[' and ']', determine if the input string is valid.\ndef is_valid(s):\n    stack = []\n    brackets = {')': '(', '}': '{', ']': '['}\n    \n    for char in s:\n        if char in '({[':\n            stack.append(char)\n        elif char in ')}]':\n            if not stack or stack.pop() != brackets[char]:\n                return False\n    \n    return len(stack) == 0\n\n# Example\nprint(is_valid(\"()[]{}\"))  # True\nprint(is_valid(\"([)]\"))    # False\nTime Complexity: O(n)\nSpace Complexity: O(n)",
    "crumbs": [
      "Data Structures & Algorithms",
      "Practice Problems"
    ]
  },
  {
    "objectID": "dsa/problems.html#medium-problems",
    "href": "dsa/problems.html#medium-problems",
    "title": "Practice Problems",
    "section": "",
    "text": "Problem: Given a string s, find the length of the longest substring without repeating characters.\ndef length_of_longest_substring(s):\n    char_map = {}\n    left = 0\n    max_length = 0\n    \n    for right, char in enumerate(s):\n        if char in char_map and char_map[char] &gt;= left:\n            left = char_map[char] + 1\n        char_map[char] = right\n        max_length = max(max_length, right - left + 1)\n    \n    return max_length\n\n# Example\nprint(length_of_longest_substring(\"abcabcbb\"))  # 3\nTime Complexity: O(n)\nSpace Complexity: O(min(m, n)) where m is charset size\n\n\n\nProblem: Merge two sorted linked lists and return it as a sorted list.\nclass ListNode:\n    def __init__(self, val=0, next=None):\n        self.val = val\n        self.next = next\n\ndef merge_two_lists(l1, l2):\n    dummy = ListNode(0)\n    current = dummy\n    \n    while l1 and l2:\n        if l1.val &lt;= l2.val:\n            current.next = l1\n            l1 = l1.next\n        else:\n            current.next = l2\n            l2 = l2.next\n        current = current.next\n    \n    current.next = l1 if l1 else l2\n    return dummy.next\nTime Complexity: O(n + m)\nSpace Complexity: O(1)",
    "crumbs": [
      "Data Structures & Algorithms",
      "Practice Problems"
    ]
  },
  {
    "objectID": "dsa/problems.html#hard-problems",
    "href": "dsa/problems.html#hard-problems",
    "title": "Practice Problems",
    "section": "",
    "text": "Problem: Find the median of two sorted arrays nums1 and nums2.\ndef find_median_sorted_arrays(nums1, nums2):\n    # Ensure nums1 is the smaller array\n    if len(nums1) &gt; len(nums2):\n        nums1, nums2 = nums2, nums1\n    \n    x, y = len(nums1), len(nums2)\n    low, high = 0, x\n    \n    while low &lt;= high:\n        partitionX = (low + high) // 2\n        partitionY = (x + y + 1) // 2 - partitionX\n        \n        # Find the elements around the partition\n        maxLeftX = float('-inf') if partitionX == 0 else nums1[partitionX - 1]\n        minRightX = float('inf') if partitionX == x else nums1[partitionX]\n        \n        maxLeftY = float('-inf') if partitionY == 0 else nums2[partitionY - 1]\n        minRightY = float('inf') if partitionY == y else nums2[partitionY]\n        \n        # Check if we found the correct partition\n        if maxLeftX &lt;= minRightY and maxLeftY &lt;= minRightX:\n            # Found the correct partition\n            if (x + y) % 2 == 0:\n                return (max(maxLeftX, maxLeftY) + min(minRightX, minRightY)) / 2\n            else:\n                return max(maxLeftX, maxLeftY)\n        elif maxLeftX &gt; minRightY:\n            high = partitionX - 1\n        else:\n            low = partitionX + 1\n    \n    raise ValueError(\"Input arrays are not sorted\")\nTime Complexity: O(log(min(m, n)))\nSpace Complexity: O(1)",
    "crumbs": [
      "Data Structures & Algorithms",
      "Practice Problems"
    ]
  },
  {
    "objectID": "dsa/problems.html#dynamic-programming-problems",
    "href": "dsa/problems.html#dynamic-programming-problems",
    "title": "Practice Problems",
    "section": "",
    "text": "Problem: You are climbing a staircase. It takes n steps to reach the top. Each time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top?\ndef climb_stairs(n):\n    if n &lt;= 2:\n        return n\n    \n    dp = [0] * (n + 1)\n    dp[1] = 1\n    dp[2] = 2\n    \n    for i in range(3, n + 1):\n        dp[i] = dp[i-1] + dp[i-2]\n    \n    return dp[n]\n\n# Space optimized version\ndef climb_stairs_optimized(n):\n    if n &lt;= 2:\n        return n\n    \n    prev, curr = 1, 2\n    for i in range(3, n + 1):\n        prev, curr = curr, prev + curr\n    \n    return curr\nTime Complexity: O(n)\nSpace Complexity: O(1) for optimized version\n\n\n\nProblem: Given an integer array nums, return the length of the longest strictly increasing subsequence.\ndef length_of_lis(nums):\n    if not nums:\n        return 0\n    \n    dp = [1] * len(nums)\n    \n    for i in range(1, len(nums)):\n        for j in range(i):\n            if nums[i] &gt; nums[j]:\n                dp[i] = max(dp[i], dp[j] + 1)\n    \n    return max(dp)\n\n# Binary search approach (more efficient)\ndef length_of_lis_binary(nums):\n    sub = []\n    \n    for num in nums:\n        i = bisect_left(sub, num)\n        if i == len(sub):\n            sub.append(num)\n        else:\n            sub[i] = num\n    \n    return len(sub)\nTime Complexity: O(n²) for DP, O(n log n) for binary search\nSpace Complexity: O(n)",
    "crumbs": [
      "Data Structures & Algorithms",
      "Practice Problems"
    ]
  },
  {
    "objectID": "dsa/problems.html#graph-problems",
    "href": "dsa/problems.html#graph-problems",
    "title": "Practice Problems",
    "section": "",
    "text": "Problem: Given an m x n 2D binary grid grid which represents a map of '1's (land) and '0's (water), return the number of islands.\ndef num_islands(grid):\n    if not grid:\n        return 0\n    \n    def dfs(i, j):\n        if (i &lt; 0 or i &gt;= len(grid) or \n            j &lt; 0 or j &gt;= len(grid[0]) or \n            grid[i][j] == '0'):\n            return\n        \n        grid[i][j] = '0'  # Mark as visited\n        dfs(i+1, j)\n        dfs(i-1, j)\n        dfs(i, j+1)\n        dfs(i, j-1)\n    \n    count = 0\n    for i in range(len(grid)):\n        for j in range(len(grid[0])):\n            if grid[i][j] == '1':\n                dfs(i, j)\n                count += 1\n    \n    return count\nTime Complexity: O(m × n)\nSpace Complexity: O(m × n) in worst case",
    "crumbs": [
      "Data Structures & Algorithms",
      "Practice Problems"
    ]
  },
  {
    "objectID": "dsa/problems.html#problem-solving-tips",
    "href": "dsa/problems.html#problem-solving-tips",
    "title": "Practice Problems",
    "section": "",
    "text": "Before Starting\n\n\n\n\nUnderstand the problem: Read carefully, identify inputs/outputs\nConsider examples: Work through small examples manually\nIdentify patterns: Look for common algorithmic patterns\nPlan your approach: Choose appropriate data structures\nConsider edge cases: Empty inputs, single elements, etc.\n\n\n\n\n\n\n\n\n\nCommon Mistakes\n\n\n\n\nNot handling edge cases\nIncorrect time/space complexity analysis\nNot optimizing for the specific constraints\nOvercomplicating simple problems",
    "crumbs": [
      "Data Structures & Algorithms",
      "Practice Problems"
    ]
  },
  {
    "objectID": "dsa/problems.html#practice-resources",
    "href": "dsa/problems.html#practice-resources",
    "title": "Practice Problems",
    "section": "",
    "text": "LeetCode: 2000+ problems with varying difficulty\nHackerRank: Good for beginners, company-specific problems\nCodeforces: Competitive programming, regular contests\nAtCoder: Japanese platform, good for learning\n\n\n\n\n\nArrays & Strings: Two pointers, sliding window, prefix sums\nLinked Lists: Fast/slow pointers, reversing, merging\nTrees: DFS/BFS, recursion, tree construction\nGraphs: DFS/BFS, shortest paths, topological sort\nDynamic Programming: Memoization, tabulation, state transitions\nBinary Search: Finding boundaries, optimization problems",
    "crumbs": [
      "Data Structures & Algorithms",
      "Practice Problems"
    ]
  },
  {
    "objectID": "books/index.html",
    "href": "books/index.html",
    "title": "Books",
    "section": "",
    "text": "Welcome to my Books section! Here I document my reading journey through technical books, share detailed notes, and track my learning progress across various software development topics.\n\n\n\nReading List - Current and planned books\nNotes - Detailed book notes and summaries\n\n\n\n\n\n\n\nCore Fundamentals: Algorithm design, complexity analysis\nProblem Solving: Interview preparation, competitive programming\nAdvanced Topics: Dynamic programming, graph algorithms\n\n\n\n\n\nDistributed Systems: Scalability, consistency, fault tolerance\nSoftware Architecture: Design patterns, best practices\nCloud-Native: Microservices, containers, serverless\n\n\n\n\n\nLanguage Deep Dives: Python, JavaScript, Go, Rust\nProgramming Paradigms: Functional, object-oriented, concurrent\nCode Quality: Clean code, refactoring, testing\n\n\n\n\n\nContainerization: Docker, Kubernetes, orchestration\nCloud Platforms: AWS, GCP, Azure services and patterns\nMonitoring & Observability: Logging, metrics, tracing\n\n\n\n\n\nApplication Security: OWASP, secure coding practices\nInfrastructure Security: Network security, access control\nCompliance: GDPR, SOC2, security frameworks\n\n\n\n\n\nDatabase Design: SQL, NoSQL, data modeling\nData Engineering: ETL, data pipelines, analytics\nMachine Learning: Algorithms, frameworks, MLOps\n\n\n\n\n\n\n\n\nCurrent Needs: Books relevant to my current projects\nSkill Gaps: Areas where I need improvement\nIndustry Trends: Emerging technologies and practices\nClassics: Timeless books that every developer should read\n\n\n\n\n\nActive Reading: Take notes, highlight key concepts\nImplementation: Build examples and practice exercises\nReflection: Connect concepts to real-world applications\nSharing: Write summaries and share insights\n\n\n\n\n## Book: [Title]\n**Author**: [Author Name]  \n**Category**: [DSA/System Design/Programming/etc.]  \n**Status**: [Reading/Completed/Planned]  \n**Rating**: [1-5 stars]\n\n### Summary\n[2-3 sentence overview of the book]\n\n### Key Concepts\n- [Concept 1 with explanation]\n- [Concept 2 with explanation]\n- [Concept 3 with explanation]\n\n### Code Examples\n[Important code snippets and implementations]\n\n### Practical Applications\n[How to apply concepts in real projects]\n\n### Questions & Follow-up\n[Topics to explore further]\n\n\n\n\n\n\n\n\nProgress: 60%\nCategory: System Design\nKey Learnings: Data models, storage engines, distributed systems\nRecent Notes: - Chapter 3: Storage and Retrieval - B-tree vs LSM-tree trade-offs - Chapter 4: Encoding and Evolution - Schema evolution strategies - Chapter 5: Replication - Leader-follower, consensus algorithms\n\n\n\nProgress: 40%\nCategory: DSA\nKey Learnings: Problem-solving techniques, interview strategies\nRecent Notes: - Arrays & Strings: Two pointers, sliding window techniques - Linked Lists: Fast/slow pointers, reversing, merging - Trees & Graphs: DFS/BFS, tree construction patterns\n\n\n\n\n\n\nRating: ⭐⭐⭐⭐⭐\nCategory: Programming\nKey Takeaways: Meaningful names, small functions, SOLID principles\nImpact: Improved code organization and maintainability in current projects.\n\n\n\nRating: ⭐⭐⭐⭐⭐\nCategory: Programming\nKey Takeaways: DRY principle, automation, continuous learning\nImpact: Enhanced development workflow and tool usage.\n\n\n\n\n\n\n\n“System Design Interview” by Alex Xu - Interview preparation\n“Building Microservices” by Sam Newman - Architecture patterns\n“Kubernetes in Action” by Marko Lukša - Container orchestration\n\n\n\n\n\n“Effective Python” by Brett Slatkin - Python best practices\n“Database Design for Mere Mortals” by Michael Hernandez - Data modeling\n“Site Reliability Engineering” by Google - DevOps practices\n\n\n\n\n\n“Introduction to Algorithms” (CLRS) - Algorithm fundamentals\n“Patterns of Enterprise Application Architecture” by Martin Fowler - Design patterns\n“The Mythical Man-Month” by Frederick Brooks - Software project management\n\n\n\n\n\n\n\n\n\nBooks Completed: 12 technical books\nPages Read: 3,000+ pages\nNotes Written: 50+ detailed notes\nProjects Built: 5+ implementations based on book concepts\n\n\n\n\n\nSystem Design: Master scalable architecture patterns\nDSA: Improve problem-solving and algorithmic thinking\nDevOps: Learn modern infrastructure and deployment practices\nSecurity: Build secure applications and systems\n\n\n\n\n\n\n\n\n“Clean Code” - Every developer should read this\n“The Pragmatic Programmer” - Timeless software development wisdom\n“Designing Data-Intensive Applications” - Excellent distributed systems coverage\n\n\n\n\n\n“Cracking the Coding Interview” - Great for interview preparation\n“Effective Python” - Python-specific best practices\n“Building Microservices” - Good microservices introduction\n\n\n\n\n\n“Head First Design Patterns” - Accessible design patterns introduction\n“Python Cookbook” - Practical Python recipes\n“Docker in Action” - Container fundamentals\n\n\n\n\n\n\n\n\nO’Reilly Learning: Online platform with technical books\nManning Publications: High-quality programming books\nPragmatic Bookshelf: Practical programming guides\nAddison-Wesley: Computer science and engineering books\n\n\n\n\n\nOnline Courses: Coursera, edX, Udemy courses\nDocumentation: Official docs and tutorials\nBlog Posts: Author blogs and technical articles\nVideo Content: Conference talks and tutorials\n\n\n\n\n\nLeetCode: Algorithm problems and solutions\nHackerRank: Programming challenges\nGitHub: Open source projects and examples\nPersonal Projects: Implementing book concepts\n\n\n\n\n\n\n\n\nE-reader: Kindle for digital books\nNote-taking: Notion for organized notes\nCode Editor: VS Code for examples and practice\nTime Tracking: Toggl for reading sessions\n\n\n\n\n\nWeekdays: 30-60 minutes before work\nWeekends: 2-3 hours for deep reading\nCommute: Audiobooks and podcasts\nEvenings: Code practice and implementation\n\n\n\n\n\n\n\n\nLocal Meetups: In-person book discussions\nOnline Forums: Reddit, Discord study groups\nBook Clubs: Organized reading groups\nMentorship: Teaching others while learning\n\n\n\n\n\nBlog Posts: Book reviews and summaries\nCode Examples: GitHub repositories with implementations\nVideo Content: Explaining concepts to others\nPresentations: Sharing learnings with teams\n\n\n\n\n\n\n\n\nBooks Read: 12+ per year\nNotes Written: 100+ detailed notes\nProjects Completed: 10+ implementations\nConcepts Mastered: 50+ key concepts\n\n\n\n\n\nUnderstanding: Deep comprehension of concepts\nApplication: Ability to use knowledge in projects\nTeaching: Can explain concepts to others\nProblem Solving: Improved analytical thinking\n\n\n\n\n\n\n\nReading Tips\n\n\n\n\nStart Small: Begin with shorter, focused books\nTake Notes: Document key concepts and insights\nPractice: Implement examples and build projects\nReview: Regularly revisit notes and concepts\nShare: Discuss learnings with others\n\n\n\n\n\n\n\n\n\nCommon Pitfalls\n\n\n\n\nOverwhelming: Don’t try to read too many books at once\nPassive Reading: Engage actively with the material\nNo Practice: Reading without implementation\nIsolation: Learning without community discussion",
    "crumbs": [
      "Books"
    ]
  },
  {
    "objectID": "books/index.html#quick-navigation",
    "href": "books/index.html#quick-navigation",
    "title": "Books",
    "section": "",
    "text": "Reading List - Current and planned books\nNotes - Detailed book notes and summaries",
    "crumbs": [
      "Books"
    ]
  },
  {
    "objectID": "books/index.html#reading-categories",
    "href": "books/index.html#reading-categories",
    "title": "Books",
    "section": "",
    "text": "Core Fundamentals: Algorithm design, complexity analysis\nProblem Solving: Interview preparation, competitive programming\nAdvanced Topics: Dynamic programming, graph algorithms\n\n\n\n\n\nDistributed Systems: Scalability, consistency, fault tolerance\nSoftware Architecture: Design patterns, best practices\nCloud-Native: Microservices, containers, serverless\n\n\n\n\n\nLanguage Deep Dives: Python, JavaScript, Go, Rust\nProgramming Paradigms: Functional, object-oriented, concurrent\nCode Quality: Clean code, refactoring, testing\n\n\n\n\n\nContainerization: Docker, Kubernetes, orchestration\nCloud Platforms: AWS, GCP, Azure services and patterns\nMonitoring & Observability: Logging, metrics, tracing\n\n\n\n\n\nApplication Security: OWASP, secure coding practices\nInfrastructure Security: Network security, access control\nCompliance: GDPR, SOC2, security frameworks\n\n\n\n\n\nDatabase Design: SQL, NoSQL, data modeling\nData Engineering: ETL, data pipelines, analytics\nMachine Learning: Algorithms, frameworks, MLOps",
    "crumbs": [
      "Books"
    ]
  },
  {
    "objectID": "books/index.html#my-reading-approach",
    "href": "books/index.html#my-reading-approach",
    "title": "Books",
    "section": "",
    "text": "Current Needs: Books relevant to my current projects\nSkill Gaps: Areas where I need improvement\nIndustry Trends: Emerging technologies and practices\nClassics: Timeless books that every developer should read\n\n\n\n\n\nActive Reading: Take notes, highlight key concepts\nImplementation: Build examples and practice exercises\nReflection: Connect concepts to real-world applications\nSharing: Write summaries and share insights\n\n\n\n\n## Book: [Title]\n**Author**: [Author Name]  \n**Category**: [DSA/System Design/Programming/etc.]  \n**Status**: [Reading/Completed/Planned]  \n**Rating**: [1-5 stars]\n\n### Summary\n[2-3 sentence overview of the book]\n\n### Key Concepts\n- [Concept 1 with explanation]\n- [Concept 2 with explanation]\n- [Concept 3 with explanation]\n\n### Code Examples\n[Important code snippets and implementations]\n\n### Practical Applications\n[How to apply concepts in real projects]\n\n### Questions & Follow-up\n[Topics to explore further]",
    "crumbs": [
      "Books"
    ]
  },
  {
    "objectID": "books/index.html#current-reading-status",
    "href": "books/index.html#current-reading-status",
    "title": "Books",
    "section": "",
    "text": "Progress: 60%\nCategory: System Design\nKey Learnings: Data models, storage engines, distributed systems\nRecent Notes: - Chapter 3: Storage and Retrieval - B-tree vs LSM-tree trade-offs - Chapter 4: Encoding and Evolution - Schema evolution strategies - Chapter 5: Replication - Leader-follower, consensus algorithms\n\n\n\nProgress: 40%\nCategory: DSA\nKey Learnings: Problem-solving techniques, interview strategies\nRecent Notes: - Arrays & Strings: Two pointers, sliding window techniques - Linked Lists: Fast/slow pointers, reversing, merging - Trees & Graphs: DFS/BFS, tree construction patterns\n\n\n\n\n\n\nRating: ⭐⭐⭐⭐⭐\nCategory: Programming\nKey Takeaways: Meaningful names, small functions, SOLID principles\nImpact: Improved code organization and maintainability in current projects.\n\n\n\nRating: ⭐⭐⭐⭐⭐\nCategory: Programming\nKey Takeaways: DRY principle, automation, continuous learning\nImpact: Enhanced development workflow and tool usage.\n\n\n\n\n\n\n\n“System Design Interview” by Alex Xu - Interview preparation\n“Building Microservices” by Sam Newman - Architecture patterns\n“Kubernetes in Action” by Marko Lukša - Container orchestration\n\n\n\n\n\n“Effective Python” by Brett Slatkin - Python best practices\n“Database Design for Mere Mortals” by Michael Hernandez - Data modeling\n“Site Reliability Engineering” by Google - DevOps practices\n\n\n\n\n\n“Introduction to Algorithms” (CLRS) - Algorithm fundamentals\n“Patterns of Enterprise Application Architecture” by Martin Fowler - Design patterns\n“The Mythical Man-Month” by Frederick Brooks - Software project management",
    "crumbs": [
      "Books"
    ]
  },
  {
    "objectID": "books/index.html#reading-goals",
    "href": "books/index.html#reading-goals",
    "title": "Books",
    "section": "",
    "text": "Books Completed: 12 technical books\nPages Read: 3,000+ pages\nNotes Written: 50+ detailed notes\nProjects Built: 5+ implementations based on book concepts\n\n\n\n\n\nSystem Design: Master scalable architecture patterns\nDSA: Improve problem-solving and algorithmic thinking\nDevOps: Learn modern infrastructure and deployment practices\nSecurity: Build secure applications and systems",
    "crumbs": [
      "Books"
    ]
  },
  {
    "objectID": "books/index.html#book-reviews-ratings",
    "href": "books/index.html#book-reviews-ratings",
    "title": "Books",
    "section": "",
    "text": "“Clean Code” - Every developer should read this\n“The Pragmatic Programmer” - Timeless software development wisdom\n“Designing Data-Intensive Applications” - Excellent distributed systems coverage\n\n\n\n\n\n“Cracking the Coding Interview” - Great for interview preparation\n“Effective Python” - Python-specific best practices\n“Building Microservices” - Good microservices introduction\n\n\n\n\n\n“Head First Design Patterns” - Accessible design patterns introduction\n“Python Cookbook” - Practical Python recipes\n“Docker in Action” - Container fundamentals",
    "crumbs": [
      "Books"
    ]
  },
  {
    "objectID": "books/index.html#learning-resources",
    "href": "books/index.html#learning-resources",
    "title": "Books",
    "section": "",
    "text": "O’Reilly Learning: Online platform with technical books\nManning Publications: High-quality programming books\nPragmatic Bookshelf: Practical programming guides\nAddison-Wesley: Computer science and engineering books\n\n\n\n\n\nOnline Courses: Coursera, edX, Udemy courses\nDocumentation: Official docs and tutorials\nBlog Posts: Author blogs and technical articles\nVideo Content: Conference talks and tutorials\n\n\n\n\n\nLeetCode: Algorithm problems and solutions\nHackerRank: Programming challenges\nGitHub: Open source projects and examples\nPersonal Projects: Implementing book concepts",
    "crumbs": [
      "Books"
    ]
  },
  {
    "objectID": "books/index.html#reading-environment",
    "href": "books/index.html#reading-environment",
    "title": "Books",
    "section": "",
    "text": "E-reader: Kindle for digital books\nNote-taking: Notion for organized notes\nCode Editor: VS Code for examples and practice\nTime Tracking: Toggl for reading sessions\n\n\n\n\n\nWeekdays: 30-60 minutes before work\nWeekends: 2-3 hours for deep reading\nCommute: Audiobooks and podcasts\nEvenings: Code practice and implementation",
    "crumbs": [
      "Books"
    ]
  },
  {
    "objectID": "books/index.html#community-sharing",
    "href": "books/index.html#community-sharing",
    "title": "Books",
    "section": "",
    "text": "Local Meetups: In-person book discussions\nOnline Forums: Reddit, Discord study groups\nBook Clubs: Organized reading groups\nMentorship: Teaching others while learning\n\n\n\n\n\nBlog Posts: Book reviews and summaries\nCode Examples: GitHub repositories with implementations\nVideo Content: Explaining concepts to others\nPresentations: Sharing learnings with teams",
    "crumbs": [
      "Books"
    ]
  },
  {
    "objectID": "books/index.html#success-metrics",
    "href": "books/index.html#success-metrics",
    "title": "Books",
    "section": "",
    "text": "Books Read: 12+ per year\nNotes Written: 100+ detailed notes\nProjects Completed: 10+ implementations\nConcepts Mastered: 50+ key concepts\n\n\n\n\n\nUnderstanding: Deep comprehension of concepts\nApplication: Ability to use knowledge in projects\nTeaching: Can explain concepts to others\nProblem Solving: Improved analytical thinking\n\n\n\n\n\n\n\nReading Tips\n\n\n\n\nStart Small: Begin with shorter, focused books\nTake Notes: Document key concepts and insights\nPractice: Implement examples and build projects\nReview: Regularly revisit notes and concepts\nShare: Discuss learnings with others\n\n\n\n\n\n\n\n\n\nCommon Pitfalls\n\n\n\n\nOverwhelming: Don’t try to read too many books at once\nPassive Reading: Engage actively with the material\nNo Practice: Reading without implementation\nIsolation: Learning without community discussion",
    "crumbs": [
      "Books"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Developer Learning Wiki",
    "section": "",
    "text": "Your journey to becoming a better software developer\n\n\n\n\n\n\nSoftware DeveloperLearning Journey & Knowledge BaseContinuous Growth\n\n \n\nBlog ⸱ GitHub ⸱ LinkedIn ⸱ About\n\n \n\nWelcome to my learning journey as a software developer. This wiki serves as my personal knowledge base covering four main areas: Data Structures & Algorithms, System Design, Technical Blog Breakdowns, and Book Notes.\n\n \n\n\n\n\n\nCore computer science fundamentals, problem-solving techniques, and algorithmic thinking.\n\n\n\nScalable architecture patterns, distributed systems, and real-world system design challenges.\n\n\n\nBreakdowns and notes from technical articles, engineering blogs, and industry insights.\n\n\n\nReading notes, summaries, and key takeaways from technical books and resources."
  },
  {
    "objectID": "index.html#learning-areas",
    "href": "index.html#learning-areas",
    "title": "Developer Learning Wiki",
    "section": "",
    "text": "Core computer science fundamentals, problem-solving techniques, and algorithmic thinking.\n\n\n\nScalable architecture patterns, distributed systems, and real-world system design challenges.\n\n\n\nBreakdowns and notes from technical articles, engineering blogs, and industry insights.\n\n\n\nReading notes, summaries, and key takeaways from technical books and resources."
  },
  {
    "objectID": "index.html#latest-blog-posts",
    "href": "index.html#latest-blog-posts",
    "title": "Developer Learning Wiki",
    "section": "Latest Blog Posts",
    "text": "Latest Blog Posts\n\n\n\n\n15 Mar, 2024\nMy System Design Learning Path\nSystem Design Learning\n\n\n\nNo matching items\n\nAll Posts"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my Developer Learning Wiki! This is my personal knowledge base and learning journey as a software developer.\n\n\nI’m a software developer passionate about continuous learning and sharing knowledge. This wiki serves as my digital garden where I document my learning journey, organize technical knowledge, and share insights with the developer community.\n\n\n\n\n\nThis wiki tracks my progress through four main areas of software development: - Data Structures & Algorithms: Core computer science fundamentals - System Design: Scalable architecture and distributed systems - Technical Blogs: Analysis of engineering articles and insights - Books: Reading notes and summaries from technical literature\n\n\n\nA comprehensive collection of: - Code Examples: Practical implementations and solutions - Architecture Patterns: System design principles and trade-offs - Best Practices: Industry standards and proven approaches - Learning Resources: Curated materials and references\n\n\n\nA living document that: - Grows Over Time: New content added regularly - Connects Ideas: Links between related concepts - Evolves: Content updated as my understanding deepens - Shares Knowledge: Open for others to learn from\n\n\n\n\n\n\n\nNever stop learning and growing\nEmbrace new technologies and approaches\nLearn from both successes and failures\nShare knowledge with the community\n\n\n\n\n\nTheory is important, but practice is essential\nBuild real projects to solidify understanding\nApply concepts to solve actual problems\nLearn by doing, not just reading\n\n\n\n\n\nOrganize knowledge in a structured way\nConnect related concepts and patterns\nDocument learnings for future reference\nReview and refine understanding regularly\n\n\n\n\n\n\n\n\nMaster fundamental DSA concepts and problem-solving\nUnderstand scalable system design patterns\nAnalyze 20+ technical articles and blogs\nComplete 6 technical books with detailed notes\n\n\n\n\n\nBuild and deploy scalable applications\nContribute to open source projects\nShare knowledge through blog posts and presentations\nMentor other developers in their learning journey\n\n\n\n\n\nDevelop expertise in distributed systems\nCreate comprehensive learning resources\nBuild a strong professional network\nContribute to the broader developer community\n\n\n\n\n\n\n\n\nActive Reading: Take notes, ask questions, make connections\nImplementation: Build examples and practice exercises\nReflection: Connect concepts to real-world applications\nSharing: Write summaries and discuss with others\n\n\n\n\n\nLeetCode/HackerRank: Regular problem-solving practice\nPersonal Projects: Build applications using learned concepts\nCode Reviews: Learn from others and improve code quality\nTeaching: Explain concepts to reinforce understanding\n\n\n\n\n\nStudy Groups: Join learning communities and discussions\nOpen Source: Contribute to projects and learn from codebases\nConferences: Attend events and network with other developers\nMentorship: Both giving and receiving guidance\n\n\n\n\n\n\n\n\nPython: Primary language for algorithms and data science\nJavaScript/TypeScript: Web development and full-stack applications\nGo: Systems programming and microservices\nSQL: Database design and optimization\n\n\n\n\n\nGit: Version control and collaboration\nDocker: Containerization and deployment\nAWS/GCP: Cloud platforms and services\nKubernetes: Container orchestration\n\n\n\n\n\nBackend Development: APIs, databases, server-side logic\nSystem Design: Scalable architecture and distributed systems\nDevOps: CI/CD, monitoring, infrastructure as code\nData Engineering: ETL pipelines, analytics, machine learning\n\n\n\n\n\n\n\n\nTrack Progress: Document my learning journey\nRetain Knowledge: Create a searchable knowledge base\nIdentify Gaps: Understand areas that need improvement\nStay Motivated: Visualize progress and achievements\n\n\n\n\n\nShare Knowledge: Help others learn and grow\nGet Feedback: Learn from community insights\nBuild Network: Connect with like-minded developers\nGive Back: Contribute to the developer ecosystem\n\n\n\n\n\nPortfolio: Showcase skills and knowledge\nInterview Prep: Organize knowledge for technical interviews\nCareer Growth: Demonstrate continuous learning\nThought Leadership: Share insights and perspectives\n\n\n\n\n\n\n\n\nBrowse by Topic: Explore specific areas of interest\nFollow the Journey: See how concepts build upon each other\nPractice Examples: Use code examples and exercises\nAsk Questions: Reach out for clarification or discussion\n\n\n\n\n\nReference Material: Use as a quick reference guide\nLearning Path: Follow structured learning paths\nCode Examples: Copy and adapt code for your projects\nBest Practices: Learn from documented patterns and approaches\n\n\n\n\n\nSuggest Improvements: Point out errors or areas for enhancement\nShare Resources: Recommend additional learning materials\nCollaborate: Work together on projects or learning goals\nMentor: Help guide others in their learning journey\n\n\n\n\n\nI’m always interested in connecting with other developers and learners. Here are some ways to reach out:\n\n\n\nGitHub: [Your GitHub Profile]\nLinkedIn: [Your LinkedIn Profile]\nTwitter: [Your Twitter Handle]\n\n\n\n\n\nEmail: [Your Email]\nDiscord: [Your Discord Handle]\nSlack: [Your Slack Workspace]\n\n\n\n\n\nStudy Groups: Join or form learning communities\nOpen Source: Contribute to projects together\nBlog Posts: Guest write or collaborate on content\nPresentations: Speak at meetups or conferences\n\n\n\n\n\n\n\n\nDigital Garden Movement: Inspired by the concept of digital gardens\nDeveloper Communities: Learning from the broader developer ecosystem\nOpen Source: Building on the work of countless contributors\nMentors: Those who have guided my learning journey\n\n\n\n\n\nQuarto: The amazing tool that powers this wiki\nGitHub: Platform for hosting and collaboration\nLearning Platforms: LeetCode, HackerRank, Coursera, etc.\nTechnical Blogs: Countless engineers sharing their knowledge\n\n\nThis wiki is a work in progress, constantly evolving as I learn and grow. Thank you for being part of this journey!\n\n\n\n\n\n\nStart Your Own Learning Journey\n\n\n\n\nChoose a Focus: Pick an area that interests you\nSet Goals: Define what you want to achieve\nCreate Structure: Organize your learning systematically\nShare Progress: Document and share your journey\nStay Consistent: Make learning a regular habit"
  },
  {
    "objectID": "about.html#who-i-am",
    "href": "about.html#who-i-am",
    "title": "About",
    "section": "",
    "text": "I’m a software developer passionate about continuous learning and sharing knowledge. This wiki serves as my digital garden where I document my learning journey, organize technical knowledge, and share insights with the developer community."
  },
  {
    "objectID": "about.html#what-this-wiki-is",
    "href": "about.html#what-this-wiki-is",
    "title": "About",
    "section": "",
    "text": "This wiki tracks my progress through four main areas of software development: - Data Structures & Algorithms: Core computer science fundamentals - System Design: Scalable architecture and distributed systems - Technical Blogs: Analysis of engineering articles and insights - Books: Reading notes and summaries from technical literature\n\n\n\nA comprehensive collection of: - Code Examples: Practical implementations and solutions - Architecture Patterns: System design principles and trade-offs - Best Practices: Industry standards and proven approaches - Learning Resources: Curated materials and references\n\n\n\nA living document that: - Grows Over Time: New content added regularly - Connects Ideas: Links between related concepts - Evolves: Content updated as my understanding deepens - Shares Knowledge: Open for others to learn from"
  },
  {
    "objectID": "about.html#my-learning-philosophy",
    "href": "about.html#my-learning-philosophy",
    "title": "About",
    "section": "",
    "text": "Never stop learning and growing\nEmbrace new technologies and approaches\nLearn from both successes and failures\nShare knowledge with the community\n\n\n\n\n\nTheory is important, but practice is essential\nBuild real projects to solidify understanding\nApply concepts to solve actual problems\nLearn by doing, not just reading\n\n\n\n\n\nOrganize knowledge in a structured way\nConnect related concepts and patterns\nDocument learnings for future reference\nReview and refine understanding regularly"
  },
  {
    "objectID": "about.html#learning-goals",
    "href": "about.html#learning-goals",
    "title": "About",
    "section": "",
    "text": "Master fundamental DSA concepts and problem-solving\nUnderstand scalable system design patterns\nAnalyze 20+ technical articles and blogs\nComplete 6 technical books with detailed notes\n\n\n\n\n\nBuild and deploy scalable applications\nContribute to open source projects\nShare knowledge through blog posts and presentations\nMentor other developers in their learning journey\n\n\n\n\n\nDevelop expertise in distributed systems\nCreate comprehensive learning resources\nBuild a strong professional network\nContribute to the broader developer community"
  },
  {
    "objectID": "about.html#how-i-learn",
    "href": "about.html#how-i-learn",
    "title": "About",
    "section": "",
    "text": "Active Reading: Take notes, ask questions, make connections\nImplementation: Build examples and practice exercises\nReflection: Connect concepts to real-world applications\nSharing: Write summaries and discuss with others\n\n\n\n\n\nLeetCode/HackerRank: Regular problem-solving practice\nPersonal Projects: Build applications using learned concepts\nCode Reviews: Learn from others and improve code quality\nTeaching: Explain concepts to reinforce understanding\n\n\n\n\n\nStudy Groups: Join learning communities and discussions\nOpen Source: Contribute to projects and learn from codebases\nConferences: Attend events and network with other developers\nMentorship: Both giving and receiving guidance"
  },
  {
    "objectID": "about.html#technology-stack",
    "href": "about.html#technology-stack",
    "title": "About",
    "section": "",
    "text": "Python: Primary language for algorithms and data science\nJavaScript/TypeScript: Web development and full-stack applications\nGo: Systems programming and microservices\nSQL: Database design and optimization\n\n\n\n\n\nGit: Version control and collaboration\nDocker: Containerization and deployment\nAWS/GCP: Cloud platforms and services\nKubernetes: Container orchestration\n\n\n\n\n\nBackend Development: APIs, databases, server-side logic\nSystem Design: Scalable architecture and distributed systems\nDevOps: CI/CD, monitoring, infrastructure as code\nData Engineering: ETL pipelines, analytics, machine learning"
  },
  {
    "objectID": "about.html#why-i-built-this-wiki",
    "href": "about.html#why-i-built-this-wiki",
    "title": "About",
    "section": "",
    "text": "Track Progress: Document my learning journey\nRetain Knowledge: Create a searchable knowledge base\nIdentify Gaps: Understand areas that need improvement\nStay Motivated: Visualize progress and achievements\n\n\n\n\n\nShare Knowledge: Help others learn and grow\nGet Feedback: Learn from community insights\nBuild Network: Connect with like-minded developers\nGive Back: Contribute to the developer ecosystem\n\n\n\n\n\nPortfolio: Showcase skills and knowledge\nInterview Prep: Organize knowledge for technical interviews\nCareer Growth: Demonstrate continuous learning\nThought Leadership: Share insights and perspectives"
  },
  {
    "objectID": "about.html#how-to-use-this-wiki",
    "href": "about.html#how-to-use-this-wiki",
    "title": "About",
    "section": "",
    "text": "Browse by Topic: Explore specific areas of interest\nFollow the Journey: See how concepts build upon each other\nPractice Examples: Use code examples and exercises\nAsk Questions: Reach out for clarification or discussion\n\n\n\n\n\nReference Material: Use as a quick reference guide\nLearning Path: Follow structured learning paths\nCode Examples: Copy and adapt code for your projects\nBest Practices: Learn from documented patterns and approaches\n\n\n\n\n\nSuggest Improvements: Point out errors or areas for enhancement\nShare Resources: Recommend additional learning materials\nCollaborate: Work together on projects or learning goals\nMentor: Help guide others in their learning journey"
  },
  {
    "objectID": "about.html#get-in-touch",
    "href": "about.html#get-in-touch",
    "title": "About",
    "section": "",
    "text": "I’m always interested in connecting with other developers and learners. Here are some ways to reach out:\n\n\n\nGitHub: [Your GitHub Profile]\nLinkedIn: [Your LinkedIn Profile]\nTwitter: [Your Twitter Handle]\n\n\n\n\n\nEmail: [Your Email]\nDiscord: [Your Discord Handle]\nSlack: [Your Slack Workspace]\n\n\n\n\n\nStudy Groups: Join or form learning communities\nOpen Source: Contribute to projects together\nBlog Posts: Guest write or collaborate on content\nPresentations: Speak at meetups or conferences"
  },
  {
    "objectID": "about.html#acknowledgments",
    "href": "about.html#acknowledgments",
    "title": "About",
    "section": "",
    "text": "Digital Garden Movement: Inspired by the concept of digital gardens\nDeveloper Communities: Learning from the broader developer ecosystem\nOpen Source: Building on the work of countless contributors\nMentors: Those who have guided my learning journey\n\n\n\n\n\nQuarto: The amazing tool that powers this wiki\nGitHub: Platform for hosting and collaboration\nLearning Platforms: LeetCode, HackerRank, Coursera, etc.\nTechnical Blogs: Countless engineers sharing their knowledge\n\n\nThis wiki is a work in progress, constantly evolving as I learn and grow. Thank you for being part of this journey!\n\n\n\n\n\n\nStart Your Own Learning Journey\n\n\n\n\nChoose a Focus: Pick an area that interests you\nSet Goals: Define what you want to achieve\nCreate Structure: Organize your learning systematically\nShare Progress: Document and share your journey\nStay Consistent: Make learning a regular habit"
  },
  {
    "objectID": "system-design/case-studies.html",
    "href": "system-design/case-studies.html",
    "title": "Case Studies",
    "section": "",
    "text": "Real-world examples of system design challenges and solutions.\n\n\n\n\n\nFunctional: Shorten long URLs, redirect to original URL\nNon-Functional: High availability, low latency, scalable\nScale: 100M URLs per month, 500M redirects per month\n\n\n\n\n┌─────────┐    ┌─────────────┐    ┌─────────┐\n│  Client │───▶│   Web App   │───▶│  URL    │\n│         │    │             │    │Service  │\n└─────────┘    └─────────────┘    └─────────┘\n                      │                   │\n                      ▼                   ▼\n                ┌─────────┐         ┌─────────┐\n                │   Cache │         │Database │\n                │  (Redis)│         │(MySQL)  │\n                └─────────┘         └─────────┘\n\n\n\n\n\nimport hashlib\nimport base64\n\ndef generate_short_url(long_url):\n    # Hash the long URL\n    hash_object = hashlib.md5(long_url.encode())\n    hash_hex = hash_object.hexdigest()\n    \n    # Take first 6 characters and encode to base62\n    short_code = base64.urlsafe_b64encode(hash_hex[:6].encode()).decode()[:6]\n    \n    return short_code\n\n# Alternative: Counter-based approach\ndef generate_short_url_counter():\n    counter = get_next_counter()  # Atomic increment\n    return base62_encode(counter)\n\n\n\nCREATE TABLE urls (\n    id BIGINT PRIMARY KEY AUTO_INCREMENT,\n    short_code VARCHAR(10) UNIQUE NOT NULL,\n    long_url TEXT NOT NULL,\n    user_id BIGINT,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    expires_at TIMESTAMP NULL,\n    INDEX idx_short_code (short_code),\n    INDEX idx_user_id (user_id)\n);\n\n\n\ndef get_long_url(short_code):\n    # Try cache first\n    long_url = cache.get(f\"url:{short_code}\")\n    if long_url:\n        return long_url\n    \n    # Cache miss - query database\n    long_url = database.get_long_url(short_code)\n    if long_url:\n        cache.set(f\"url:{short_code}\", long_url, ttl=3600)\n    \n    return long_url\n\n\n\n\n\nDatabase: Read replicas for redirects, sharding by user_id\nCache: Redis cluster for high availability\nCDN: For static assets and popular redirects\nRate Limiting: Prevent abuse\n\n\n\n\n\n\n\n\nFunctional: Send/receive messages, group chats, online status\nNon-Functional: Real-time, low latency, high availability\nScale: 1M concurrent users, 10M messages per second\n\n\n\n\n┌─────────┐    ┌─────────────┐    ┌─────────┐\n│  Client │◄──▶│   WebSocket │◄──▶│ Message │\n│         │    │   Gateway   │    │Service  │\n└─────────┘    └─────────────┘    └─────────┘\n                      │                   │\n                      ▼                   ▼\n                ┌─────────┐         ┌─────────┐\n                │ Presence│         │ Message │\n                │ Service │         │  Store  │\n                └─────────┘         └─────────┘\n                      │                   │\n                      ▼                   ▼\n                ┌─────────┐         ┌─────────┐\n                │   Cache │         │Database │\n                │  (Redis)│         │(MongoDB)│\n                └─────────┘         └─────────┘\n\n\n\n\n\nclass MessageService:\n    def send_message(self, sender_id, receiver_id, message):\n        # Store message\n        message_id = self.store_message(sender_id, receiver_id, message)\n        \n        # Update conversation\n        self.update_conversation(sender_id, receiver_id, message_id)\n        \n        # Notify receiver if online\n        if self.is_user_online(receiver_id):\n            self.push_message(receiver_id, message_id)\n        \n        return message_id\n    \n    def push_message(self, user_id, message_id):\n        # Get user's WebSocket connection\n        connections = self.get_user_connections(user_id)\n        \n        # Send message to all user's devices\n        for connection in connections:\n            connection.send({\n                'type': 'new_message',\n                'message_id': message_id\n            })\n\n\n\nclass PresenceService:\n    def user_online(self, user_id, device_id):\n        # Update user status\n        self.redis.hset(f\"user:{user_id}:devices\", device_id, \"online\")\n        self.redis.expire(f\"user:{user_id}:devices\", 300)  # 5 min TTL\n        \n        # Notify contacts\n        contacts = self.get_user_contacts(user_id)\n        for contact_id in contacts:\n            self.notify_presence_change(contact_id, user_id, \"online\")\n    \n    def user_offline(self, user_id, device_id):\n        # Remove device\n        self.redis.hdel(f\"user:{user_id}:devices\", device_id)\n        \n        # Check if user has other online devices\n        if not self.redis.hkeys(f\"user:{user_id}:devices\"):\n            contacts = self.get_user_contacts(user_id)\n            for contact_id in contacts:\n                self.notify_presence_change(contact_id, user_id, \"offline\")\n\n\n\n\n\nWebSocket: Load balancer with sticky sessions\nMessage Store: Sharding by conversation_id\nPresence: Redis cluster with replication\nMedia: CDN for file storage\n\n\n\n\n\n\n\n\nFunctional: Post tweets, follow users, view timeline\nNon-Functional: Low latency, high availability, real-time updates\nScale: 100M users, 1M tweets per minute\n\n\n\n\n┌─────────┐    ┌─────────────┐    ┌─────────┐\n│  Client │───▶│   API       │───▶│  Feed   │\n│         │    │  Gateway    │    │Service  │\n└─────────┘    └─────────────┘    └─────────┘\n                      │                   │\n                      ▼                   ▼\n                ┌─────────┐         ┌─────────┐\n                │  Tweet  │         │  User   │\n                │ Service │         │Service  │\n                └─────────┘         └─────────┘\n                      │                   │\n                      ▼                   ▼\n                ┌─────────┐         ┌─────────┐\n                │   Cache │         │Database │\n                │  (Redis)│         │(MySQL)  │\n                └─────────┘         └─────────┘\n\n\n\n\n\ndef get_user_feed(user_id, page=1, limit=20):\n    # Get user's following list\n    following = get_following_users(user_id)\n    \n    # Get tweets from following users\n    tweets = get_tweets_by_users(following, page, limit)\n    \n    # Sort by timestamp\n    tweets.sort(key=lambda x: x['created_at'], reverse=True)\n    \n    return tweets\n\n\n\ndef post_tweet(user_id, content):\n    # Store tweet\n    tweet_id = store_tweet(user_id, content)\n    \n    # Get user's followers\n    followers = get_user_followers(user_id)\n    \n    # Push to followers' timelines\n    for follower_id in followers:\n        add_to_timeline(follower_id, tweet_id)\n    \n    return tweet_id\n\ndef add_to_timeline(user_id, tweet_id):\n    # Add to user's timeline (Redis sorted set)\n    redis.zadd(f\"timeline:{user_id}\", {tweet_id: time.time()})\n    \n    # Keep only recent tweets (e.g., last 1000)\n    redis.zremrangebyrank(f\"timeline:{user_id}\", 0, -1001)\n\n\n\ndef get_user_feed_hybrid(user_id, page=1, limit=20):\n    # Try cache first (push model for active users)\n    cached_tweets = get_cached_timeline(user_id, page, limit)\n    if cached_tweets:\n        return cached_tweets\n    \n    # Fallback to pull model\n    return get_user_feed_pull(user_id, page, limit)\n\n\n\n\n-- Users table\nCREATE TABLE users (\n    id BIGINT PRIMARY KEY AUTO_INCREMENT,\n    username VARCHAR(50) UNIQUE NOT NULL,\n    email VARCHAR(100) UNIQUE NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Tweets table\nCREATE TABLE tweets (\n    id BIGINT PRIMARY KEY AUTO_INCREMENT,\n    user_id BIGINT NOT NULL,\n    content TEXT NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    FOREIGN KEY (user_id) REFERENCES users(id),\n    INDEX idx_user_created (user_id, created_at)\n);\n\n-- Follows table\nCREATE TABLE follows (\n    follower_id BIGINT NOT NULL,\n    following_id BIGINT NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    PRIMARY KEY (follower_id, following_id),\n    FOREIGN KEY (follower_id) REFERENCES users(id),\n    FOREIGN KEY (following_id) REFERENCES users(id)\n);\n\n\n\n\n\n\n\nFunctional: Upload videos, stream videos, search, recommendations\nNon-Functional: High bandwidth, low latency, global distribution\nScale: 1B users, 1M video uploads per day\n\n\n\n\n┌─────────┐    ┌─────────────┐    ┌─────────┐\n│  Client │───▶│   CDN       │───▶│ Video   │\n│         │    │  (CloudFlare)│   │Storage  │\n└─────────┘    └─────────────┘    └─────────┘\n                      │\n                      ▼\n                ┌─────────────┐\n                │   API       │\n                │  Gateway    │\n                └─────────────┘\n                      │\n                      ▼\n┌─────────┐    ┌─────────────┐    ┌─────────┐\n│  Video  │◄──▶│   Video     │◄──▶│  User   │\n│Processing│   │  Service    │    │Service  │\n└─────────┘    └─────────────┘    └─────────┘\n                      │                   │\n                      ▼                   ▼\n                ┌─────────┐         ┌─────────┐\n                │   Cache │         │Database │\n                │  (Redis)│         │(MySQL)  │\n                └─────────┘         └─────────┘\n\n\n\nclass VideoProcessor:\n    def process_video(self, video_id, file_path):\n        # 1. Extract metadata\n        metadata = self.extract_metadata(file_path)\n        \n        # 2. Generate multiple qualities\n        qualities = ['360p', '720p', '1080p']\n        for quality in qualities:\n            self.transcode_video(file_path, video_id, quality)\n        \n        # 3. Generate thumbnail\n        self.generate_thumbnail(file_path, video_id)\n        \n        # 4. Update video status\n        self.update_video_status(video_id, 'processed')\n        \n        # 5. Trigger indexing\n        self.index_video(video_id, metadata)\n\n\n\ndef get_video_manifest(video_id, quality):\n    # Get available qualities for video\n    qualities = get_video_qualities(video_id)\n    \n    # Generate HLS manifest\n    manifest = \"#EXTM3U\\n\"\n    manifest += \"#EXT-X-VERSION:3\\n\"\n    \n    for q in qualities:\n        manifest += f\"#EXT-X-STREAM-INF:BANDWIDTH={q['bandwidth']},RESOLUTION={q['resolution']}\\n\"\n        manifest += f\"{video_id}_{q['quality']}.m3u8\\n\"\n    \n    return manifest\n\n\n\n\n\n\n\n\n\n\nCommon Patterns\n\n\n\n\nCaching: Redis for session data, CDN for static content\nDatabase: Read replicas, sharding, denormalization\nMessaging: Queues for async processing, WebSockets for real-time\nStorage: Object storage for files, databases for metadata\n\n\n\n\n\n\n\n\n\nTrade-offs to Consider\n\n\n\n\nConsistency vs Availability: Choose based on use case\nLatency vs Throughput: Optimize for user experience\nCost vs Performance: Balance infrastructure costs\nComplexity vs Scalability: Start simple, evolve as needed",
    "crumbs": [
      "System Design",
      "Case Studies"
    ]
  },
  {
    "objectID": "system-design/case-studies.html#url-shortener-bit.ly-clone",
    "href": "system-design/case-studies.html#url-shortener-bit.ly-clone",
    "title": "Case Studies",
    "section": "",
    "text": "Functional: Shorten long URLs, redirect to original URL\nNon-Functional: High availability, low latency, scalable\nScale: 100M URLs per month, 500M redirects per month\n\n\n\n\n┌─────────┐    ┌─────────────┐    ┌─────────┐\n│  Client │───▶│   Web App   │───▶│  URL    │\n│         │    │             │    │Service  │\n└─────────┘    └─────────────┘    └─────────┘\n                      │                   │\n                      ▼                   ▼\n                ┌─────────┐         ┌─────────┐\n                │   Cache │         │Database │\n                │  (Redis)│         │(MySQL)  │\n                └─────────┘         └─────────┘\n\n\n\n\n\nimport hashlib\nimport base64\n\ndef generate_short_url(long_url):\n    # Hash the long URL\n    hash_object = hashlib.md5(long_url.encode())\n    hash_hex = hash_object.hexdigest()\n    \n    # Take first 6 characters and encode to base62\n    short_code = base64.urlsafe_b64encode(hash_hex[:6].encode()).decode()[:6]\n    \n    return short_code\n\n# Alternative: Counter-based approach\ndef generate_short_url_counter():\n    counter = get_next_counter()  # Atomic increment\n    return base62_encode(counter)\n\n\n\nCREATE TABLE urls (\n    id BIGINT PRIMARY KEY AUTO_INCREMENT,\n    short_code VARCHAR(10) UNIQUE NOT NULL,\n    long_url TEXT NOT NULL,\n    user_id BIGINT,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    expires_at TIMESTAMP NULL,\n    INDEX idx_short_code (short_code),\n    INDEX idx_user_id (user_id)\n);\n\n\n\ndef get_long_url(short_code):\n    # Try cache first\n    long_url = cache.get(f\"url:{short_code}\")\n    if long_url:\n        return long_url\n    \n    # Cache miss - query database\n    long_url = database.get_long_url(short_code)\n    if long_url:\n        cache.set(f\"url:{short_code}\", long_url, ttl=3600)\n    \n    return long_url\n\n\n\n\n\nDatabase: Read replicas for redirects, sharding by user_id\nCache: Redis cluster for high availability\nCDN: For static assets and popular redirects\nRate Limiting: Prevent abuse",
    "crumbs": [
      "System Design",
      "Case Studies"
    ]
  },
  {
    "objectID": "system-design/case-studies.html#chat-application-whatsapp-clone",
    "href": "system-design/case-studies.html#chat-application-whatsapp-clone",
    "title": "Case Studies",
    "section": "",
    "text": "Functional: Send/receive messages, group chats, online status\nNon-Functional: Real-time, low latency, high availability\nScale: 1M concurrent users, 10M messages per second\n\n\n\n\n┌─────────┐    ┌─────────────┐    ┌─────────┐\n│  Client │◄──▶│   WebSocket │◄──▶│ Message │\n│         │    │   Gateway   │    │Service  │\n└─────────┘    └─────────────┘    └─────────┘\n                      │                   │\n                      ▼                   ▼\n                ┌─────────┐         ┌─────────┐\n                │ Presence│         │ Message │\n                │ Service │         │  Store  │\n                └─────────┘         └─────────┘\n                      │                   │\n                      ▼                   ▼\n                ┌─────────┐         ┌─────────┐\n                │   Cache │         │Database │\n                │  (Redis)│         │(MongoDB)│\n                └─────────┘         └─────────┘\n\n\n\n\n\nclass MessageService:\n    def send_message(self, sender_id, receiver_id, message):\n        # Store message\n        message_id = self.store_message(sender_id, receiver_id, message)\n        \n        # Update conversation\n        self.update_conversation(sender_id, receiver_id, message_id)\n        \n        # Notify receiver if online\n        if self.is_user_online(receiver_id):\n            self.push_message(receiver_id, message_id)\n        \n        return message_id\n    \n    def push_message(self, user_id, message_id):\n        # Get user's WebSocket connection\n        connections = self.get_user_connections(user_id)\n        \n        # Send message to all user's devices\n        for connection in connections:\n            connection.send({\n                'type': 'new_message',\n                'message_id': message_id\n            })\n\n\n\nclass PresenceService:\n    def user_online(self, user_id, device_id):\n        # Update user status\n        self.redis.hset(f\"user:{user_id}:devices\", device_id, \"online\")\n        self.redis.expire(f\"user:{user_id}:devices\", 300)  # 5 min TTL\n        \n        # Notify contacts\n        contacts = self.get_user_contacts(user_id)\n        for contact_id in contacts:\n            self.notify_presence_change(contact_id, user_id, \"online\")\n    \n    def user_offline(self, user_id, device_id):\n        # Remove device\n        self.redis.hdel(f\"user:{user_id}:devices\", device_id)\n        \n        # Check if user has other online devices\n        if not self.redis.hkeys(f\"user:{user_id}:devices\"):\n            contacts = self.get_user_contacts(user_id)\n            for contact_id in contacts:\n                self.notify_presence_change(contact_id, user_id, \"offline\")\n\n\n\n\n\nWebSocket: Load balancer with sticky sessions\nMessage Store: Sharding by conversation_id\nPresence: Redis cluster with replication\nMedia: CDN for file storage",
    "crumbs": [
      "System Design",
      "Case Studies"
    ]
  },
  {
    "objectID": "system-design/case-studies.html#social-media-feed-twitter-clone",
    "href": "system-design/case-studies.html#social-media-feed-twitter-clone",
    "title": "Case Studies",
    "section": "",
    "text": "Functional: Post tweets, follow users, view timeline\nNon-Functional: Low latency, high availability, real-time updates\nScale: 100M users, 1M tweets per minute\n\n\n\n\n┌─────────┐    ┌─────────────┐    ┌─────────┐\n│  Client │───▶│   API       │───▶│  Feed   │\n│         │    │  Gateway    │    │Service  │\n└─────────┘    └─────────────┘    └─────────┘\n                      │                   │\n                      ▼                   ▼\n                ┌─────────┐         ┌─────────┐\n                │  Tweet  │         │  User   │\n                │ Service │         │Service  │\n                └─────────┘         └─────────┘\n                      │                   │\n                      ▼                   ▼\n                ┌─────────┐         ┌─────────┐\n                │   Cache │         │Database │\n                │  (Redis)│         │(MySQL)  │\n                └─────────┘         └─────────┘\n\n\n\n\n\ndef get_user_feed(user_id, page=1, limit=20):\n    # Get user's following list\n    following = get_following_users(user_id)\n    \n    # Get tweets from following users\n    tweets = get_tweets_by_users(following, page, limit)\n    \n    # Sort by timestamp\n    tweets.sort(key=lambda x: x['created_at'], reverse=True)\n    \n    return tweets\n\n\n\ndef post_tweet(user_id, content):\n    # Store tweet\n    tweet_id = store_tweet(user_id, content)\n    \n    # Get user's followers\n    followers = get_user_followers(user_id)\n    \n    # Push to followers' timelines\n    for follower_id in followers:\n        add_to_timeline(follower_id, tweet_id)\n    \n    return tweet_id\n\ndef add_to_timeline(user_id, tweet_id):\n    # Add to user's timeline (Redis sorted set)\n    redis.zadd(f\"timeline:{user_id}\", {tweet_id: time.time()})\n    \n    # Keep only recent tweets (e.g., last 1000)\n    redis.zremrangebyrank(f\"timeline:{user_id}\", 0, -1001)\n\n\n\ndef get_user_feed_hybrid(user_id, page=1, limit=20):\n    # Try cache first (push model for active users)\n    cached_tweets = get_cached_timeline(user_id, page, limit)\n    if cached_tweets:\n        return cached_tweets\n    \n    # Fallback to pull model\n    return get_user_feed_pull(user_id, page, limit)\n\n\n\n\n-- Users table\nCREATE TABLE users (\n    id BIGINT PRIMARY KEY AUTO_INCREMENT,\n    username VARCHAR(50) UNIQUE NOT NULL,\n    email VARCHAR(100) UNIQUE NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Tweets table\nCREATE TABLE tweets (\n    id BIGINT PRIMARY KEY AUTO_INCREMENT,\n    user_id BIGINT NOT NULL,\n    content TEXT NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    FOREIGN KEY (user_id) REFERENCES users(id),\n    INDEX idx_user_created (user_id, created_at)\n);\n\n-- Follows table\nCREATE TABLE follows (\n    follower_id BIGINT NOT NULL,\n    following_id BIGINT NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    PRIMARY KEY (follower_id, following_id),\n    FOREIGN KEY (follower_id) REFERENCES users(id),\n    FOREIGN KEY (following_id) REFERENCES users(id)\n);",
    "crumbs": [
      "System Design",
      "Case Studies"
    ]
  },
  {
    "objectID": "system-design/case-studies.html#video-streaming-service-youtube-clone",
    "href": "system-design/case-studies.html#video-streaming-service-youtube-clone",
    "title": "Case Studies",
    "section": "",
    "text": "Functional: Upload videos, stream videos, search, recommendations\nNon-Functional: High bandwidth, low latency, global distribution\nScale: 1B users, 1M video uploads per day\n\n\n\n\n┌─────────┐    ┌─────────────┐    ┌─────────┐\n│  Client │───▶│   CDN       │───▶│ Video   │\n│         │    │  (CloudFlare)│   │Storage  │\n└─────────┘    └─────────────┘    └─────────┘\n                      │\n                      ▼\n                ┌─────────────┐\n                │   API       │\n                │  Gateway    │\n                └─────────────┘\n                      │\n                      ▼\n┌─────────┐    ┌─────────────┐    ┌─────────┐\n│  Video  │◄──▶│   Video     │◄──▶│  User   │\n│Processing│   │  Service    │    │Service  │\n└─────────┘    └─────────────┘    └─────────┘\n                      │                   │\n                      ▼                   ▼\n                ┌─────────┐         ┌─────────┐\n                │   Cache │         │Database │\n                │  (Redis)│         │(MySQL)  │\n                └─────────┘         └─────────┘\n\n\n\nclass VideoProcessor:\n    def process_video(self, video_id, file_path):\n        # 1. Extract metadata\n        metadata = self.extract_metadata(file_path)\n        \n        # 2. Generate multiple qualities\n        qualities = ['360p', '720p', '1080p']\n        for quality in qualities:\n            self.transcode_video(file_path, video_id, quality)\n        \n        # 3. Generate thumbnail\n        self.generate_thumbnail(file_path, video_id)\n        \n        # 4. Update video status\n        self.update_video_status(video_id, 'processed')\n        \n        # 5. Trigger indexing\n        self.index_video(video_id, metadata)\n\n\n\ndef get_video_manifest(video_id, quality):\n    # Get available qualities for video\n    qualities = get_video_qualities(video_id)\n    \n    # Generate HLS manifest\n    manifest = \"#EXTM3U\\n\"\n    manifest += \"#EXT-X-VERSION:3\\n\"\n    \n    for q in qualities:\n        manifest += f\"#EXT-X-STREAM-INF:BANDWIDTH={q['bandwidth']},RESOLUTION={q['resolution']}\\n\"\n        manifest += f\"{video_id}_{q['quality']}.m3u8\\n\"\n    \n    return manifest",
    "crumbs": [
      "System Design",
      "Case Studies"
    ]
  },
  {
    "objectID": "system-design/case-studies.html#key-learnings",
    "href": "system-design/case-studies.html#key-learnings",
    "title": "Case Studies",
    "section": "",
    "text": "Common Patterns\n\n\n\n\nCaching: Redis for session data, CDN for static content\nDatabase: Read replicas, sharding, denormalization\nMessaging: Queues for async processing, WebSockets for real-time\nStorage: Object storage for files, databases for metadata\n\n\n\n\n\n\n\n\n\nTrade-offs to Consider\n\n\n\n\nConsistency vs Availability: Choose based on use case\nLatency vs Throughput: Optimize for user experience\nCost vs Performance: Balance infrastructure costs\nComplexity vs Scalability: Start simple, evolve as needed",
    "crumbs": [
      "System Design",
      "Case Studies"
    ]
  },
  {
    "objectID": "system-design/patterns.html",
    "href": "system-design/patterns.html",
    "title": "Design Patterns",
    "section": "",
    "text": "Common architectural patterns and their applications in building scalable systems.\n\n\n\n\n\nDescription: Single application containing all functionality\nPros: Simple to develop, deploy, and test\nCons: Difficult to scale, technology lock-in, deployment risk\nUse Cases: Small applications, MVPs, simple business logic\n\n┌─────────────────────────────────────┐\n│           Monolithic App            │\n│  ┌─────────┐ ┌─────────┐ ┌─────────┐ │\n│  │  Auth   │ │  User   │ │ Payment │ │\n│  └─────────┘ └─────────┘ └─────────┘ │\n│  ┌─────────┐ ┌─────────┐ ┌─────────┐ │\n│  │  Order  │ │ Product │ │  Email  │ │\n│  └─────────┘ └─────────┘ └─────────┘ │\n└─────────────────────────────────────┘\n\n\n\n\nDescription: Application split into small, independent services\nPros: Independent deployment, technology diversity, fault isolation\nCons: Distributed system complexity, network overhead, data consistency\nUse Cases: Large applications, team autonomy, complex domains\n\n┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐\n│  Auth   │ │  User   │ │ Payment │ │  Order  │\n│ Service │ │ Service │ │ Service │ │ Service │\n└─────────┘ └─────────┘ └─────────┘ └─────────┘\n     │           │           │           │\n     └───────────┼───────────┼───────────┘\n                 │           │\n         ┌───────▼───────┐   │\n         │   API Gateway │   │\n         └───────────────┘   │\n                 │           │\n         ┌───────▼───────┐   │\n         │   Load Balancer   │\n         └───────────────┘\n\n\n\n\nDescription: Services communicate through events\nPros: Loose coupling, scalability, real-time processing\nCons: Event ordering, debugging complexity, eventual consistency\nUse Cases: Real-time systems, IoT, analytics pipelines\n\n┌─────────┐    ┌─────────┐    ┌─────────┐\n│ Service │───▶│ Event   │───▶│ Service │\n│    A    │    │  Bus    │    │    B    │\n└─────────┘    └─────────┘    └─────────┘\n     │              │              │\n     └──────────────┼──────────────┘\n                    │\n              ┌─────▼─────┐\n              │ Service C │\n              └───────────┘\n\n\n\n\n\n\n\nDescription: Each microservice has its own database\nPros: Data isolation, independent scaling, technology choice\nCons: Data consistency challenges, distributed transactions\nUse Cases: Microservices, bounded contexts\n\n┌─────────┐ ┌─────────┐ ┌─────────┐\n│ Service │ │ Service │ │ Service │\n│    A    │ │    B    │ │    C    │\n└─────────┘ └─────────┘ └─────────┘\n     │           │           │\n┌─────────┐ ┌─────────┐ ┌─────────┐\n│   DB    │ │   DB    │ │   DB    │\n│    A    │ │    B    │ │    C    │\n└─────────┘ └─────────┘ └─────────┘\n\n\n\n\nDescription: Multiple services share a single database\nPros: ACID transactions, data consistency, simpler queries\nCons: Tight coupling, scaling challenges, technology lock-in\nUse Cases: Legacy systems, simple applications\n\n\n\n\n\nDescription: Separate read and write models\nPros: Optimized for read/write operations, scalability\nCons: Complexity, eventual consistency, data synchronization\nUse Cases: High-read applications, complex domains\n\n┌─────────┐    ┌─────────┐    ┌─────────┐\n│ Command │───▶│  Event  │───▶│  Query  │\n│  Model  │    │  Store  │    │  Model  │\n└─────────┘    └─────────┘    └─────────┘\n     │              │              │\n┌─────────┐    ┌─────────┐    ┌─────────┐\n│ Write   │    │  Event  │    │  Read   │\n│   DB    │    │  Bus    │    │   DB    │\n└─────────┘    └─────────┘    └─────────┘\n\n\n\n\n\n\n\nDescription: Direct service-to-service calls\nPros: Simple, immediate response, error handling\nCons: Tight coupling, cascading failures, latency\nUse Cases: Critical operations, real-time requirements\n\n# REST API call\nimport requests\n\ndef get_user_data(user_id):\n    response = requests.get(f\"http://user-service/users/{user_id}\")\n    return response.json()\n\n# gRPC call\nimport grpc\n\ndef get_user_data_grpc(user_id):\n    with grpc.insecure_channel('localhost:50051') as channel:\n        stub = user_pb2_grpc.UserServiceStub(channel)\n        response = stub.GetUser(user_pb2.UserRequest(id=user_id))\n        return response\n\n\n\n\nDescription: Communication through message queues\nPros: Loose coupling, fault tolerance, scalability\nCons: Eventual consistency, debugging complexity\nUse Cases: Background processing, event-driven systems\n\n# Using RabbitMQ\nimport pika\n\ndef send_message(message):\n    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))\n    channel = connection.channel()\n    channel.queue_declare(queue='task_queue')\n    channel.basic_publish(exchange='', routing_key='task_queue', body=message)\n    connection.close()\n\n# Using Apache Kafka\nfrom kafka import KafkaProducer\nimport json\n\ndef send_kafka_message(topic, message):\n    producer = KafkaProducer(bootstrap_servers=['localhost:9092'])\n    producer.send(topic, json.dumps(message).encode('utf-8'))\n    producer.flush()\n\n\n\n\n\n\n\nDescription: Distributing traffic across multiple servers\nTypes: Round-robin, least connections, IP hash, weighted\nUse Cases: High availability, horizontal scaling\n\n┌─────────┐\n│  Client │\n└────┬────┘\n     │\n┌────▼────┐\n│   Load  │\n│Balancer │\n└────┬────┘\n     │\n┌────┴────┐\n│ Server1 │\n└─────────┘\n     │\n┌────┴────┐\n│ Server2 │\n└─────────┘\n     │\n┌────┴────┐\n│ Server3 │\n└─────────┘\n\n\n\n\n\n\nDescription: Application manages cache directly\nPros: Simple, flexible, cache control\nCons: Cache miss penalty, cache invalidation complexity\n\ndef get_user_data(user_id):\n    # Try cache first\n    user_data = cache.get(f\"user:{user_id}\")\n    if user_data:\n        return user_data\n    \n    # Cache miss - fetch from database\n    user_data = database.get_user(user_id)\n    if user_data:\n        cache.set(f\"user:{user_id}\", user_data, ttl=3600)\n    \n    return user_data\n\n\n\n\nDescription: Write to cache and database simultaneously\nPros: Data consistency, read performance\nCons: Write latency, cache space usage\n\ndef update_user_data(user_id, user_data):\n    # Update database\n    database.update_user(user_id, user_data)\n    # Update cache\n    cache.set(f\"user:{user_id}\", user_data, ttl=3600)\n\n\n\n\nDescription: Write to cache first, database later\nPros: Write performance, reduced database load\nCons: Data loss risk, complexity\n\n\n\n\n\n\n\n\nDescription: Multiple read-only copies of database\nPros: Read scalability, reduced load on primary\nCons: Eventual consistency, replication lag\n\n┌─────────┐    ┌─────────┐\n│ Primary │───▶│ Replica │\n│   DB    │    │   1     │\n└─────────┘    └─────────┘\n     │              │\n     └──────────────┼─────┐\n                    │     │\n              ┌─────▼─┐   │\n              │Replica│   │\n              │   2   │   │\n              └───────┘   │\n                          │\n                    ┌─────▼─┐\n                    │Replica│\n                    │   3   │\n                    └───────┘\n\n\n\n\nDescription: Partitioning data across multiple databases\nPros: Horizontal scaling, improved performance\nCons: Complexity, cross-shard queries, rebalancing\n\ndef get_shard_key(user_id):\n    return user_id % 4  # 4 shards\n\ndef get_user_data(user_id):\n    shard_id = get_shard_key(user_id)\n    shard_connection = get_shard_connection(shard_id)\n    return shard_connection.execute(\"SELECT * FROM users WHERE id = ?\", user_id)\n\n\n\n\n\n\n\n\nDescription: Single entry point for all client requests\nPros: Centralized security, rate limiting, monitoring\nCons: Single point of failure, complexity\n\n┌─────────┐    ┌─────────────┐    ┌─────────┐\n│  Client │───▶│     API     │───▶│ Service │\n│         │    │   Gateway   │    │    A    │\n└─────────┘    └─────────────┘    └─────────┘\n                      │\n                      ▼\n                ┌─────────┐\n                │ Service │\n                │    B    │\n                └─────────┘\n\n\n\n\nDescription: Prevents cascading failures\nStates: Closed, Open, Half-Open\nUse Cases: External service calls, fault tolerance\n\nclass CircuitBreaker:\n    def __init__(self, failure_threshold=5, timeout=60):\n        self.failure_threshold = failure_threshold\n        self.timeout = timeout\n        self.failure_count = 0\n        self.last_failure_time = None\n        self.state = 'CLOSED'  # CLOSED, OPEN, HALF_OPEN\n    \n    def call(self, func, *args, **kwargs):\n        if self.state == 'OPEN':\n            if time.time() - self.last_failure_time &gt; self.timeout:\n                self.state = 'HALF_OPEN'\n            else:\n                raise Exception(\"Circuit breaker is OPEN\")\n        \n        try:\n            result = func(*args, **kwargs)\n            if self.state == 'HALF_OPEN':\n                self.state = 'CLOSED'\n                self.failure_count = 0\n            return result\n        except Exception as e:\n            self.failure_count += 1\n            self.last_failure_time = time.time()\n            \n            if self.failure_count &gt;= self.failure_threshold:\n                self.state = 'OPEN'\n            \n            raise e\n\n\n\n\n\n\n\n\n\n\nPattern Selection\n\n\n\n\nChoose patterns based on requirements, not trends\nConsider team expertise and maintenance capabilities\nStart simple and evolve as needed\nDocument trade-offs and decisions\n\n\n\n\n\n\n\n\n\nCommon Anti-Patterns\n\n\n\n\nOver-engineering with unnecessary complexity\nIgnoring data consistency requirements\nNot considering failure scenarios\nTight coupling between services",
    "crumbs": [
      "System Design",
      "Design Patterns"
    ]
  },
  {
    "objectID": "system-design/patterns.html#architectural-patterns",
    "href": "system-design/patterns.html#architectural-patterns",
    "title": "Design Patterns",
    "section": "",
    "text": "Description: Single application containing all functionality\nPros: Simple to develop, deploy, and test\nCons: Difficult to scale, technology lock-in, deployment risk\nUse Cases: Small applications, MVPs, simple business logic\n\n┌─────────────────────────────────────┐\n│           Monolithic App            │\n│  ┌─────────┐ ┌─────────┐ ┌─────────┐ │\n│  │  Auth   │ │  User   │ │ Payment │ │\n│  └─────────┘ └─────────┘ └─────────┘ │\n│  ┌─────────┐ ┌─────────┐ ┌─────────┐ │\n│  │  Order  │ │ Product │ │  Email  │ │\n│  └─────────┘ └─────────┘ └─────────┘ │\n└─────────────────────────────────────┘\n\n\n\n\nDescription: Application split into small, independent services\nPros: Independent deployment, technology diversity, fault isolation\nCons: Distributed system complexity, network overhead, data consistency\nUse Cases: Large applications, team autonomy, complex domains\n\n┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐\n│  Auth   │ │  User   │ │ Payment │ │  Order  │\n│ Service │ │ Service │ │ Service │ │ Service │\n└─────────┘ └─────────┘ └─────────┘ └─────────┘\n     │           │           │           │\n     └───────────┼───────────┼───────────┘\n                 │           │\n         ┌───────▼───────┐   │\n         │   API Gateway │   │\n         └───────────────┘   │\n                 │           │\n         ┌───────▼───────┐   │\n         │   Load Balancer   │\n         └───────────────┘\n\n\n\n\nDescription: Services communicate through events\nPros: Loose coupling, scalability, real-time processing\nCons: Event ordering, debugging complexity, eventual consistency\nUse Cases: Real-time systems, IoT, analytics pipelines\n\n┌─────────┐    ┌─────────┐    ┌─────────┐\n│ Service │───▶│ Event   │───▶│ Service │\n│    A    │    │  Bus    │    │    B    │\n└─────────┘    └─────────┘    └─────────┘\n     │              │              │\n     └──────────────┼──────────────┘\n                    │\n              ┌─────▼─────┐\n              │ Service C │\n              └───────────┘",
    "crumbs": [
      "System Design",
      "Design Patterns"
    ]
  },
  {
    "objectID": "system-design/patterns.html#data-patterns",
    "href": "system-design/patterns.html#data-patterns",
    "title": "Design Patterns",
    "section": "",
    "text": "Description: Each microservice has its own database\nPros: Data isolation, independent scaling, technology choice\nCons: Data consistency challenges, distributed transactions\nUse Cases: Microservices, bounded contexts\n\n┌─────────┐ ┌─────────┐ ┌─────────┐\n│ Service │ │ Service │ │ Service │\n│    A    │ │    B    │ │    C    │\n└─────────┘ └─────────┘ └─────────┘\n     │           │           │\n┌─────────┐ ┌─────────┐ ┌─────────┐\n│   DB    │ │   DB    │ │   DB    │\n│    A    │ │    B    │ │    C    │\n└─────────┘ └─────────┘ └─────────┘\n\n\n\n\nDescription: Multiple services share a single database\nPros: ACID transactions, data consistency, simpler queries\nCons: Tight coupling, scaling challenges, technology lock-in\nUse Cases: Legacy systems, simple applications\n\n\n\n\n\nDescription: Separate read and write models\nPros: Optimized for read/write operations, scalability\nCons: Complexity, eventual consistency, data synchronization\nUse Cases: High-read applications, complex domains\n\n┌─────────┐    ┌─────────┐    ┌─────────┐\n│ Command │───▶│  Event  │───▶│  Query  │\n│  Model  │    │  Store  │    │  Model  │\n└─────────┘    └─────────┘    └─────────┘\n     │              │              │\n┌─────────┐    ┌─────────┐    ┌─────────┐\n│ Write   │    │  Event  │    │  Read   │\n│   DB    │    │  Bus    │    │   DB    │\n└─────────┘    └─────────┘    └─────────┘",
    "crumbs": [
      "System Design",
      "Design Patterns"
    ]
  },
  {
    "objectID": "system-design/patterns.html#communication-patterns",
    "href": "system-design/patterns.html#communication-patterns",
    "title": "Design Patterns",
    "section": "",
    "text": "Description: Direct service-to-service calls\nPros: Simple, immediate response, error handling\nCons: Tight coupling, cascading failures, latency\nUse Cases: Critical operations, real-time requirements\n\n# REST API call\nimport requests\n\ndef get_user_data(user_id):\n    response = requests.get(f\"http://user-service/users/{user_id}\")\n    return response.json()\n\n# gRPC call\nimport grpc\n\ndef get_user_data_grpc(user_id):\n    with grpc.insecure_channel('localhost:50051') as channel:\n        stub = user_pb2_grpc.UserServiceStub(channel)\n        response = stub.GetUser(user_pb2.UserRequest(id=user_id))\n        return response\n\n\n\n\nDescription: Communication through message queues\nPros: Loose coupling, fault tolerance, scalability\nCons: Eventual consistency, debugging complexity\nUse Cases: Background processing, event-driven systems\n\n# Using RabbitMQ\nimport pika\n\ndef send_message(message):\n    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))\n    channel = connection.channel()\n    channel.queue_declare(queue='task_queue')\n    channel.basic_publish(exchange='', routing_key='task_queue', body=message)\n    connection.close()\n\n# Using Apache Kafka\nfrom kafka import KafkaProducer\nimport json\n\ndef send_kafka_message(topic, message):\n    producer = KafkaProducer(bootstrap_servers=['localhost:9092'])\n    producer.send(topic, json.dumps(message).encode('utf-8'))\n    producer.flush()",
    "crumbs": [
      "System Design",
      "Design Patterns"
    ]
  },
  {
    "objectID": "system-design/patterns.html#scalability-patterns",
    "href": "system-design/patterns.html#scalability-patterns",
    "title": "Design Patterns",
    "section": "",
    "text": "Description: Distributing traffic across multiple servers\nTypes: Round-robin, least connections, IP hash, weighted\nUse Cases: High availability, horizontal scaling\n\n┌─────────┐\n│  Client │\n└────┬────┘\n     │\n┌────▼────┐\n│   Load  │\n│Balancer │\n└────┬────┘\n     │\n┌────┴────┐\n│ Server1 │\n└─────────┘\n     │\n┌────┴────┐\n│ Server2 │\n└─────────┘\n     │\n┌────┴────┐\n│ Server3 │\n└─────────┘\n\n\n\n\n\n\nDescription: Application manages cache directly\nPros: Simple, flexible, cache control\nCons: Cache miss penalty, cache invalidation complexity\n\ndef get_user_data(user_id):\n    # Try cache first\n    user_data = cache.get(f\"user:{user_id}\")\n    if user_data:\n        return user_data\n    \n    # Cache miss - fetch from database\n    user_data = database.get_user(user_id)\n    if user_data:\n        cache.set(f\"user:{user_id}\", user_data, ttl=3600)\n    \n    return user_data\n\n\n\n\nDescription: Write to cache and database simultaneously\nPros: Data consistency, read performance\nCons: Write latency, cache space usage\n\ndef update_user_data(user_id, user_data):\n    # Update database\n    database.update_user(user_id, user_data)\n    # Update cache\n    cache.set(f\"user:{user_id}\", user_data, ttl=3600)\n\n\n\n\nDescription: Write to cache first, database later\nPros: Write performance, reduced database load\nCons: Data loss risk, complexity\n\n\n\n\n\n\n\n\nDescription: Multiple read-only copies of database\nPros: Read scalability, reduced load on primary\nCons: Eventual consistency, replication lag\n\n┌─────────┐    ┌─────────┐\n│ Primary │───▶│ Replica │\n│   DB    │    │   1     │\n└─────────┘    └─────────┘\n     │              │\n     └──────────────┼─────┐\n                    │     │\n              ┌─────▼─┐   │\n              │Replica│   │\n              │   2   │   │\n              └───────┘   │\n                          │\n                    ┌─────▼─┐\n                    │Replica│\n                    │   3   │\n                    └───────┘\n\n\n\n\nDescription: Partitioning data across multiple databases\nPros: Horizontal scaling, improved performance\nCons: Complexity, cross-shard queries, rebalancing\n\ndef get_shard_key(user_id):\n    return user_id % 4  # 4 shards\n\ndef get_user_data(user_id):\n    shard_id = get_shard_key(user_id)\n    shard_connection = get_shard_connection(shard_id)\n    return shard_connection.execute(\"SELECT * FROM users WHERE id = ?\", user_id)",
    "crumbs": [
      "System Design",
      "Design Patterns"
    ]
  },
  {
    "objectID": "system-design/patterns.html#security-patterns",
    "href": "system-design/patterns.html#security-patterns",
    "title": "Design Patterns",
    "section": "",
    "text": "Description: Single entry point for all client requests\nPros: Centralized security, rate limiting, monitoring\nCons: Single point of failure, complexity\n\n┌─────────┐    ┌─────────────┐    ┌─────────┐\n│  Client │───▶│     API     │───▶│ Service │\n│         │    │   Gateway   │    │    A    │\n└─────────┘    └─────────────┘    └─────────┘\n                      │\n                      ▼\n                ┌─────────┐\n                │ Service │\n                │    B    │\n                └─────────┘\n\n\n\n\nDescription: Prevents cascading failures\nStates: Closed, Open, Half-Open\nUse Cases: External service calls, fault tolerance\n\nclass CircuitBreaker:\n    def __init__(self, failure_threshold=5, timeout=60):\n        self.failure_threshold = failure_threshold\n        self.timeout = timeout\n        self.failure_count = 0\n        self.last_failure_time = None\n        self.state = 'CLOSED'  # CLOSED, OPEN, HALF_OPEN\n    \n    def call(self, func, *args, **kwargs):\n        if self.state == 'OPEN':\n            if time.time() - self.last_failure_time &gt; self.timeout:\n                self.state = 'HALF_OPEN'\n            else:\n                raise Exception(\"Circuit breaker is OPEN\")\n        \n        try:\n            result = func(*args, **kwargs)\n            if self.state == 'HALF_OPEN':\n                self.state = 'CLOSED'\n                self.failure_count = 0\n            return result\n        except Exception as e:\n            self.failure_count += 1\n            self.last_failure_time = time.time()\n            \n            if self.failure_count &gt;= self.failure_threshold:\n                self.state = 'OPEN'\n            \n            raise e",
    "crumbs": [
      "System Design",
      "Design Patterns"
    ]
  },
  {
    "objectID": "system-design/patterns.html#best-practices",
    "href": "system-design/patterns.html#best-practices",
    "title": "Design Patterns",
    "section": "",
    "text": "Pattern Selection\n\n\n\n\nChoose patterns based on requirements, not trends\nConsider team expertise and maintenance capabilities\nStart simple and evolve as needed\nDocument trade-offs and decisions\n\n\n\n\n\n\n\n\n\nCommon Anti-Patterns\n\n\n\n\nOver-engineering with unnecessary complexity\nIgnoring data consistency requirements\nNot considering failure scenarios\nTight coupling between services",
    "crumbs": [
      "System Design",
      "Design Patterns"
    ]
  }
]