---
title: "Case Studies"
order: 3
---

# System Design Case Studies

Real-world examples of system design challenges and solutions.

## URL Shortener (Bit.ly Clone)

### Requirements
- **Functional**: Shorten long URLs, redirect to original URL
- **Non-Functional**: High availability, low latency, scalable
- **Scale**: 100M URLs per month, 500M redirects per month

### High-Level Design

```
┌─────────┐    ┌─────────────┐    ┌─────────┐
│  Client │───▶│   Web App   │───▶│  URL    │
│         │    │             │    │Service  │
└─────────┘    └─────────────┘    └─────────┘
                      │                   │
                      ▼                   ▼
                ┌─────────┐         ┌─────────┐
                │   Cache │         │Database │
                │  (Redis)│         │(MySQL)  │
                └─────────┘         └─────────┘
```

### Key Components

#### URL Generation
```python
import hashlib
import base64

def generate_short_url(long_url):
    # Hash the long URL
    hash_object = hashlib.md5(long_url.encode())
    hash_hex = hash_object.hexdigest()
    
    # Take first 6 characters and encode to base62
    short_code = base64.urlsafe_b64encode(hash_hex[:6].encode()).decode()[:6]
    
    return short_code

# Alternative: Counter-based approach
def generate_short_url_counter():
    counter = get_next_counter()  # Atomic increment
    return base62_encode(counter)
```

#### Database Schema
```sql
CREATE TABLE urls (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    short_code VARCHAR(10) UNIQUE NOT NULL,
    long_url TEXT NOT NULL,
    user_id BIGINT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    expires_at TIMESTAMP NULL,
    INDEX idx_short_code (short_code),
    INDEX idx_user_id (user_id)
);
```

#### Caching Strategy
```python
def get_long_url(short_code):
    # Try cache first
    long_url = cache.get(f"url:{short_code}")
    if long_url:
        return long_url
    
    # Cache miss - query database
    long_url = database.get_long_url(short_code)
    if long_url:
        cache.set(f"url:{short_code}", long_url, ttl=3600)
    
    return long_url
```

### Scaling Considerations
- **Database**: Read replicas for redirects, sharding by user_id
- **Cache**: Redis cluster for high availability
- **CDN**: For static assets and popular redirects
- **Rate Limiting**: Prevent abuse

## Chat Application (WhatsApp Clone)

### Requirements
- **Functional**: Send/receive messages, group chats, online status
- **Non-Functional**: Real-time, low latency, high availability
- **Scale**: 1M concurrent users, 10M messages per second

### High-Level Design

```
┌─────────┐    ┌─────────────┐    ┌─────────┐
│  Client │◄──▶│   WebSocket │◄──▶│ Message │
│         │    │   Gateway   │    │Service  │
└─────────┘    └─────────────┘    └─────────┘
                      │                   │
                      ▼                   ▼
                ┌─────────┐         ┌─────────┐
                │ Presence│         │ Message │
                │ Service │         │  Store  │
                └─────────┘         └─────────┘
                      │                   │
                      ▼                   ▼
                ┌─────────┐         ┌─────────┐
                │   Cache │         │Database │
                │  (Redis)│         │(MongoDB)│
                └─────────┘         └─────────┘
```

### Key Components

#### Message Flow
```python
class MessageService:
    def send_message(self, sender_id, receiver_id, message):
        # Store message
        message_id = self.store_message(sender_id, receiver_id, message)
        
        # Update conversation
        self.update_conversation(sender_id, receiver_id, message_id)
        
        # Notify receiver if online
        if self.is_user_online(receiver_id):
            self.push_message(receiver_id, message_id)
        
        return message_id
    
    def push_message(self, user_id, message_id):
        # Get user's WebSocket connection
        connections = self.get_user_connections(user_id)
        
        # Send message to all user's devices
        for connection in connections:
            connection.send({
                'type': 'new_message',
                'message_id': message_id
            })
```

#### Presence Management
```python
class PresenceService:
    def user_online(self, user_id, device_id):
        # Update user status
        self.redis.hset(f"user:{user_id}:devices", device_id, "online")
        self.redis.expire(f"user:{user_id}:devices", 300)  # 5 min TTL
        
        # Notify contacts
        contacts = self.get_user_contacts(user_id)
        for contact_id in contacts:
            self.notify_presence_change(contact_id, user_id, "online")
    
    def user_offline(self, user_id, device_id):
        # Remove device
        self.redis.hdel(f"user:{user_id}:devices", device_id)
        
        # Check if user has other online devices
        if not self.redis.hkeys(f"user:{user_id}:devices"):
            contacts = self.get_user_contacts(user_id)
            for contact_id in contacts:
                self.notify_presence_change(contact_id, user_id, "offline")
```

### Scaling Considerations
- **WebSocket**: Load balancer with sticky sessions
- **Message Store**: Sharding by conversation_id
- **Presence**: Redis cluster with replication
- **Media**: CDN for file storage

## Social Media Feed (Twitter Clone)

### Requirements
- **Functional**: Post tweets, follow users, view timeline
- **Non-Functional**: Low latency, high availability, real-time updates
- **Scale**: 100M users, 1M tweets per minute

### High-Level Design

```
┌─────────┐    ┌─────────────┐    ┌─────────┐
│  Client │───▶│   API       │───▶│  Feed   │
│         │    │  Gateway    │    │Service  │
└─────────┘    └─────────────┘    └─────────┘
                      │                   │
                      ▼                   ▼
                ┌─────────┐         ┌─────────┐
                │  Tweet  │         │  User   │
                │ Service │         │Service  │
                └─────────┘         └─────────┘
                      │                   │
                      ▼                   ▼
                ┌─────────┐         ┌─────────┐
                │   Cache │         │Database │
                │  (Redis)│         │(MySQL)  │
                └─────────┘         └─────────┘
```

### Feed Generation Strategies

#### Pull Model (Timeline on Read)
```python
def get_user_feed(user_id, page=1, limit=20):
    # Get user's following list
    following = get_following_users(user_id)
    
    # Get tweets from following users
    tweets = get_tweets_by_users(following, page, limit)
    
    # Sort by timestamp
    tweets.sort(key=lambda x: x['created_at'], reverse=True)
    
    return tweets
```

#### Push Model (Timeline on Write)
```python
def post_tweet(user_id, content):
    # Store tweet
    tweet_id = store_tweet(user_id, content)
    
    # Get user's followers
    followers = get_user_followers(user_id)
    
    # Push to followers' timelines
    for follower_id in followers:
        add_to_timeline(follower_id, tweet_id)
    
    return tweet_id

def add_to_timeline(user_id, tweet_id):
    # Add to user's timeline (Redis sorted set)
    redis.zadd(f"timeline:{user_id}", {tweet_id: time.time()})
    
    # Keep only recent tweets (e.g., last 1000)
    redis.zremrangebyrank(f"timeline:{user_id}", 0, -1001)
```

#### Hybrid Model
```python
def get_user_feed_hybrid(user_id, page=1, limit=20):
    # Try cache first (push model for active users)
    cached_tweets = get_cached_timeline(user_id, page, limit)
    if cached_tweets:
        return cached_tweets
    
    # Fallback to pull model
    return get_user_feed_pull(user_id, page, limit)
```

### Database Schema
```sql
-- Users table
CREATE TABLE users (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Tweets table
CREATE TABLE tweets (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    user_id BIGINT NOT NULL,
    content TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id),
    INDEX idx_user_created (user_id, created_at)
);

-- Follows table
CREATE TABLE follows (
    follower_id BIGINT NOT NULL,
    following_id BIGINT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (follower_id, following_id),
    FOREIGN KEY (follower_id) REFERENCES users(id),
    FOREIGN KEY (following_id) REFERENCES users(id)
);
```

## Video Streaming Service (YouTube Clone)

### Requirements
- **Functional**: Upload videos, stream videos, search, recommendations
- **Non-Functional**: High bandwidth, low latency, global distribution
- **Scale**: 1B users, 1M video uploads per day

### High-Level Design

```
┌─────────┐    ┌─────────────┐    ┌─────────┐
│  Client │───▶│   CDN       │───▶│ Video   │
│         │    │  (CloudFlare)│   │Storage  │
└─────────┘    └─────────────┘    └─────────┘
                      │
                      ▼
                ┌─────────────┐
                │   API       │
                │  Gateway    │
                └─────────────┘
                      │
                      ▼
┌─────────┐    ┌─────────────┐    ┌─────────┐
│  Video  │◄──▶│   Video     │◄──▶│  User   │
│Processing│   │  Service    │    │Service  │
└─────────┘    └─────────────┘    └─────────┘
                      │                   │
                      ▼                   ▼
                ┌─────────┐         ┌─────────┐
                │   Cache │         │Database │
                │  (Redis)│         │(MySQL)  │
                └─────────┘         └─────────┘
```

### Video Processing Pipeline
```python
class VideoProcessor:
    def process_video(self, video_id, file_path):
        # 1. Extract metadata
        metadata = self.extract_metadata(file_path)
        
        # 2. Generate multiple qualities
        qualities = ['360p', '720p', '1080p']
        for quality in qualities:
            self.transcode_video(file_path, video_id, quality)
        
        # 3. Generate thumbnail
        self.generate_thumbnail(file_path, video_id)
        
        # 4. Update video status
        self.update_video_status(video_id, 'processed')
        
        # 5. Trigger indexing
        self.index_video(video_id, metadata)
```

### Adaptive Bitrate Streaming
```python
def get_video_manifest(video_id, quality):
    # Get available qualities for video
    qualities = get_video_qualities(video_id)
    
    # Generate HLS manifest
    manifest = "#EXTM3U\n"
    manifest += "#EXT-X-VERSION:3\n"
    
    for q in qualities:
        manifest += f"#EXT-X-STREAM-INF:BANDWIDTH={q['bandwidth']},RESOLUTION={q['resolution']}\n"
        manifest += f"{video_id}_{q['quality']}.m3u8\n"
    
    return manifest
```

## Key Learnings

::: {.callout-tip}
## Common Patterns
- **Caching**: Redis for session data, CDN for static content
- **Database**: Read replicas, sharding, denormalization
- **Messaging**: Queues for async processing, WebSockets for real-time
- **Storage**: Object storage for files, databases for metadata
:::

::: {.callout-warning}
## Trade-offs to Consider
- **Consistency vs Availability**: Choose based on use case
- **Latency vs Throughput**: Optimize for user experience
- **Cost vs Performance**: Balance infrastructure costs
- **Complexity vs Scalability**: Start simple, evolve as needed
::: 