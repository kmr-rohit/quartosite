---
title: "Scalability"
order: 4
---

# Scalability

Strategies and techniques for building systems that can handle growth in users, data, and traffic.

## Types of Scaling

### Vertical Scaling (Scale Up)
- **Description**: Adding more resources to existing machines
- **Resources**: CPU, RAM, Storage, Network bandwidth
- **Pros**: Simple, no code changes required
- **Cons**: Limited by hardware, expensive, single point of failure
- **Use Cases**: Small to medium applications, database servers

```
┌─────────────────────────────────────┐
│           Single Server             │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐ │
│  │  32 CPU │ │ 128GB   │ │ 10TB    │ │
│  │  Cores  │ │   RAM   │ │ Storage │ │
│  └─────────┘ └─────────┘ └─────────┘ │
└─────────────────────────────────────┘
```

### Horizontal Scaling (Scale Out)
- **Description**: Adding more machines to distribute load
- **Pros**: No hardware limits, fault tolerance, cost-effective
- **Cons**: Complexity, distributed system challenges
- **Use Cases**: Web applications, microservices, cloud-native apps

```
┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐
│ Server1 │ │ Server2 │ │ Server3 │ │ Server4 │
│  8 CPU  │ │  8 CPU  │ │  8 CPU  │ │  8 CPU  │
│ 32GB RAM│ │ 32GB RAM│ │ 32GB RAM│ │ 32GB RAM│
└─────────┘ └─────────┘ └─────────┘ └─────────┘
     │           │           │           │
     └───────────┼───────────┼───────────┘
                 │           │
         ┌───────▼───────┐   │
         │   Load        │   │
         │  Balancer     │   │
         └───────────────┘   │
                 │           │
         ┌───────▼───────┐   │
         │   Clients     │   │
         └───────────────┘
```

## Load Balancing

### Load Balancer Types

#### Application Load Balancer (ALB)
- **Layer**: Application Layer (Layer 7)
- **Features**: Content-based routing, SSL termination, health checks
- **Use Cases**: Web applications, microservices

```python
# Health check configuration
health_check = {
    'path': '/health',
    'port': 8080,
    'protocol': 'HTTP',
    'interval': 30,
    'timeout': 5,
    'healthy_threshold': 2,
    'unhealthy_threshold': 3
}
```

#### Network Load Balancer (NLB)
- **Layer**: Transport Layer (Layer 4)
- **Features**: TCP/UDP traffic, high performance, static IP
- **Use Cases**: TCP applications, gaming, IoT

#### Classic Load Balancer (CLB)
- **Layer**: Both Layer 4 and Layer 7
- **Features**: Basic load balancing, health checks
- **Use Cases**: Legacy applications, simple setups

### Load Balancing Algorithms

#### Round Robin
```python
class RoundRobinLoadBalancer:
    def __init__(self, servers):
        self.servers = servers
        self.current_index = 0
    
    def get_next_server(self):
        server = self.servers[self.current_index]
        self.current_index = (self.current_index + 1) % len(self.servers)
        return server
```

#### Least Connections
```python
class LeastConnectionsLoadBalancer:
    def __init__(self, servers):
        self.servers = {server: 0 for server in servers}
    
    def get_next_server(self):
        return min(self.servers, key=self.servers.get)
    
    def increment_connections(self, server):
        self.servers[server] += 1
    
    def decrement_connections(self, server):
        self.servers[server] = max(0, self.servers[server] - 1)
```

#### Weighted Round Robin
```python
class WeightedRoundRobinLoadBalancer:
    def __init__(self, server_weights):
        self.servers = []
        for server, weight in server_weights.items():
            self.servers.extend([server] * weight)
        self.current_index = 0
    
    def get_next_server(self):
        server = self.servers[self.current_index]
        self.current_index = (self.current_index + 1) % len(self.servers)
        return server
```

#### IP Hash
```python
import hashlib

class IPHashLoadBalancer:
    def __init__(self, servers):
        self.servers = servers
    
    def get_server_for_ip(self, client_ip):
        hash_value = int(hashlib.md5(client_ip.encode()).hexdigest(), 16)
        server_index = hash_value % len(self.servers)
        return self.servers[server_index]
```

## Caching Strategies

### Cache Levels

#### Application Cache (In-Memory)
```python
import functools
from collections import OrderedDict

class LRUCache:
    def __init__(self, capacity):
        self.cache = OrderedDict()
        self.capacity = capacity
    
    def get(self, key):
        if key in self.cache:
            self.cache.move_to_end(key)
            return self.cache[key]
        return None
    
    def put(self, key, value):
        if key in self.cache:
            self.cache.move_to_end(key)
        self.cache[key] = value
        if len(self.cache) > self.capacity:
            self.cache.popitem(last=False)

# Usage with decorator
def cache_result(ttl=300):
    def decorator(func):
        cache = {}
        
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            key = str(args) + str(kwargs)
            if key in cache:
                result, timestamp = cache[key]
                if time.time() - timestamp < ttl:
                    return result
            
            result = func(*args, **kwargs)
            cache[key] = (result, time.time())
            return result
        
        return wrapper
    return decorator
```

#### Distributed Cache (Redis)
```python
import redis
import json

class RedisCache:
    def __init__(self, host='localhost', port=6379, db=0):
        self.redis = redis.Redis(host=host, port=port, db=db)
    
    def get(self, key):
        value = self.redis.get(key)
        return json.loads(value) if value else None
    
    def set(self, key, value, ttl=None):
        serialized = json.dumps(value)
        if ttl:
            self.redis.setex(key, ttl, serialized)
        else:
            self.redis.set(key, serialized)
    
    def delete(self, key):
        self.redis.delete(key)
    
    def exists(self, key):
        return self.redis.exists(key)
```

#### CDN (Content Delivery Network)
```python
# CDN configuration for static assets
cdn_config = {
    'domain': 'cdn.example.com',
    'regions': ['us-east-1', 'us-west-2', 'eu-west-1', 'ap-southeast-1'],
    'cache_headers': {
        'Cache-Control': 'public, max-age=31536000',  # 1 year
        'ETag': 'resource-version-hash'
    }
}

def get_cdn_url(path):
    return f"https://{cdn_config['domain']}/{path}"
```

### Cache Patterns

#### Cache-Aside (Lazy Loading)
```python
def get_user_data(user_id):
    # Try cache first
    cache_key = f"user:{user_id}"
    user_data = cache.get(cache_key)
    
    if user_data:
        return user_data
    
    # Cache miss - fetch from database
    user_data = database.get_user(user_id)
    
    if user_data:
        # Store in cache for future requests
        cache.set(cache_key, user_data, ttl=3600)
    
    return user_data
```

#### Write-Through
```python
def update_user_data(user_id, user_data):
    # Update database first
    database.update_user(user_id, user_data)
    
    # Update cache immediately
    cache_key = f"user:{user_id}"
    cache.set(cache_key, user_data, ttl=3600)
```

#### Write-Behind (Write-Back)
```python
class WriteBackCache:
    def __init__(self, batch_size=100, flush_interval=60):
        self.cache = {}
        self.write_queue = []
        self.batch_size = batch_size
        self.flush_interval = flush_interval
        self.last_flush = time.time()
    
    def write(self, key, value):
        # Write to cache immediately
        self.cache[key] = value
        
        # Add to write queue
        self.write_queue.append((key, value))
        
        # Flush if conditions are met
        if (len(self.write_queue) >= self.batch_size or 
            time.time() - self.last_flush >= self.flush_interval):
            self.flush()
    
    def flush(self):
        if not self.write_queue:
            return
        
        # Batch write to database
        batch_writes = self.write_queue[:self.batch_size]
        database.batch_update(batch_writes)
        
        # Clear processed writes
        self.write_queue = self.write_queue[self.batch_size:]
        self.last_flush = time.time()
```

## Database Scaling

### Read Replicas
```python
class DatabaseManager:
    def __init__(self):
        self.master = DatabaseConnection('master-host', 'master-port')
        self.replicas = [
            DatabaseConnection('replica1-host', 'replica1-port'),
            DatabaseConnection('replica2-host', 'replica2-port'),
            DatabaseConnection('replica3-host', 'replica3-port')
        ]
        self.current_replica = 0
    
    def read(self, query):
        # Use round-robin for read replicas
        replica = self.replicas[self.current_replica]
        self.current_replica = (self.current_replica + 1) % len(self.replicas)
        return replica.execute(query)
    
    def write(self, query):
        # Always use master for writes
        return self.master.execute(query)
```

### Database Sharding
```python
class ShardedDatabase:
    def __init__(self, shards):
        self.shards = shards
        self.shard_count = len(shards)
    
    def get_shard(self, key):
        # Simple hash-based sharding
        shard_id = hash(key) % self.shard_count
        return self.shards[shard_id]
    
    def read(self, key, query):
        shard = self.get_shard(key)
        return shard.execute(query)
    
    def write(self, key, query):
        shard = self.get_shard(key)
        return shard.execute(query)
    
    def read_across_shards(self, query):
        # For queries that need data from multiple shards
        results = []
        for shard in self.shards:
            result = shard.execute(query)
            results.extend(result)
        return results
```

## Auto Scaling

### Horizontal Pod Autoscaler (Kubernetes)
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### AWS Auto Scaling Group
```python
import boto3

class AutoScalingManager:
    def __init__(self):
        self.autoscaling = boto3.client('autoscaling')
    
    def create_auto_scaling_group(self, name, min_size, max_size, desired_capacity):
        response = self.autoscaling.create_auto_scaling_group(
            AutoScalingGroupName=name,
            MinSize=min_size,
            MaxSize=max_size,
            DesiredCapacity=desired_capacity,
            TargetGroupARNs=['arn:aws:elasticloadbalancing:...'],
            VPCZoneIdentifier='subnet-12345678,subnet-87654321'
        )
        return response
    
    def create_scaling_policy(self, asg_name, policy_name, target_cpu):
        response = self.autoscaling.put_scaling_policy(
            AutoScalingGroupName=asg_name,
            PolicyName=policy_name,
            PolicyType='TargetTrackingScaling',
            TargetTrackingConfiguration={
                'PredefinedMetricSpecification': {
                    'PredefinedMetricType': 'ASGAverageCPUUtilization'
                },
                'TargetValue': target_cpu
            }
        )
        return response
```

## Performance Monitoring

### Key Metrics
```python
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {}
    
    def record_latency(self, operation, duration):
        if operation not in self.metrics:
            self.metrics[operation] = []
        self.metrics[operation].append(duration)
    
    def get_average_latency(self, operation):
        if operation not in self.metrics:
            return 0
        return sum(self.metrics[operation]) / len(self.metrics[operation])
    
    def get_p95_latency(self, operation):
        if operation not in self.metrics:
            return 0
        sorted_latencies = sorted(self.metrics[operation])
        index = int(len(sorted_latencies) * 0.95)
        return sorted_latencies[index]
    
    def record_throughput(self, operation, count):
        # Record requests per second
        current_time = time.time()
        if operation not in self.metrics:
            self.metrics[operation] = {'count': 0, 'start_time': current_time}
        
        self.metrics[operation]['count'] += count
        
        # Calculate RPS
        elapsed = current_time - self.metrics[operation]['start_time']
        rps = self.metrics[operation]['count'] / elapsed
        return rps
```

## Best Practices

::: {.callout-tip}
## Scaling Guidelines
- **Start Simple**: Begin with vertical scaling for small applications
- **Monitor First**: Understand bottlenecks before scaling
- **Scale Horizontally**: Add more machines rather than bigger machines
- **Cache Aggressively**: Reduce database load with caching
- **Use CDN**: Distribute static content globally
:::

::: {.callout-warning}
## Common Pitfalls
- **Premature Optimization**: Don't scale before you need to
- **Ignoring Bottlenecks**: Database is often the limiting factor
- **Poor Monitoring**: Can't optimize what you can't measure
- **Over-Engineering**: Keep it simple until complexity is justified
::: 